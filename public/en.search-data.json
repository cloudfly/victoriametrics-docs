{"/docs/":{"data":{"":"","victoriametrics-是什么#VictoriaMetrics 是什么？":"VictoriaMetrics是一个快速、经济高效且可扩展的监控解决方案和时间序列数据库。\nVictoriaMetrics提供二进制发布版、Docker镜像、Snap软件包和源代码。\nVictoriaMetrics的集群版本可以在这里找到。\n了解更多关于VictoriaMetrics的核心概念，并按照快速开始获得更好的体验。\n它还有一个用户友好型日志数据库 - VictoriaLogs。"},"title":"VictoriaMetrics 中文手册"},"/docs/concepts/":{"data":{"":"","metric-类型#Metric 类型":"","metric-结构#Metric 结构":"","tenant#多租户":"本文主要阐述一些词汇概念的基本定义，如果你对这些基本概念或词汇没有基本的了解，对本书中的大部分内容的理解上都会有一些困难。\n什么是 Metric（度量指标） 简单来说，metric是对事物的数值测量或观察。\nMetric 最常见的用途包括：\n检查系统在特定时间段内的行为； 将行为变化与其他测量结果相关联； 观察或预测趋势； 如果度量标准超过阈值，则触发事件（告警）。 Metric 结构 让我们从一个例子开始。为了追踪我们的应用程序处理了多少请求，我们将定义一个名为requests_total的指标。\n在这里你可以更具体一些，比如说requests_success_total（仅针对成功的请求）或者request_errors_total（针对失败的请求）。\n选择一个指标名称非常重要，它应该能够清楚地向每个看到它的人传达正确信息：实际测量到了什么内容；就像编程中的变量名一样。在其他的 tsdb 中，也有使用 measurement 这个单词的，其表达的核心内容是一样的。\nLabels（标签） 每个指标都可以包含额外的元信息，以 Label 对的形式呈现：\nrequests_total{path=\"/\", code=\"200\"} requests_total{path=\"/\", code=\"403\"} 指标元信息，即一组用花括号括起来的键值对，为我们提供了request被处理的path和status code的上下文。Label 的值始终是string类型。VictoriaMetrics数据模型是无模式的（No Scheme），即没有预先定义的表结构，用户不需要预先定义指标名称或其标签，而是可以随时添加或更改已采用的指标。\n实际上，指标名称也是一个具有特殊名称__name__的 Label。因此，以下两个系列是相同的：\nrequests_total{path=\"/\", code=\"200\"} {__name__=\"requests_total\", path=\"/\", code=\"200\"} Labels可以自动附加到通过vmagent或Prometheus采集的 timeseries 上。VictoriaMetrics支持对查询API强制执行 Label 过滤器以实现数据的软隔离。然而，真正的数据隔离可以通过多租户实现。\nTimeseries（时间序列） 一个指标名称和其 Label 的组合定义了一个 timeseries。例如，requests_total{path=\"/\", code=\"200\"} 和 requests_total{path=\"/\", code=\"403\"} 是两个不同的 timeseries，因为它们在code标签上有不同的值。\n唯一时间序列的数量对数据库资源用量产生影响。详细信息请参阅什么是活跃时间序列以及什么是高流失率。\nCardinality（基数） 唯一时间序列的数量被称为基数。过多的唯一时间序列被称为高基数。高基数可能导致在VictoriaMetrics中增加资源使用量。请参阅这篇文档以获取更多详细信息。\nRaw samples（原始样本） 每个唯一的时间序列可以由任意数量的(value，timestamp)数据点（也称为原始样本）组成，它们按照timestamp排序。value是双精度浮点数。timestamp是具有毫秒精度的 Unix 时间戳。\n以下是一个Prometheus文本格式的单个原始样本的示例：\nrequests_total{path=\"/\", code=\"200\"} 123 4567890 requests_total{path=\"/\", code=\"200\"} 用于标识给定样本的相关 timeseries。 123 是一个样本值。 4567890 是可选的样本时间戳。如果缺失，则数据被存储到VictoriaMetrics中时使用数据库的当前时间戳。 Timeseries resolution（时间序列粒度） 分辨率是 timeseries 的 samples 之间的最小间隔。考虑以下示例：\n---------------------------------------------------------------------- | \u003ctime series\u003e | \u003cvalue\u003e | \u003ctimestamp\u003e | | requests_total{path=\"/health\", code=\"200\"} | 1 | 1676297640 | | requests_total{path=\"/health\", code=\"200\"} | 2 | 1676297670 | | requests_total{path=\"/health\", code=\"200\"} | 3 | 1676297700 | | requests_total{path=\"/health\", code=\"200\"} | 4 | 1676297730 | .... 这里有一个代表请求总数的 timeseries{path=\"/health\", code=\"200\"}，每30秒更新一次值。这意味着它的分辨率也是30秒。\n在 Pull 模式中，分辨率等于抓取间隔，并由监控系统（服务器）控制。对于 Push 模式，分辨率是样本时间戳之间的间隔，并由客户端（指标收集器）控制。\n尽量保持时间序列的分辨率一致，因为某些 MetricsQL 函数可能期望如此，以免计算出『奇怪』的结果。\nMetric 类型 在 VictoriaMetrics 内部，并 metric type 的概念。此概念存在是为了帮助用户理解度量是如何测量的。有四种常见的度量类型。\nCounter（计数器） Counter 是一种用于统计某些事件的发生次数的 Metric。它的值是累加的，随着时间增加或保持不变，在一般情况下不会减少。唯一的例外是当计数器重置为零时，例如计数器重置。当暴露 Counter 指标的服务重新启动时，可能会发生计数器重置。因此，Counter指标显示了自服务启动以来观察到的事件数量。\n在编程中，Counter 是一个变量，在每次发生某个事件时递增其值。\nvm_http_requests_total 是一个典型的 Counter 示例。上面图表的解释是，时间序列 vm_http_requests_total{instance=\"localhost:8428\", job=\"victoriametrics\", path=\"api/v1/query_range\"} 在下午1点38分到1点39分之间迅速变化，然后在1点41分之前没有任何变化。\nCounter用于测量事件数量，例如请求、错误、日志、消息等。与计数器一起使用最常见的 MetricsQL 函数有：\nrate - 计算指标每秒平均变化速度。例如，rate(requests_total) 显示平均每秒服务多少个请求； increase - 计算给定时间段内指标的增长情况，时间段由方括号中指定。例如，increase(requests_total[1h]) 显示过去一小时内服务的请求数量。 Counter 可以具有小数值。例如，request_duration_seconds_sum 计数器可能会对所有请求的持续时间进行求和。每个持续时间可能以秒为单位具有小数值，如0.5 秒。因此所有请求持续时间的累积总和也可能是小数。\n建议在 Counter 指标名称中添加 _total、_sum 或 _count 后缀，这样人们就可以轻松区分这些指标与其他类型的指标。\nGauge（仪表） Gauge 用于测量可以上下变化的值：\n图表上的度量指标 process_resident_memory_anon_bytes 显示了应用程序在每个给定时间点的内存使用情况。它经常变化，上下波动，显示进程如何分配和释放内存。在编程中，gauge 是一个变量，你可以将其设置为随着变化而改变的特定值。\n以下是 gauge 的使用场景：\n测量温度、内存使用情况、磁盘使用情况等； 存储某个过程的状态。例如，如果配置重新加载成功，则可以将 gauge config_reloaded_successful 设置为 1；如果配置重新加载失败，则设置为 0； 存储事件发生时的时间戳。例如，config_last_reload_success_timestamp_seconds 可以存储最后一次成功配置重新加载的时间戳。 与 gauges 最常用的 MetricsQL 函数是聚合函数和滚动函数。\nHistogram（直方图） Histogram是一组具有不同vmrange或le标签的 Counter 指标。 vmrange或le标签定义了特定bucket（桶）的测量边界。当观察到的测量值命中特定的bucket时，相应的Counter会递增。\n直方图桶通常在其名称中带有_bucket后缀。例如，VictoriaMetrics使用vm_rows_read_per_query直方图跟踪每个查询处理的行分布情况。该 Histogram 的暴露格式如下：\nvm_rows_read_per_query_bucket{vmrange=\"4.084e+02...4.642e+02\"} 2 vm_rows_read_per_query_bucket{vmrange=\"5.275e+02...5.995e+02\"} 1 vm_rows_read_per_query_bucket{vmrange=\"8.799e+02...1.000e+03\"} 1 vm_rows_read_per_query_bucket{vmrange=\"1.468e+03...1.668e+03\"} 3 vm_rows_read_per_query_bucket{vmrange=\"1.896e+03...2.154e+03\"} 4 vm_rows_read_per_query_sum 15582 vm_rows_read_per_query_count 11 其中 vm_rows_read_per_query_bucket{vmrange=\"4.084e+02...4.642e+02\"} 2 这一行表示自上次VictoriaMetrics启动以来，vmrange的值在(408.4 - 464.2]区间的查询有2个。\n以 _bucket 后缀结尾的计数器可以使用 histogram_quantile 函数估算观测测量值的任意百分位数。例如，以下查询返回在过去一小时内每个查询读取的行数的估算第99百分位数（见方括号中的 1h）：\nhistogram_quantile(0.99, sum(increase(vm_rows_read_per_query_bucket[1h])) by (vmrange)) 这个查询的执行逻辑如下：\n增加(vm_rows_read_per_query_bucket[1h]) 计算每个桶每个实例在过去一小时内的事件数量。 sum(...) 按 (vmrange) 计算相同 vmrange 值的每个实例桶的事件总数。 histogram_quantile(0.99, ...) 在步骤 2 返回的 vmrange 桶上计算第 99 百分位数。 histogram 类型还暴露了额外两个附加计数器，以 _sum 和 _count 后缀结尾。\nvm_rows_read_per_query_sum是所有观测到的测量值的总和，例如自上次VictoriaMetrics启动以来由所有查询服务的行数之和。\nvm_rows_read_per_query_count是观测到的事件总数，例如自上次VictoriaMetrics启动以来观测到的查询总数。\n这些计数器允许在特定回溯窗口内计算平均测量值。例如，以下查询计算最近5分钟（方括号中为5m）每个查询读取行数的平均值：\nincrease(vm_rows_read_per_query_sum[5m]) / increase(vm_rows_read_per_query_count[5m]) 使用 github.com/VictoriaMetrics/metrics 包，可以通过以下方式在Go应用程序中使用vm_rows_read_per_query直方图：\n// define the histogram rowsReadPerQuery := metrics.NewHistogram(`vm_rows_read_per_query`) // use the histogram during processing for _, query := range queries { rowsReadPerQuery.Update(float64(len(query.Rows))) } 我们来看看每次调用rowsReadPerQuery.Update时，会发生什么：\n计数器vm_rows_read_per_query_sum的值将增加query.Rows表达式的长度； 计数器vm_rows_read_per_query_count增加1； 只有在观察到的值在vmrange定义的范围（桶）内时，计数器vm_rows_read_per_query_bucket才会递增。 这样一组计数器指标可以在Grafana中绘制热力图并计算分位数：\nGrafana对带有vmrange标签的桶不理解，因此在构建Grafana中的热力图之前，必须使用prometheus_buckets函数将带有vmrange标签的桶转换为带有le标签的桶。\nhistogram 通常用于测量延迟分布、元素大小（例如批处理大小）等。VictoriaMetrics支持两种直方图实现：\nPrometheus Histogram。大多数客户端库都支持这种经典的 Histogram 实现方式。Prometheus Histogram 要求用户静态定义范围（bucket）。 VictoriaMetrics Histogram 由 VictoriaMetrics/metrics 工具库支持。Victoriametrics Histogram 会自动处理桶边界，因此用户无需考虑它们。 我们建议您在开始使用直方图之前阅读以下文章：\nPrometheus histogram Histograms and summaries How does a Prometheus Histogram work? Improving histogram usability for Prometheus and Grafana Summary（摘要） Summary 与 Histogram 非常相似，用于计算分位数。主要区别在于 Summary 是在客户端进行计算的，因此指标公开格式已经包含了预定义的分位数：\ngo_gc_duration_seconds{quantile=\"0\"} 0 go_gc_duration_seconds{quantile=\"0.25\"} 0 go_gc_duration_seconds{quantile=\"0.5\"} 0 go_gc_duration_seconds{quantile=\"0.75\"} 8.0696e-05 go_gc_duration_seconds{quantile=\"1\"} 0.001222168 go_gc_duration_seconds_sum 0.015077078 go_gc_duration_seconds_count 83 Summary 的可视化非常直观：\n这种方法使得 Summary 更易于使用，但与 Histogram 相比也存在显著的限制：\n无法计算多个 Summary 指标的分位数，例如 sum(go_gc_duration_seconds{quantile=\"0.75\"})、avg(go_gc_duration_seconds{quantile=\"0.75\"}) 或 max(go_gc_duration_seconds{quantile=\"0.75\"}) 不会返回从应用程序的多个实例收集到的 go_gc_duration_seconds 指标的预期第75百分位数。有关详细信息，请参阅本文。 无法计算除已经预先计算过的分位数之外的其他分位数。 无法针对在任意时间范围内收集到的测量值计算分位数。通常，Summary 分位数是在固定时间范围内（如最近5分钟）计算出来的。 Summary 通常用于跟踪延迟、元素大小（例如批处理大小）等预定义百分比。\n使用 Metric 对应用进行观测 正如在Metric类型部分的开头所说，Metric类型定义了它是如何被测量的。VictoriaMetrics TSDB并不认识Metric类型。它只看到Metric的名称、Label、Value和 Timestamp。这些 Metric 是什么，它们衡量什么以及如何衡量 - 这一切都取决于发出这些指标的应用程序。\n为了使用与VictoriaMetrics兼容的Metric来监控您的应用程序，我们建议使用 github.com/VictoriaMetrics/metrics 包。\nVictoriaMetrics还与Prometheus客户端库兼容。\n命名 我们建议遵循Prometheus的指标命名规范。对于 VictoriaMetrics 来说，没有严格的限制，所以任何指标名称和 Label 名称都是可以接受的。但是遵循这个约定有助于保持名称有意义、描述性强，并且清晰易懂给其他人。遵循这个约定是一个好习惯。\nLabel 每个 Metric 都可以包含任意数量的key=\"value\"标签。良好的实践是保持这个数量可控。否则，处理包含大量Label的数据将会很困难。默认情况下，VictoriaMetrics将每个Metric的Label数限制为30，并丢弃其他标签。如果需要，可以通过-maxLabelsPerTimeseries命令行参数来更改此限制（但不建议这样做）。\n每个Label的值都可以包含任意字符串值。良好的实践是使用简短而有意义的标签值来描述指标属性，而不是讲述它们的故事。例如，environment=\"prod\"是可以接受的正常Label，但log_message=\"long log message with a lot of details...\"就不是可接受的。默认情况下，VictoriaMetrics将标签值大小限制为16kB。可以通过-maxLabelValueLen命令行参数来更改此限制（同样强烈不建议这样做）。\n控制唯一标签值的数量非常重要，因为每个唯一标签值都会导致一个新 timeseries 产生。尽量避免使用易变性较高的标签值（如会话ID或查询ID），以避免过多资源使用和数据库减速问题发生。\n多租户 VictoriaMetrics的集群版本支持数据隔离的多租户功能。\n对于单机版本的VictoriaMetrics，可以通过在写入URL路径上添加 Label 并在查询URL路径上强制进行 Label 过滤来模拟多租户。","什么是-metric度量指标#什么是 Metric（度量指标）":"","使用-metric-对应用进行观测#使用 Metric 对应用进行观测":""},"title":"核心概念"},"/docs/faq/":{"data":{"":"","how-to-delete-data#如何删除数据":"什么是活跃时间序列? 时间序列通过其名称和一组标签来唯一标识。例如，temperature{city=\"NY\",country=\"US\"} 和 temperature{city=\"SF\",country=\"US\"} 是两个不同的序列，因为它们在城市标签上有所区别。如果一个时间序列在最近一小时内至少接收到一个新样本，则被视为活跃。\n高流失率是指什么？ 如果旧的时间序列以高频率被新的时间序列不断替换，那么这种状态被称为高流失率。高流失率会带来以下负面影响：\n数据库中存储的时间序列总数增加。\n倒排索引（存储在\u003cstorageDataPath\u003e/indexdb）的大小增加，因为倒排索引包含了每个标签至少有一个摄入样本的所有时间序列的条目。\n查询跨多天时变慢。\n导致高流失率的主要原因是具有频繁更改值的度量标签。以下是一些示例：\nqueryid，在postgres_exporter中每次查询都会更改。\napp_name或deployment_id，在Kubernetes中每次部署都会更改。\n从当前时间派生出来的标签，例如timestamp、minute或hour。\n经常更改的hash或uuid标签。\n解决高流失率问题需要识别和消除具有频繁更改值的标签。Cardinality explorer可以帮助确定这些标签。\n什么是高基数 高基数通常意味着活跃时间序列的数量很多。高基数可能导致内存使用量增加和/或慢速插入的比例较高。高基数的来源通常是具有大量唯一值的标签，这些标签占了被摄取时间序列的很大比例。解决方案是通过基数探索器来识别和移除高基数的来源。\n什么是慢写入 VictoriaMetrics在内存中维护了一个缓存，用于将活跃时间序列映射为内部系列ID。缓存的大小取决于主机系统中可用的VictoriaMetrics内存。如果所有活跃时间序列的信息无法适应缓存，则VictoriaMetrics需要在每个进入样本时从磁盘上读取和解压缩不在缓存中的时间序列信息。这个操作比缓存查找要慢得多，因此这种插入被称为慢写入。官方仪表板上出现大量慢写入表示当前活跃时间序列数量存在内存不足问题。这种情况通常会导致数据摄取严重减慢，并显著增加磁盘IO和CPU使用率。解决方法是增加更多内存或减少活跃时间序列的数量。Cardinality Explorer可以帮助定位高数量活跃时间序列的来源。\n如何限制 VictoriaMetrics 组件的内存 所有的VictoriaMetrics组件都提供了命令行参数来控制内部缓冲区和缓存的大小：-memory.allowedPercent 和 -memory.allowedBytes（在任何一个VictoriaMetrics组件中使用-help 查看这些参数的描述）。这些限制不考虑可能需要用于处理传入查询的额外内存。硬限制只能通过操作系统通过cgroups、Docker或Kubernetes来强制执行。\n根据以下文档，可以调整VictoriaMetrics组件的内存使用情况：\nResource usage limits for single-node VictoriaMetrics Resource usage limits for cluster VictoriaMetrics Troubleshooting for vmagent Troubleshooting for single-node VictoriaMetrics 如何删除数据 请阅读 如何删除 Timeseries。","how-to-limit-memory-usage#如何限制 VictoriaMetrics 组件的内存":"","what-is-active-timeseries#什么是活跃时间序列? ":"","what-is-high-cardinality#什么是高基数":"","what-is-high-churn-rate#高流失率是指什么？":"","what-is-slow-insert#什么是慢写入":""},"title":"FAQ"},"/docs/ops/cluster/":{"data":{"":"","api接口#API接口":"集群版本和单机版的API接口主要区别是数据的读取和写入是由独立组件完成的，而且也有了租户的支持。集群版本也支持/prometheus/api/v1来接收 jsonl, csv, native 和 prometheus数据格式，而不仅仅是prometheus数据格式。可以在这里查看VictoriaMetrics的API的使用范例。\n用于数据写入的 URLs 是：http://\u003cvminsert\u003e:8480/insert/\u003caccountID\u003e/\u003csuffix\u003e，其中： \u003caccountID\u003e 是一个任意的32位数字，用来表示数据写入的空间（即租户）。也可以设置成accountID:projectID格式，其中 projectID 也是一个任意的32位数字。如果 projectID 没有指定,则默认是0。更多信息可以看多租户文档。 这里的\u003caccountID\u003e 可以使用字符串 multitenant ， 比如 http://\u003cvminsert\u003e:8480/insert/multitenant/\u003csuffix\u003e，该 URL 接受到的数据会将数据的 vm_account_id 和 vm_project_id label 视为租户信息。更多信息请看通过label实现多租户。 \u003csuffix\u003e 可以是以下这些内容： prometheus 和 prometheus/api/v1/write - 用来写入 Prometheus Remote Write 数据协议的接口。 prometheus/api/v1/import - 用来导入通过vmselect的 api/v1/export 接口导出来的数据（见下文）, 是 JSON line 的格式. prometheus/api/v1/import/native - 用来导入通过vmselect的api/v1/export/native 接口导出的数据（见下文）。 prometheus/api/v1/import/csv - 用来导入 CSV 数据。详细信息见文档。 prometheus/api/v1/import/prometheus - 用来导入 Prometheus text exposition 或 OpenMetrics格式的数据。该接口也支持 Pushgateway 协议。 更多信息看这些文档。 datadog/api/v1/series - 用来写入 DataDog submit metrics接口。 更多信息见这些文档。 influx/write and influx/api/v2/write - 用来写入 InfluxDB line protocol的数据，更多信息见这些文档。 opentsdb/api/put - 用来处理 OpenTSDB HTTP /api/put 请求。这个接口默认是关闭的。他是通过一个独立的 TCP 地址暴露的，改地址可通过-opentsdbHTTPListenAddr 命令行参数指定。更多信息见这些文档。 Prometheus 查询 API: http://\u003cvmselect\u003e:8481/select/\u003caccountID\u003e/prometheus/\u003csuffix\u003e, 其中: \u003caccountID\u003e 是一个任意32位数字，用来标识查询的空间（即租户）。 \u003csuffix\u003e 可以是一下的内容： api/v1/query - 执行 PromQL instant. api/v1/query_range - 执行 PromQL range 查询。 api/v1/series - 执行 series 查询。 api/v1/labels - 返回 label 名称列表。 api/v1/label/\u003clabel_name\u003e/values - 返回指定 \u003clabel_name\u003e 的所有值，参考这个 API. federate - 返回 federated metrics. api/v1/export - 导出 JSON line 格式的原始数据，更多信息看这篇文章。 api/v1/export/native - 导出原生二进制格式的原始数据，该数据可以通过另一个接口api/v1/import/native导入到 VictoriaMetrics (见上文). api/v1/export/csv - 导出 CSV 格式原始数据。它可以使用另外一个接口 api/v1/import/csv 导入到 VictoriaMetrics（见上文）。 api/v1/series/count - 返回 series 的总数。 api/v1/status/tsdb - 返回时序数据的统计信息。更多详细信息见这些文档。 api/v1/status/active_queries - 返回当前活跃的查询请求。逐一每个 vmselect 实例都有独立的活跃查询列表。 api/v1/status/top_queries - 返回执行频率最高以及查询耗时最长的查询列表。 metric-relabel-debug - 用于对 relabeling 规则 Debug。 Graphite Metrics API：http://\u003cvmselect\u003e:8481/select/\u003caccountID\u003e/graphite/\u003csuffix\u003e, 其中: \u003caccountID\u003e 是一个任意32位数字，用来标识查询的空间（即租户）。 \u003csuffix\u003e 可以是一下的内容： render - 实现 Graphite Render API. 看 these docs. metrics/find - 搜索 Graphite metrics. See these docs. metrics/expand - 扩展 Graphite metrics. See these docs. metrics/index.json - returns 所有的 names. See these docs. tags/tagSeries - 注册 time series. See these docs. tags/tagMultiSeries - 批量注册 time series. See these docs. tags - 返回 tag 名称列表. See these docs. tags/\u003ctag_name\u003e - 返回指定 \u003ctag_name\u003e的值列表 See these docs. tags/findSeries - 返回匹配expr的 series，these docs. tags/autoComplete/tags - 返回匹配 tagPrefix 和/或 expr的tag名称列表。 See these docs. tags/autoComplete/values - 返回匹配 valuePrefix 和/或 expr tag值列表 See these docs. tags/delSeries - deletes series matching the given path. See these docs. 基础的 Web UI: http://\u003cvmselect\u003e:8481/select/\u003caccountID\u003e/vmui/. 统计所有租户的查询：http://\u003cvmselect\u003e:8481/api/v1/status/top_queries。它会列出请求最频繁，以及执行时间最长的查询列表。 删除时间序列：http://\u003cvmselect\u003e:8481/delete/\u003caccountID\u003e/prometheus/api/v1/admin/tsdb/delete_series?match[]=\u003ctimeseries_selector_for_delete\u003e。 请注意，delete_series 处理程序应仅在特殊情况下使用，例如删除意外提取的错误时间序列。它不应定期使用，因为它会带来额外的系统开销。 列出在给定时间范围内已提取数据的租户： http://\u003cvmselect\u003e:8481/admin/tenants?start=...\u0026end=...。start 和 end 参数是可选的。默认返回 VictoriaMetrics 集群中至少包含一条数据的租户列表。 vmalerts UI 界面： http://\u003cvmselect\u003e:8481/select/\u003caccountID\u003e/prometheus/vmalert/。这个 URL works only 只有在指定了 -vmalert.proxyURL 参数时才有效。关于 vmalert 的跟多内容参考这里。 vmstorage 在 8482 端口上提供了如下接口： /internal/force_merge - 强制启动 vmstorage 实例的数据合并压缩。 /snapshot/create - 创建实例快照，可用于后台备份。快照在\u003cstorageDataPath\u003e/snapshots 文件夹中创建，其中\u003cstorageDataPath\u003e是通过相应的命令行参数指定。 /snapshot/list - 列出可用的快照。 /snapshot/delete?snapshot=\u003cid\u003e - 删除给定的快照。 /snapshot/delete_all - 删除所有快照。 快照可以在每个 vmstorage 节点上独立创建。无需在 vmstorage 节点之间同步快照的创建。","helm#Helm":"Helm图表简化了在Kubernetes中管理VictoriaMetrics集群版本的过程。它可在helm-charts仓库中获得。","kubernetes-operator#Kubernetes operator":"K8s operator 简化了在Kubernetes中管理VictoriaMetrics组件的过程。","vmstorage-自动发现#vmstorage 自动发现":"只有企业版支持vminsert 和vmselect对 vmstorage实例自动服务发现，开源版的话需要进行二次开发。\nVictoriaMetrics 的代码质量很高，所以二次开发也比较简单。只需要参考netstorage.Init实现即可，仅有 2 行代码。这里给出一个代码实现参考：\n// ResetStorageNodes initializing new storageNodes by using new addrs, and replace the old global storageNodes func ResetStorageNodes(addrs []string, hashSeed uint64) { if len(addrs) == 0 { return } prevSnb := getStorageNodesBucket() snb := initStorageNodes(addrs, hashSeed) setStorageNodesBucket(snb) if prevSnb != nil { go func() { logger.Infof(\"Storage nodes updated, stopping previous storage nodes\") mustStopStorageNodes(prevSnb) logger.Infof(\"Previous storage nodes already stopped\") }() } } 自己实现发现实例列表的库，在库里面调用该ResetStorageNodes方法即可。","二进制#二进制":"","保存时间过滤器#保存时间过滤器":"VictoriaMetrics 企业版支持通过 label filter 来配置多种数据保留时间，通过 vmstorage 的命令行参数 -retentionFilter 来指定。\n例如，以下配置将 accountID 从 42 开始的租户的保留期设置为 1 天，然后将任何租户的标签 env=“dev” 或 env=“prod” 的时间序列的保留期设置为 3 天，而其余租户的保留期为 4 周：\n-retentionFilter='{vm_account_id=~\"42.*\"}:1d' -retentionFilter='{env=~\"dev|staging\"}:3d' -retentionPeriod=4w' 更多关于保存时间过滤器的详细内容，可以阅读这些文档。","副本和数据安全#副本和数据安全":"默认情况下，VictoriaMetrics将复制工作卸载到由-storageDataPath指定的底层存储上，如Google计算引擎的持久磁盘，这保证了数据的持久性。如果出于某种原因无法使用复制的持久磁盘，VictoriaMetrics支持应用级别的复制。\n通过向vminsert传递-replicationFactor=N命令行标志可以启用复制，这指示vminsert在N个不同的vmstorage节点上存储每个摄入样本的N份副本。这保证了即使有最多N-1个vmstorage节点不可用，所有存储的数据仍然可用于查询。\n向vmselect传递-replicationFactor=N命令行标志指示它不在查询期间如果少于-replicationFactor个vmstorage节点不可用时将响应标记为部分响应。详情请参阅集群可用性文档。\n为了在N-1个存储节点不可用时保持对新摄入数据的给定复制因子，集群必须包含至少2*N-1个vmstorage节点，其中N是复制因子。\nVictoriaMetrics以毫秒精度存储时间戳，因此在启用复制时必须向vmselect节点传递-dedup.minScrapeInterval=1ms命令行参数，这样它们在查询期间可以从不同的vmstorage节点上去重复制的样本。如果从配置相同的vmagent实例或Prometheus实例向VictoriaMetrics推送了重复数据，则根据去重文档，-dedup.minScrapeInterval必须设置为抓取配置中的scrape_interval。\n注意，复制不能防止灾难，因此建议定期进行备份。详情请参阅这些文档。\n注意，复制会增加资源使用——CPU、RAM、磁盘空间、网络带宽——最多可达-replicationFactor=N倍，因为vminsert将N份摄入数据存储到不同的vmstorage节点上，并且vmselect在查询期间需要去重从vmstorage节点获得的复制数据。因此，将复制工作卸载到由-storageDataPath指定的底层复制的持久存储上，如Google计算引擎的持久磁盘，这可以防止数据丢失和数据损坏，更加成本效益。它还提供持续的高性能，并且可以在不停机的情况下调整大小。基于HDD的持久磁盘应该足以满足大多数用例。建议在Kubernetes中使用耐用的复制持久卷。","升级集群节点#升级集群节点":"所有节点类型 - vminsert、vmselect 和 vmstorage - 都可以通过启停进行更新。向相应进程发送 SIGINT 信号，等待其退出，然后使用新配置启动新版本。\n存在以下集群更新/升级方法：\n无停机策略 使用更新的配置/升级的二进制文件逐个重新启动集群中的每个节点。\n建议按以下顺序重新启动节点：\n重启 vmstorage nodes. 重启 vminsert nodes. 重启 vmselect nodes. 如果满足以下条件，此策略允许在不停机的情况下升级集群：\n集群至少有两个及以上实例（每种类型都有 vminsert、vmselect 和 vmstorage），因此当单个节点在重启期间暂时不可用时，其它实例可以继续接受新数据并处理传入请求。有关详细信息，请参阅集群可用性文档。 当任何类型的单个节点（vminsert、vmselect 或 vmstorage）在重启期间暂时不可用时，集群具有足够的计算资源（CPU、RAM、网络带宽、磁盘 IO）来处理当前工作负载。 更新后的的二进制文件与集群中的其余组件兼容。请参阅 CHANGELOG 了解不同版本之间的兼容性说明。 只要有一个条件不满足，则滚动重启可能会导致在升级期间集群不可用。在这种情况下，建议采用以下策略。\n最短停机策略 并发停止所有的 vminsert 和 vmselect 实例。 并发重启所有的vmstorage 实例。 并发重启所有的vminsert 和 vmselect 实例。 执行上述步骤时，集群无法进行数据提取和查询。通过在上述每个步骤中并行重启集群节点，可以最大限度地减少停机时间。与无停机策略相比，最短停机时间策略具有以下优势：\n当以前的版本与新版本不兼容时，它允许以最小的中断完成升级。 当集群没有足够的计算资源（CPU、RAM、磁盘 IO、网络带宽）进行滚动升级时，它允许以最小的中断完成版本升级。 对于具有大量节点的集群或具有大量 vmstorage 节点的集群，它允许最短升级的持续时间，因为它需要很长时间才能平滑重启。 ","去重机制#去重机制":"VictoriaMetrics的集群版本支持数据去重，与单节点版本的方式相同。详情请参阅这些文档。唯一的区别是，由于以下方面，相同的-dedup.minScrapeInterval命令行标志值必须同时传递给vmselect和vmstorage节点：\n默认情况下，vminsert尝试将单个时间序列的所有样本路由到单个vmstorage节点。但在某些条件下，单个时间序列的样本可能会分布在多个vmstorage节点上：\n当添加/移除vmstorage节点时。此时，部分时间序列的新样本将被路由到其他vmstorage节点； 当vmstorage节点暂时不可用（例如，在它们重启期间）。此时，新样本将被重新路由到剩余的可用vmstorage节点； 当vmstorage节点没有足够的能力处理传入的数据流时。此时，vminsert将新样本重新路由到其他vmstorage节点。 ","只读模式#只读模式":"当 -storageDataPath 指向的目录包含的可用空间少于 -storage.minFreeDiskSpaceBytes 时，vmstorage 节点会自动切换到只读模式。vminsert 节点停止向此类节点发送数据，并开始将数据重新路由到剩余的 vmstorage 节点。\n当 vmstorage 进入只读模式时，它会将 http://vmstorage:8482/metrics 上的 vm_storage_is_read_only 指标设置为 1。当 vmstorage 未处于只读模式时，该指标值为 0。","基数限制#基数限制":"vmstorage 实例可以通过下面的命令行来限制所有租户总共 series 的数量\n-storage.maxHourlySeries 限制最近1小时的活跃时间序列的数量。 -storage.maxDailySeries 限制最近一天的活跃时间序列的数量。这个限制可以用于限制天级别的 time series churn rate. 请注意，这些限制是针对集群中的每个 vmstorage 实例的。因此，如果集群有 N 个 vmstorage 节点，则整个集群级限制将比每个 vmstorage 限制大 N 倍。\n关于更多的基数限制可以看这些文档。","备份#备份":"建议定期从即时快照进行备份，以防止用户错误，如意外删除数据。\n创建备份时，必须对每个vmstorage节点执行以下步骤：\n通过导航到/snapshot/create HTTP处理器创建即时快照。它将创建快照并返回其名称。 使用vmbackup从\u003cstorageDataPath\u003e/snapshots/\u003csnapshot_name\u003e文件夹归档创建的快照。归档过程不会干扰vmstorage的工作，因此可以在任何合适的时间进行。 通过/snapshot/delete?snapshot=\u003csnapshot_name\u003e或/snapshot/delete_all删除未使用的快照，以释放占用的存储空间。 无需在所有vmstorage节点之间同步备份。\n从备份中恢复数据：\nkill -INT命令关停 vmstorage。 使用 vmrestore 将备份数据恢复到 -storageDataPath 指定的目录。 启动 vmstorage 节点. ","多层联邦部署#多层联邦部署":"当vmselect节点运行时带有-clusternativeListenAddr命令行标志，它们可以被其他vmselect节点查询。例如，如果vmselect以-clusternativeListenAddr=:8401启动，那么它可以在TCP端口8401上接受来自其他vmselect节点的查询，就像vmstorage节点一样。这允许vmselect节点进行链式连接，并构建多层集群拓扑。例如，顶层vmselect节点可以查询不同可用区（AZ）中的第二层vmselect节点，而第二层vmselect节点可以查询本地AZ中的vmstorage节点。\n当vminsert节点运行时带有-clusternativeListenAddr命令行标志，它们可以接受来自其他vminsert节点的数据。例如，如果vminsert以-clusternativeListenAddr=:8400启动，那么它可以在TCP端口8400上接受来自其他vminsert节点的数据，就像vmstorage节点一样。这允许vminsert节点进行链式连接，并构建多层集群拓扑。例如，顶层vminsert节点可以将数据复制到位于不同可用区（AZ）的第二层vminsert节点中，而第二层vminsert节点可以将数据分散到本地AZ中的vmstorage节点。\n由于同步复制和数据分片，vminsert节点的多层集群设置存在以下缺点：\n数据写入速度受限于连接到AZ的最慢链路。 当某些可用区（AZ）暂时不可用时，顶层的vminsert节点会将传入数据重新路由到剩余的AZ中。这会导致在暂时不可用的AZ中出现数据缺口。 当vmagent以多租户模式运行时，这些问题得到了解决。当特定AZ暂时不可用时，vmagent会缓冲必须发送到该AZ的数据。缓冲区存储在磁盘上。一旦AZ变得可用，缓冲的数据就会被发送到AZ。","多租户#多租户":"","安全#安全":"一般的安全建议：\n所有 VictoriaMetrics 集群组件都必须在受保护的私有网络中运行，并且不能被互联网等不受信任的网络直接访问。 外部客户端必须通过身份验证代理（例如 vmauth 或 vmgateway）访问 vminsert 和 vmselect。 为了保护身份验证令牌不被窃听，身份验证代理必须仅通过 https 接受来自不受信任网络的身份验证令牌。 建议对不同的租户使用不同的身份验证令牌，以减少某些租户的身份验证令牌被泄露时造成的潜在损害。 在 vminsert 和 vmselect 之前配置身份验证代理时，最好使用允许的 API 接口白名单，同时禁止访问其他接口。这可以最大限度地减少攻击面。 也可以参考 security recommendation for single-node VictoriaMetrics 和 the general security page at VictoriaMetrics website.","容量规划#容量规划":"根据我们的案例研究，与竞争解决方案（Prometheus、Thanos、Cortex、TimescaleDB、InfluxDB、QuestDB、M3DB）相比，VictoriaMetrics 在生产工作负载上使用的 CPU、RAM 和存储空间更少。\n每种节点类型（vminsert、vmselect 和 vmstorage）都可以在最合适的硬件上运行。集群容量随可用资源线性扩展。每种节点类型所需的 CPU 和 RAM 数量高度依赖于工作负载 - 活动时间序列的数量、序列流失率、查询类型、查询 qps 等。建议为您的生产工作负载设置一个测试 VictoriaMetrics 集群，并迭代扩展每个节点的资源和每个节点类型的节点数量，直到集群稳定下来。建议为集群设置监控。它有助于确定集群设置中的瓶颈。还建议遵循故障排除文档。\n给定保留期所需的存储空间（保留期通过 vmstorage 上的 -retentionPeriod 命令行标志设置）可以根据测试运行中的磁盘空间使用情况推断出来。例如，如果在生产工作负载上进行一天的测试运行后存储空间使用量为 10GB，那么在 -retentionPeriod=100d（100 天保留期）的情况下，至少需要 10GB*100=1TB 的磁盘空间。可以使用 VictoriaMetrics 集群的官方 Grafana 大盘监控存储空间使用情况。\n建议保留以下数量的备用资源：\n所有节点类型均有 50% 的可用 RAM，用于降低工作负载暂时激增期间出现 OOM（内存不足）崩溃和速度减速的概率。 所有节点类型均有 50% 的备用 CPU，以降低工作负载临时激增期间出现速度变慢的可能性。 vmstorage 节点的 -storageDataPath 命令行参数指向的目录中至少有 20% 的可用存储空间。另请参阅 vmstorage 的 -storage.minFreeDiskSpaceBytes 命令行参数描述。 VictoriaMetrics 集群的一些容量规划技巧：\n多副本可将集群所需的资源量增加多达 N 倍，其中 N 是副本数。这是因为 vminsert 将每个摄取样本的 N 个副本存储在不同的 vmstorage 节点上。查询期间，vmselect 会对这些副本进行重复数据删除。数据持久性最具成本和性能的解决方案是依赖高可用磁盘（例如 Google Compute 持久磁盘），而不是使用 VictoriaMetrics 级别的复制机制。 建议构建一个由众多小型 vmstorage 节点组成的集群，而非少数大型 vmstorage 节点。这样，在进行维护操作（如升级、配置更改或迁移）时，若部分 vmstorage 节点临时离线，集群更有可能保持高可用性和稳定性。举例来说，若一个集群拥有10个vmstorage节点，其中一个节点临时不可用，其余9个节点的负载将增加约11%（即1/9）。而如果集群仅由3个vmstorage节点构成，单个节点离线时，其余两个节点的负载将激增50%（即1/2）。在这种情况下，剩余节点可能无法承受额外的工作负载，导致集群过载，进而影响可用性和稳定性。 增加每个vmstorage节点的RAM和CPU资源，或者添加新的vmstorage节点，可以提高集群对活跃时间序列的处理能力。 提高每个vmselect节点的CPU资源可以降低查询延迟，因为每个传入查询都由单个vmselect节点处理。vmselect节点的可用CPU核心数越多，其处理查询中涉及的时间序列的性能就越好。 如果集群需要高速处理传入查询，可以通过添加更多vmselect节点来提高其处理能力，这样传入查询就可以分散到更多的vmselect节点上。 默认情况下，vminsert会压缩发送给vmstorage的数据，以减少网络带宽使用。压缩过程会消耗vminsert节点额外的CPU资源。如果vminsert节点的CPU资源有限，可以通过在vminsert节点上传递-rpc.disableCompression命令行标志来禁用压缩。 默认情况下，vmstorage在查询期间会压缩发送给vmselect的数据，以减少网络带宽使用。压缩过程会消耗vmstorage节点额外的CPU资源。如果vmstorage节点的CPU资源有限，可以通过在vmstorage节点上传递-rpc.disableCompression命令行参数来禁用压缩。 也可以参阅资源使用限制文档。","性能分析#性能分析":"All the cluster components provide the following handlers for profiling:\nhttp://vminsert:8480/debug/pprof/heap 内存剖析和http://vminsert:8480/debug/pprof/profile CPU 剖析 http://vmselect:8481/debug/pprof/heap 内存剖析和http://vmselect:8481/debug/pprof/profile CPU 剖析 http://vmstorage:8482/debug/pprof/heap 内存剖析和http://vmstorage:8482/debug/pprof/profile CPU 剖析 从vmstorage收集CPU剖析示例命令（使用 vmstorage 的 hostname 替换掉 0.0.0.0）：\nCopycurl http://0.0.0.0:8482/debug/pprof/profile \u003e cpu.pprof 从 vminsert 收集内存剖析实例命令（使用 vminsert 的 hostname 替换掉 0.0.0.0）：\nCopycurl http://0.0.0.0:8480/debug/pprof/heap \u003e mem.pprof 从安全角度来看，共享收集的剖析是安全的，因为它们不包含敏感信息。","架构概览#架构概览":"","源码构建#源码构建":"","监控#监控":"所有集群组件均在 -httpListenAddr 命令行参数中设置的 TCP 端口上的 /metrics 页面上以 Prometheus 兼容格式公开各种指标。默认情况下，使用以下 TCP 端口：\nvminsert - 8480 vmselect - 8481 vmstorage - 8482 建议使用 vmagent 或 Prometheus 以从所有集群组件中抓取 /metrics 页面，这样就可以使用 VictoriaMetrics 集群的官方 Grafana 大盘或 VictoriaMetrics 集群大盘来监控和分析它们。这些仪表板上的图表包含有用的提示 - 将鼠标悬停在每个图表左上角的 i 图标上即可阅读。\n建议通过此配置在 vmalert 或 Prometheus 中设置告警。更多详细信息请参阅文章 VictoriaMetrics 监控。 基数限制。","资源使用限制#资源使用限制":"默认情况下，VictoriaMetrics 的集群组件会根据典型工作负载的最佳资源使用情况进行调整。某些工作负载可能需要细粒度的资源使用限制。在这种情况下，以下命令行参数可能会有用：\n-memory.allowedPercent 和 -memory.allowedBytes 限制所有的 VictoriaMetrics 集群组件里的各种内部 cache 会使用的内存用量 —— vminsert, vmselect 和 vmstorage。请注意，VictoriaMetrics 组件可能会占用更多内存，因为这些参数并不限制其他地方消耗的内存，比如可能是查询请求消耗的。 -search.maxMemoryPerQuery 限制 vmselect 实例执行一次查询请求所使用的内存总量。申请超限的内存会被拒绝。查询大量时间序列的重查询，可能会超查询内存限制一点点。并发查询的内存总限制差不多等于-search.maxMemoryPerQuery 和 -search.maxConcurrentRequests 的乘机。 vmselect组件的-search.maxUniqueTimeseries 参数限制了单词查询能够查询并计算多少个独立时间序列。vmselect 会将该限制参数传递给 vmstorage 组件，vmstorage 在内存中记录每个查询请求检索到的时间序列的元信息，并消耗一定的 CPU 来处理检索到的时间序列。这意味着在 vmstorage 中，单个查询可使用的最大内存使用量和 CPU 使用量与 -search.maxUniqueTimeseries 成比例。 vmselect的-search.maxQueryDuration 参数限制了一个查询的执行时间。如果一个查询耗时超出了指定的限制，就会被取消执行。这可以使vmselect 和 vmstorage 遇到非预期的重查询时，避免 CPU 和 内存的重度消耗。 vmselect和vmstorage的-search.maxConcurrentRequests 参数限制单个vmselect和vmstorage实例可以同时执行多少个查询。更大的并发数通常意味着需要消耗更多的内存。比如，如果一个查询在执行期间需要额外消耗 100MiB 的内存，那么100个并行的查询就需要100 * 100 MiB = 10 GiB的额外内存。所以最好限制一下请求并发数，这样会把超出并发限制的请求挂起排队。vmselect和vmstorage同时提供了-search.maxQueueDuration命令行参数来限制请求排队的最长时间。同时也看下vmselect的-search.maxMemoryPerQuery参数。 vmselect和vmstorage的-search.maxQueueDuration 限制查询因超出并发数限制而挂起等待的最长时间。上面提到了-search.maxConcurrentRequests参数指定了允许的最大并发数量。 vmselect的-search.maxSamplesPerSeries 限制了对于一个时间序列能够处理的最大原始样本值的数量。在执行查询时，vmselect会顺序第处理每个检索到的时间序列中的原始样本值。它将每个时间序列的指定时间范围内的原始样本解压到内存，然后对齐执行rollup函数。-search.maxSamplesPerSeries .可以限制内存用量，以免vmselect处理的start-end时间范围内每个时间序列都包含上一条原始样本数据。 vmselect的-search.maxSamplesPerQuery限制一个查询最大处理的原始样本数。可以限制 vmselect遇到重查询时的CPU用量。 -search.maxPointsPerTimeseries限制了范围查询(query range)中每个时间序列最终返回的最多数据点数。 -search.maxPointsSubqueryPerTimeseries 限制了每个子查询执行时所产生的最大数据点数。 -search.maxSeriesPerAggrFunc 限制一次查询由MetricsQL聚合函数所产生的最大时间序列数量。 vmselect的-search.maxSeries参数限制/api/v1/series接口最多返回的series数量。这个接口主要用于 Grafana 自动补全 Metric 名称，Label 名称 和 Label 值。如果数据库中因为高基数存储了大量的时间序列，那么这个接口会消耗vmstorage和vmselect的大量CPU。所以在这种情况下需要使用-search.maxSeries来限制下CPU和内存的过度消耗。 -search.maxTagKeys at vmstorage limits the number of items, which may be returned from /api/v1/labels. This endpoint is used mostly by Grafana for auto-completion of label names. Queries to this endpoint may take big amounts of CPU time and memory at vmstorage and vmselect when the database contains big number of unique time series because of high churn rate. In this case it might be useful to set the -search.maxTagKeys to quite low value in order to limit CPU and memory usage. vmstorage的-search.maxTagKeys限制/api/v1/labels接口返回的label总数量。这个接口主要用于 Grafana 自动补全 Label 名称。如果数据库中因为高基数存储了大量的时间序列，那么这个接口会消耗vmstorage和vmselect的大量CPU。所以在这种情况下需要使用-search.maxTagKeys来限制下CPU和内存的过度消耗。 vmstorage的-search.maxTagKeys限制/api/v1/label/…/values接口返回的label值总数量。这个接口主要用于 Grafana 自动补全 Label 值。如果数据库中因为高基数存储了大量的时间序列，那么这个接口会消耗vmstorage和vmselect的大量CPU。所以在这种情况下需要使用-search.maxTagValues来限制下CPU和内存的过度消耗。 vmstorage的-storage.maxDailySeries可以用于限制每天最多创建多少个新时间序列。见限制文档。 vmstorage的-storage.maxHourlySeries可以用于限制活跃时间序列的数量。见限制文档。 也可以参考容量规划文档和vmagent的基数显示器。","运维#运维":"架构概览 VictoriaMetrics 集群版本由以下几个服务组成：\nvmstorage - 存储原始数据，并返回在给定时间范围内针对给定 Label 筛选器查询的数据。 vminsert - 接受摄入的数据，并 根据对度量名称及其所有标签的一致散列，将数据分散到 vmstorage 节点中 vmselect - 通过从所有已配置的 vmstorage 节点获取所需数据来执行接收到的查询请求。 每项服务都可独立扩展，并可在最合适的硬件上运行。 vmstorage 节点之间互不相识，互不通信，也不共享任何数据。 这是一种共享无架构 。 它提高了集群的可用性，简化了集群维护和集群扩展。\n多租户 VictoriaMetrics集群支持多个隔离的租户（即命名空间）。租户通过accountID或accountID:projectID进行标识，这些标识符被置于请求URL中。详情请参阅这些文档。\n关于VictoriaMetrics中租户的一些事实：\n每个accountID和projectID均由一个任意的32位整数标识，范围为[0..2^32)。如果projectID缺失，则自动分配为0。预期其他关于租户的信息，如身份验证令牌、租户名称、限制、会计等，存储在一个独立的关系数据库中。该数据库必须由位于VictoriaMetrics集群前端的独立服务进行管理，例如vmauth或vmgateway。如果您需要此类服务的协助，请联系我们。\n当第一个数据点被写入给定的租户时，租户会被自动创建。\n所有租户的数据均匀分布在可用的vmstorage节点之间。这保证了当不同租户拥有不同数量的数据和不同的查询负载时，vmstorage节点之间的负载也是均匀的。\n数据库的性能和资源使用情况并不取决于租户的数量，而主要取决于所有租户中活跃时间序列的总数。如果一个时间序列在过去的一小时中至少接收了一个样本，或者在过去的一小时中被查询访问过，那么它就被认为是活跃的。\nVictoriaMetrics不支持在单一请求中查询多个租户。\n已注册租户的列表可以通过http://\u003cvmselect\u003e:8481/admin/tenants URL获取。请参阅这些文档。\nVictoriaMetrics通过指标公开了各种按租户划分的统计数据——请参阅这些文档。\n也可以看下通过 labels 实现多租户。\n通过 labels 实现多租户 vminsert可以从多个租户通过一个特殊的多租户端点http://vminsert:8480/insert/multitenant/\u003csuffix\u003e接收数据，其中可以替换为从此列表中获取数据的任何受支持的\u003csuffix\u003e。在这种情况下，AccountID 和ProjectID是从传入样本的可选 vm_account_id 和 vm_project_id 标签中获取的。如果 vm_account_id 或 vm_project_id 标签缺失或无效，则相应的AccountID 或ProjectID 将设置为 0。在将样本转发到vmstorage之前，会自动从样本中删除这些Label。例如，如果将以下样本写入 http://vminsert:8480/insert/multitenant/prometheus/api/v1/write：\nhttp_requests_total{path=\"/foo\",vm_account_id=\"42\"} 12 http_requests_total{path=\"/bar\",vm_account_id=\"7\",vm_project_id=\"9\"} 34 然后http_requests_total｛path=“/foo”｝12将被存储在租户accountID=42，projectID=0中，而http_requests_total{path=“/bar”｝34将被存储到租户accountID=7，projectID=9中。\nvm_account_id和vm_project_id labels 是在通过-rebelConfig命令行标志应用 relabeling 集后提取的，因此可以在此阶段设置这些 label。\n安全提示：建议将对多租户端点的访问限制为仅限可信源，因为不可信源可能会通过向任意租户写入不需要的样本来破坏每个租户的数据。\n二进制 集群版本的编译二进制文件可在发布页面的 assets 部分中找到。另请参阅包含单词“集群”的档案。\n集群版本的 Docker 镜像可在此处找到：\nvminsert - https://hub.docker.com/r/victoriametrics/vminsert/tags vmselect - https://hub.docker.com/r/victoriametrics/vmselect/tags vmstorage - https://hub.docker.com/r/victoriametrics/vmstorage/tags 源码构建 集群版本的源代码可在cluster分支中获取。\n生产环境构建 无需在主机系统上安装 Go，因为二进制文件是在 Go 的官方 docker 容器内构建的。这允许可重现的构建。因此，安装 docker 并运行以下命令：\nmake vminsert-prod vmselect-prod vmstorage-prod 生产二进制文件内置于静态链接二进制文件中。它们被放入带有 -prod 后缀的 bin 文件夹中：\n$ make vminsert-prod vmselect-prod vmstorage-prod $ ls -1 bin vminsert-prod vmselect-prod vmstorage-prod 开发环境构建 安装Go，最低支持版本是 Go1.18。 从仓库根目录运行 make。它应该构建 vmstorage、vmselect 和 vminsert 二进制文件并将它们放入 bin 文件夹中。 构建 docker 镜像 执行 make package命令，会在本地构建下面几个 docker 镜像：\nvictoriametrics/vminsert:\u003cPKG_TAG\u003e victoriametrics/vmselect:\u003cPKG_TAG\u003e victoriametrics/vmstorage:\u003cPKG_TAG\u003e \u003cPKG_TAG\u003e 是根据仓库中的源码自动生产的 image tag。\u003cPKG_TAG\u003e 可以使用环境变量来指定，比如：PKG_TAG=foobar make package.\n默认情况下，为了提高可调试性，image 是在 alpine image 之上构建的。可以通过 \u003cROOT_IMAGE\u003e 环境变量设置，在任何其他基础镜像之上构建镜像。例如，以下命令在临时镜像之上构建镜像：\nROOT_IMAGE=scratch make package 运维 ","通过-labels-实现多租户#通过 labels 实现多租户":"","部署集群#部署集群":"一个集群至少包含下面几项：\n一个 vmstorage 节点，需要指定 -retentionPeriod 和 -storageDataPath 参数 一个 vminsert 节点，需要指定 -storageNode=\u003cvmstorage_host\u003e 一个 vmselect 节点，需要指定 -storageNode=\u003cvmstorage_host\u003e 建议每个服务至少运行两个实例，以实现高可用性。在这种情况下，当单个节点暂时不可用时，群集仍可继续工作，其余节点可处理增加的工作量。在底层硬件损坏、软件升级、迁移或其他维护任务期间，节点可能会暂时不可用。\n最好运行许多小型 vmstorage 节点而不是少数大型 vmstorage 节点，因为当某些 vmstorage 节点暂时不可用时，这可以减少剩余 vmstorage 节点上的工作负载增加。\n必须在 vminsert 和 vmselect 节点前放置一个 http 负载均衡器，例如 vmauth 或 nginx。它必须根据 url 格式包含以下路由配置：\n带有 /insert 前缀的请求必须被路由到 vminsert 实例的 8480 端口数。 带有 /select 前缀的请求必须被路由到 vmselect 实例的 8481 端口数。 端口可以通过在相应节点上通过 -httpListenAddr 参数来设定。\n建议为集群配置上监控。\n下面的工具可以简化集群部署：\nAn example docker-compose config for VictoriaMetrics cluster Helm charts for VictoriaMetrics Kubernetes operator for VictoriaMetrics 可以在单个主机上手动设置一个玩具集群。在这种情况下，每个集群组件 - vminsert、vmselect 和 vmstorage - 必须使用 -httpListenAddr 命令行参数指定不同的端口。此参数指定用于接受用于监控和Profiling http 请求的 http 地址。vmstorage 节点必须具有以下附加命令行参数的不同值，以防止资源使用冲突：\n-storageDataPath - 每个 vmstorage 实例都不行有一个专用的数据存储路径。 -vminsertAddr - 每个 vmstorage 实例必须监听一个 tcp 地址，用来接受 vminsert 发送过来的数据。 -vmselectAddr - 每个 vmstorage 实例必须监听一个 tcp 地址，用来处理 vmselect 发送过来的查询请求。 环境变量 所有的 VictoriaMetrics 组件都可以在命令行参数中使用%{ENV_VAR}语法来引用环境变量。比如，如果 VictoriaMetrics 启动的时候存在环境变量METRICS_AUTH_KEY=top-secret ，那么-metricsAuthKey=%{METRICS_AUTH_KEY} 参数会自动转换成 -metricsAuthKey=top-secret。这个转换是 VictoriaMetrics 内部自己完成的。\nVictoriaMetrics 在启动的时候会递归式的对%{ENV_VAR} 进行环境变量引用转换。比如，当存在环境变量 BAR=a%{BAZ} 和 BAZ=bc时，FOO=%{BAR} 环境变量会被转换为 FOO=abc 。\n所有的 VictoriaMetrics 组件都支持通过上述的环境变量方式来设置参数，前提是：\n必须使用-envflag.enable 参数开启该特性。 命令行参数中的 . 必须用下划线_替换 (比如 -insert.maxQueueDuration \u003cduration\u003e 对应的环境变量是 insert_maxQueueDuration=\u003cduration\u003e)。 对于可重复的指定的参数，可用逗号,分隔符进行链接。 (比如 -storageNode \u003cnodeA\u003e -storageNode \u003cnodeB\u003e 对应的环境变量是 storageNode=\u003cnodeA\u003e,\u003cnodeB\u003e)。 可以使用 -envflag.prefix 参数来指定环境变量前缀，例如使用了 -envflag.prefix=VM_参数，那么环境变量名就都必须以 VM_ 开头。 ","问题排查#问题排查":"请看问题排查文档。","集群可用性#集群可用性":"VictoriaMetrics 集群架构优先考虑可用性而不是数据一致性。这意味着，如果集群的某些组件暂时不可用，集群仍可用于数据提取和数据查询。\n如果满足以下条件，VictoriaMetrics 集群将保持可用：\nHTTP 负载平衡器必须停止将请求路由到不可用的 vminsert 和 vmselect 节点（vmauth 停止将请求路由到不可用的节点）。 集群中必须至少有一个 vminsert 节点可用于处理数据提取工作负载。其余可用的的 vminsert 节点必须具有足够的计算能力（CPU、RAM、网络带宽）来处理当前的数据写入工作负载。如果其余可用的 vminsert 节点没有足够的资源来处理数据提取工作负载，则数据提取期间可能会出现任意延迟。有关更多详细信息，请参阅容量规划和集群扩缩容文档。 集群中必须至少有一个 vmselect 节点可用于处理查询工作负载。其余活动的 vmselect 节点必须具有足够的计算能力（CPU、RAM、网络带宽、磁盘 IO）来处理当前的查询工作负载。如果剩余的活动 vmselect 节点没有足够的资源来处理查询工作负载，则在查询处理期间可能会发生任意故障和延迟。有关更多详细信息，请参阅容量规划和集群扩缩容文档。 集群中必须至少有一个 vmstorage 节点可用，以接受新提取的数据和处理传入的查询。剩余的活动 vmstorage 节点必须具有足够的计算能力（CPU、RAM、网络带宽、磁盘 IO、可用磁盘空间）来处理当前工作负载。如果剩余的活动 vmstorage 节点没有足够的资源来处理查询工作负载，则在数据提取和查询处理期间可能会发生任意故障和延迟。有关更多详细信息，请参阅容量规划和集群扩缩容文档。 当某些 vmstorage 节点不可用时，集群的工作方式如下：\nvminsert 将新写入的数据从不可用的 vmstorage 节点重新路由到剩余的健康 vmstorage 节点。如果健康的 vmstorage 节点具有足够的 CPU、RAM、磁盘 IO 和网络带宽来处理新增加的数据量，就可确保新写入的数据得以正确保存。vminsert 会在健康的 vmstorage 节点之间均匀分布额外的数据，以便均匀分布这些节点上增加的负载。 只要有一个 vmstorage 节点可用，vmselect 将继续提供查询。它会将其余健康 vmstorage 节点提供的查询的响应标记为部分响应，因为此类响应可能会丢失存储在暂时不可用的 vmstorage 节点上的历史数据。每个部分 JSON 响应都包含“isPartial”：true 选项。如果您更喜欢一致性而不是可用性，请使用 -search.denyPartialResponse 命令行参数运行 vmselect 节点。在这种情况下，只要有一个 vmstorage 节点不可用，vmselect 将返回错误。另一个选项是在vmselect的查询请求中加上deny_partial_response=1 参数。 vmselect 还接受 -replicationFactor=N 命令行参数。此参数表示 vmselect 在查询期间如果少于 -replicationFactor 个 vmstorage 节点不可用则返回完整响应，因为它假定剩余的 vmstorage 节点包含完整数据。有关详细信息，请参阅这些文档。\nvmselect 不会为返回原始数据点的 API 处理程序提供部分响应 - /api/v1/export*接口，因为用户通常希望这些数据始终是完整的。\n数据副本可用于提高存储耐用性。有关详细信息，请参阅这些文档。","集群扩缩容#集群扩缩容":"集群的性能和容量有两种提升方式：\n为先有的实例节点增加计算资源（CPU，内存，磁盘IO，磁盘空间，网络带宽），即垂直扩容。 为集群增加更多的实例节点，即水平扩容。 一些扩容建议：\n向现有 vmselect 节点添加更多 CPU 和 RAM 可提高重度查询的性能，这些查询会处理大量时间序列和大量原始样本。请参阅本文，了解如何检测和优化重度查询。 添加更多 vmstorage 节点以增加集群可以处理的活动时间序列的数量。这还会提高高流失率时间序列的查询性能。集群稳定性也会随着 vmstorage 节点数量的增加而提高，因为当某些 vmstorage 节点不可用时，活动 vmstorage 节点需要处理的额外工作负载较少。 向现有 vmstorage 节点添加更多 CPU 和 RAM 会增加集群可以处理的活动时间序列的数量。与向现有 vmstorage 节点添加更多 CPU 和 RAM 相比，添加更多 vmstorage 节点是更好的选择，因为 vmstorage 节点数量越多，集群稳定性就越高，并且会提高高流失率时间序列的查询性能。 添加更多 vminsert 节点会增加最大可能的数据提取速度，因为提取的数据可能会在更多数量的 vminsert 节点之间分配。 添加更多 vmselect 节点会增加最大可能的查询率，因为传入的并发请求可能会在更多 vmselect 节点之间分配。 新增 vmstorage 节点的步骤：\n启动具有与集群中现有节点相同的 -retentionPeriod 的新 vmstorage 节点。 平滑启动 vmselect 节点，并在-storageNode 参数中把 \u003cnew_vmstorage_host\u003e加上。 平滑启动 vminsert 节点，并在-storageNode 参数中把 \u003cnew_vmstorage_host\u003e加上。 ","高可用#高可用":"如果数据库在部分组件暂时不可用时仍能接收新数据并处理传入查询，则被认为是高可用的。VictoriaMetrics集群符合这一定义，请参阅集群可用性文档。\n建议在具有高带宽、低延迟和低错误率的同一子网络中运行单个集群的所有组件，这可以提高集群的性能和可用性。不建议将单个集群的组件分布在多个可用区（AZ）中，因为跨AZ网络通常带宽较低、延迟较高、错误率也较高，相比之下，单个AZ内的网络表现更好。\n如果你需要跨多个AZ的设置，建议在每个AZ中运行独立的集群，并在这些集群前设置vmagent，以便它能将传入数据复制到所有集群中，详情请参阅相关文档。此外，可以配置额外的vmselect节点，以便根据这些文档从多个集群中读取数据。"},"title":"集群版本"},"/docs/ops/disk-space/":{"data":{"":"","font-stylecolorrgb2165749不要删-seriesfont#\u003c!-- raw HTML omitted --\u003e不要删 Series\u003c!-- raw HTML omitted --\u003e":"磁盘空间属于前期规划的，这种事故主要是因为前期规划失误。只能临时补救。具体有如下集中方法\n强行 merge 让 vmstorage 执行 merge，会将多个 part merge 成一个 part，减少磁盘空间。有数据持续写入的 partition 会自动触发 merge，不要去强制 merge。所以只对历史 partition 进行 merge。\n## 参数 partition_prefix 指定 partition，partition 的名字在 $DATA/data/small 下可以看到 curl 'http://localhost:8442/internal/force_merge?partition_prefix=2022_01' 效果如图所示：\n磁盘使用率上升是因为 merge 过程创建新的 part 来 merge 老的多个 parts。突然下降代表 merge 结束，删掉老的 parts。\n整个 merge 过程，CPU 和 Memory 几乎没有什么影响。merge 的耗时数个小时，跟数据量大小有关。\n等待 如上所述，系统对多个 part 进行 merge 时，会临时使用一定的磁盘空间，合并后将老的 part 删除就会释放。\n因此在磁盘不足时，可查看 vmstorage 是否正在执行 merge，如果是，可以等待其执行完毕。一次 merge 可能会执行是个小时甚至数天。\n删除 cache 如果 cache 目录比较大，可以删除。但通常不会太大。\n强制删除历史 partition 删除历史数据是最直接的。\n先 stop 掉 vmstorage 组件。 删除 $DATA/data/{big,small}/YYYY_MM 目录。 启动 vmstorage。 只有一个 partition ? 也就是这一个月而数据磁盘都扛不住，那么只能删除 part。part 的文件夹名称，包含着这个 part 的时间范围。可以根据这些数据删除历史 part。\n./small/2022_02/93109700891_21411093_20220201043320.000_20220204141544.799_16CF806E39D42DF8 修改 retention 直接修改 vmstorage 的运行参数，让 retention 更短。然后重启，让 vmstorage 自己去删过期的 partition 也是OK的。\n不过这就是永久生效了，而不是临时删下历史数据清理磁盘。\n不要删 Series 因为删除 series 会带来额外很大的开销，让系统不稳定。而且它不会释放多少空间。","修改-retention#修改 retention":"","删除-cache#删除 cache":"","只有一个-partition-#只有一个 partition ?":"","强制删除历史-partition#强制删除历史 partition":"","强行-merge#强行 merge":"","等待#等待":""},"title":"如何处理磁盘空间不足"},"/docs/ops/single/":{"data":{"":"","其他#其他":"压测 请注意，供应商（包括VictoriaMetrics在内）在进行此类测试时往往存在偏见。例如，他们会试图突出自己产品的优点，同时强调竞争产品的缺点。因此，我们鼓励用户和所有独立第三方对他们正在评估的各种产品进行生产环境下的基准测试，并公布结果。\n作为参考，请查看VictoriaMetrics团队进行的基准测试。还请查看使用node_exporter指标运行摄取基准测试的helm chart。\nProfiling VictoriaMetrics提供了用于收集以下 Go profiles 内容的处理程序 :\n内存配置文件。可以使用以下命令收集（如有需要，请将0.0.0.0替换为主机名）： curl http://0.0.0.0:8428/debug/pprof/heap \u003e mem.pprof CPU配置文件。可以使用以下命令收集（如有需要，请将0.0.0.0替换为主机名）： curl http://0.0.0.0:8428/debug/pprof/profile \u003e cpu.pprof 收集 CPU 个人资料的命令会在等待 30 秒后返回。 可以使用 go tool pprof 分析收集到的个人资料。从安全角度来看，共享这些收集到的个人资料是安全的，因为它们不包含敏感信息。\n常见问题建议 建议在不需要调整标志值的情况下使用默认命令行标志值（即不要显式设置它们）。 建议在故障排除过程中检查日志，因为它们可能包含有用的信息。 建议从此页面升级到最新可用版本，因为遇到的问题可能已经在那里修复了。 建议至少保留50%的CPU、磁盘IO和RAM资源作为备用，这样VictoriaMetrics就可以处理工作负载中的短暂峰值而无性能问题。 VictoriaMetrics需要空闲磁盘空间将数据文件合并成更大的文件。当没有足够的剩余空间时，它可能会变慢。因此，请确保-storageDataPath目录至少有20%的可用空间。剩余可用空间量可以通过vm_free_disk_space_bytes指标进行监控。存储在磁盘上的数据总大小可以通过vm_data_size_bytes指标之和进行监控。还可以查看vm_merge_need_free_disk_space指标，如果由于缺乏免费磁盘空间而无法启动后台合并，则其值将设置为大于0.该值显示每月分区数，在拥有更多免费磁盘空间时将启动后台合并。 VictoriaMetrics会将传入数据缓冲到内存中，并在几秒钟后将其刷新到持久存储中。这可能会导致以下“问题”： 插入后的几秒钟数据才能进行查询。可以通过请求/internal/force_flush http处理程序将内存缓冲区刷新到可搜索部分。此处理程序主要用于测试和调试目的。 在非正常关闭（即OOM、kill -9或硬件重置）时，最后几秒钟插入的数据可能会丢失。-inmemoryDataFlushInterval命令行标志允许控制将内存中的数据刷新到持久存储的频率。有关更多详细信息，请参阅存储文档和本文。 如果VictoriaMetrics工作缓慢，并且每秒摄取100K个数据点占用超过一个CPU核心，则很可能是当前RAM量对于太多活动时间序列来说不足够了。VictoriaMetrics公开了vm_slow_*指标，例如vm_slow_row_inserts_total和vm_slow_metric_name_loads_total，它们可以用作RAM数量不足的指示器。建议增加节点上VictoriaMetrics所使用的RAM量以改善摄取和查询性能。 如果同一度量标签顺序随时间变化（例如metric{k1=\"v1\",k2=\"v2\"}可能变为metric{k2=\"v2\",k1=\"v1\"}），则建议使用-sortLabels命令行标志运行VictoriaMetrics，以减少内存使用和CPU使用率。 VictoriaMetrics优先考虑数据摄取而不是数据查询。因此，如果没有足够的资源进行数据摄取，则数据查询可能会显著减慢。 如果VictoriaMetrics由于磁盘错误导致某些部分损坏而无法工作，则只需删除带有损坏部分的目录即可。在VictoriaMetrics未运行时，安全地删除\u003c-storageDataPath\u003e/data/{big,small}/YYYY_MM目录下的子目录可以恢复VictoriaMetrics，但会丢失已存储在被删除损坏部分中的数据。将来将创建vmrecover工具以自动从此类错误中恢复。 如果您在图表上看到间隙，请尝试通过向/internal/resetRollupResultCache发送请求来重置缓存。如果这样可以消除图表上的间隙，则很可能是将早于-search.cacheTimestampOffset时间戳的数据。 如果您从InfluxDB或TimescaleDB切换过来，可能需要设置-search.setLookbackToStep命令行标志。这将抑制VictoriaMetrics使用的默认间隙填充算法-默认情况下，它假设每个时间序列是连续的而不是离散的，因此会用固定间隔填补真实样本之间的空白。 通过cardinality explorer和/api/v1/status/tsdb端点可以确定导致高基数或高变动率的指标和标签。 如果要在VictoriaMetrics中记录新时间序列，请传递-logNewSeries命令行标志。 VictoriaMetrics通过-maxLabelsPerTimeseries命令行标志限制每个度量指标的标签数量。这可以防止摄入具有太多标签的指标。建议监视vm_metrics_with_dropped_labels_total度量以确定是否需要根据工作负载调整-maxLabelsPerTimeseries。 如果您在VictoriaMetrics中存储Graphite指标（如foo.bar.baz），则可以使用{__graphite__=\"foo.*.baz\"}过滤器选择此类指标。详细信息请参阅相关文档。 在数据摄取期间，VictoriaMetrics会忽略NaN值。 更多参见故障排查文档。","安装部署#安装部署":"安装 要快速尝试VictoriaMetrics，只需下载VictoriaMetrics可执行文件或Docker镜像，并使用所需的运行参数启动它。还可以参考快速开始指南获取更多信息。\n此外，也可以通过以下方法来安装VictoriaMetrics：\nHelm charts Kubernetes operator 安装集群版本的 Ansible Role（官方） 安装集群版本的 Ansible Role（社区） 安装单机版的 Ansible Role（社区） Snap package 运行 下面的几个运行参数是最常用的：\n-storageDataPath：VictoriaMetrics 把所有的数据都保存在这个目录。默认的路径是当前工作目录中的victoria-metrics-data 子目录。 -retentionPeriod：数据的保留时间。历史的数据会被自动清理删除。默认的保留时间是 1 个月。最小的保留时间是 1 天（即 24 小时）。点击了解更多详情。 其他的运行参数，基本使用默认值就可以了，所以只有在有特殊需求的时候再修改他们就行。用-help 参数看下所有可用参数及他们描述和默认值。\n正因 VictoriaMetrics 的配置参数都是通过命令行传递的，所以它不支持动态修改配置。如果要修改配置就只能用新的命令行对 VictoriaMetrics 进行重启。步骤如下：\n向VictoriaMetrics进程发送SIGINT信号以正常停止它。请参阅如何向进程发送信号。 等待进程停止。这可能需要几秒钟时间。 启动已升级的VictoriaMetrics。 下面的几个文档，对初始化 VictoriaMetrics 可能会有些帮助：\nHow to set up scraping of Prometheus-compatible targets How to ingest data to VictoriaMetrics How to set up Prometheus to write data to VictoriaMetrics How to query VictoriaMetrics via Grafana How to query VictoriaMetrics via Graphite API How to handle alerts VictoriaMetrics 默认使用 8428 端口处理 Prometheus 查询请求。建议为 VictoriaMetrics 搭建监控。\n环境变量 所有的 VictoriaMetrics 组件都支持在命令行参数中使用语法%{ENV_VAR}引用环境变量。比如，\n在 VictoriaMetrics 启动时，如果环境变量中存在METRICS_AUTH_KEY=top-secret，那么-metricsAuthKey=%{METRICS_AUTH_KEY}就会自动转换成metricsAuthKey=top-secret。这个转换是 VictoriaMetrics 自动做的。\nVictoriaMetrics 会递归的转换环境变量。比如我们有 2 个环境变量 BAR=a%{BAZ} 和 BAZ=bc。那对于 FOO=%{BAR} 就会自动被转换成FOO=abc。\n此外，所有的VictoriaMetrics组件都允许根据以下规则通过环境变量设置参数：\nAdditionally, all the VictoriaMetrics components allow setting flag values via environment variables according to these rules:\n-envflag.enable 参数必须开启。 参数名中的每一个.字符都会被用_替代（比如-insert.maxQueueDuration \u003cduration\u003e 会被转换成insert_maxQueueDuration=\u003cduration\u003e）。 对于重复参数，有一个替代方式就是用逗号,把多个参数值链接起来（比如 -storageNode \u003cnodeA\u003e -storageNode \u003cnodeB\u003e 会被转换成 storageNode=\u003cnodeA\u003e,\u003cnodeB\u003e）。 环境变量的前缀可以通过参数 -envflag.prefix 设定. 比如，如果-envflag.prefix=VM_, 那么所有环境变量名都要以 VM_开头。 使用 Snap 包 VictoriaMetrics 的 Snap 包在 这里 可以找到。\n可以使用以下命令设置Snap软件包的命令行参数：\necho 'FLAGS=\"-selfScrapeInterval=10s -search.logSlowQueryDuration=20s\"' \u003e $SNAP_DATA/var/snap/victoriametrics/current/extra_flags snap restart victoriametrics 不要修改 -storageDataPath 的参数值， 因为 snap 包对宿主机的文件系统有访问限制。\n可以使用一个文本编辑器修改采集配置：\nvi $SNAP_DATA/var/snap/victoriametrics/current/etc/victoriametrics-scrape-config.yaml 上面步骤完成后， 使用命令 curl 127.0.0.1:8428/-/reload触发一下配置中心加载。\n升级 VictoriaMetrics 除非发布说明另有说明，升级VictoriaMetrics到新版本是安全的。在升级过程中跳过多个版本也是安全的，除非发布说明另有说明。建议定期升级到最新版本，因为它可能包含重要的错误修复、性能优化或新功能。\n除非发布说明另有说明，降级到旧版本也是安全的。\n在升级/降级过程中必须执行以下步骤：\n向VictoriaMetrics进程发送SIGINT信号以正常停止它。请参阅如何向进程发送信号。 等待进程停止。这可能需要几秒钟时间。 启动已升级的VictoriaMetrics。 Prometheus在重新启动VictoriaMetrics时不会丢失数据。详细信息请参阅本文。对于vmagent也适用相同规则。\n如何构建源代码 我们建议使用发布的二进制 或者 Docker 镜像，而不是使用源代码进行构建。构建源代码一般是在你要开发一些定制化需求或者测试 BUG 修复时候才需要。\n构建开发环境 安装 Go。 要求最低版本是 Go 1.19。 在仓库的根目录运行命令 make victoria-metrics 。命令会构建 victoria-metrics 二进制然后把它放到 bin 目录中。 构建生产环境 安装 docker。 在仓库的跟目录执行命令make victoria-metrics-prod 。 命令会构建 victoria-metrics-prod 二进制，并把它放到 bin 目录中. ARM build ARM 的构建可以在树莓派或 energy-efficient ARM servers上执行。\nDevelopment ARM build Install Go. 要求最低版本是 Go 1.19。 Run make victoria-metrics-linux-arm or make victoria-metrics-linux-arm64 from the root folder of the repository. It builds victoria-metrics-linux-arm or victoria-metrics-linux-arm64 binary respectively and puts it into the bin folder. Production ARM build Install docker. Run make victoria-metrics-linux-arm-prod or make victoria-metrics-linux-arm64-prod from the root folder of the repository. It builds victoria-metrics-linux-arm-prod or victoria-metrics-linux-arm64-prod binary respectively and puts it into the bin folder. 纯 Go 构建 (CGO_ENABLED=0) 纯Go 模式构建就是只构建没有 cgo 的依赖的 Go 代码。\n安装Go。 要求最低版本是 Go 1.19。 在仓库的根目录执行命令 make victoria-metrics-pure ，命令会构建出二进制 victoria-metrics-pure ，并把它放到 bin 目录中。 构建 Docker 镜像 执行命令 make package-victoria-metrics。 命令会在本地构建 victoriametrics/victoria-metrics:\u003cPKG_TAG\u003e 的镜像。 \u003cPKG_TAG\u003e 是使用仓库的源代码自动生成的镜像 Tag。 The \u003cPKG_TAG\u003e 可以通过命令 PKG_TAG=foobar make package-victoria-metrics手动指定。\nBase Image 用的是 alpine，但是可以使用 \u003cROOT_IMAGE\u003e环境变量选择使用其他 Base Image。比如，下面的命令就是使用 scratch 镜像作为我们的 Base Image:\nROOT_IMAGE=scratch make package-victoria-metrics 使用 docker-compose 启动 Docker-compose 能帮助我们用一条命令加速启动 VictoriaMetrics, vmagent 和 Grafana。更多详细信息请查阅这里。\nSystemd Service 参考这里将 VictoriaMetrics 设置为一个系统 Service。 一个 snap 包 可在 Ubuntu 上直接使用。\n容量规划 VictoriaMetrics在我们的案例研究中表明，与竞争解决方案（Prometheus、Thanos、Cortex、TimescaleDB、InfluxDB、QuestDB和M3DB）相比，在生产工作负载上使用更少的CPU、RAM和存储空间。\nVictoriaMetrics的容量与可用资源呈线性扩展。所需的CPU和RAM数量高度依赖于工作负载 - 活跃时间序列的数量、指标流失率、查询类型、查询每秒请求数等等。建议根据故障排除文档，为您的生产工作负载设置一个测试VictoriaMetrics，并迭代地调整CPU和RAM资源，直到其稳定运行。根据我们的案例研究，单节点VictoriaMetrics可以完美地处理以下生产工作负载：\n写入速率: 150万/秒+ 的样本数。 活跃 time series 总量: 5000万+ time series 总量: 50亿+ Time series 流失率: 每天1.5亿+ 样本总数: 10万亿 查询：200+ qps 查询延时 (P99): 1 second 根据测试运行期间的磁盘空间使用情况，可以推算出所需的存储空间（保留期通过-retentionPeriod命令行标志设置）。例如，如果在生产工作负载上进行了为期一天的测试运行后，-storageDataPath目录大小变为10GB，则对于-retentionPeriod=100d（100天保留期），至少需要10GB*100=1TB的磁盘空间。\n建议保留以下数量的备用资源：\n为了降低工作负载暂时性峰值期间内存溢出（OOM）崩溃和减速的概率，建议保留50%的空闲RAM。 为了在工作负载暂时激增期间降低减速的可能性，将50%的空闲CPU用于分配。 至少保留 -storageDataPath 命令行标志指定的目录中 20% 的可用存储空间。详见此处-storage.minFreeDiskSpaceBytes 命令行参数说明。 At least 20% of free storage space at the directory pointed by -storageDataPath command-line flag. See also -storage.minFreeDiskSpaceBytes command-line flag description here. 参见资源使用限制。\n保存期 保留期是通过 -retentionPeriod 命令行标志进行配置的，该标志后面跟着一个数字和时间单位字符 - h(小时), d(天), w(周), y(年)。如果未指定时间单位，则默认为月份。例如，-retentionPeriod=3 表示数据将被存储 3 个月然后删除。默认的保留期为一个月。最小的保留期为 24 小时或者 1 天。\n数据被分割成每月的分区，存储在\u003c-storageDataPath\u003e/data/{small,big}文件夹中。超出配置保留期限的数据分区会在新月的第一天被删除。每个分区由一个或多个数据部分组成。超出配置保留期限的数据part最终会在\n后台合并\n过程中被删除。数据part所覆盖的时间范围不受保留期单位限制。一个数据part可以涵盖几小时或几天的数据。因此，只有当完全超出配置保留期时才能删除一个数据部分。请点击\n这里\n了解更多关于分区和部件。\n给定的保留期（-retentionPeriod）对应的最大磁盘空间使用量将是（-retentionPeriod + 1）个月。例如，如果 -retentionPeriod 设置为 1，则一月份的数据将在三月一日被删除。\n在现有数据上延长保留期是安全的。如果将保留期（-retentionPeriod）设置为比之前更低的值，则配置周期外的数据最终将被删除。\nVictoriaMetrics不支持无限保留时间，但您可以指定一个任意长的持续时间，例如-retentionPeriod=100年。\n资源使用限制 默认情况下，VictoriaMetrics针对典型工作负载进行了优化，以实现最佳资源使用。某些工作负载可能需要细粒度的资源使用限制。在这些情况下，以下命令行标志可能会有用：\n-memory.allowedPercent 和 -memory.allowedBytes 限制 VictoriaMetrics 内部缓存使用的内存量。请注意，VictoriaMetrics 可能会使用更多的内存，因为这些标志不限制每个查询所需的额外内存。 -search.maxMemoryPerQuery 限制了用于处理单个查询的内存量。需要更多内存的查询将被拒绝。选择大量时间序列的重型查询可能会略微超过每个查询的内存限制。同时执行的查询的总内存限制可以估计为-search.maxMemoryPerQuery乘以-search.maxConcurrentRequests。 -search.maxUniqueTimeseries 限制了单个查询可以找到和处理的唯一时间序列的数量。VictoriaMetrics在内存中保留有关每个查询定位到的时间序列的一些元信息，并花费一些CPU时间来处理找到的时间序列。这意味着单个查询可以使用的最大内存使用量和CPU使用量与-search.maxUniqueTimeseries成比例。 -search.maxQueryDuration 限制了单个查询的持续时间。如果查询超过给定的持续时间，那么它将被取消。这样可以在执行意外繁重的查询时节省CPU和内存。 -search.maxConcurrentRequests 限制了VictoriaMetrics可以处理的并发请求数量。更多的并发请求通常意味着更大的内存使用量。例如，如果单个查询在执行过程中需要100 MiB的额外内存，则可能需要100个并发查询需要100 * 100 MiB = 10 GiB 的额外内存。因此，在达到并发限制时，最好限制并发查询的数量，并暂停进入的附加查询。VictoriaMetrics提供了-search.maxQueueDuration命令行标志来限制挂起查询的最长等待时间。另请参阅-search.maxMemoryPerQuery命令行标志。 -search.maxSamplesPerSeries 每个时间序列查询可以处理的原始样本数量。VictoriaMetrics在查询期间按顺序处理每个找到的时间序列的原始样本。它将所选时间范围内每个时间序列的原始样本解压缩到内存中，然后应用给定的汇总函数。当查询在包含数亿条原始样本的时间范围上执行时，-search.maxSamplesPerSeries命令行标志允许限制内存使用量。 -search.maxSamplesPerQuery 限制单个查询可以处理的原始样本数量。这样可以限制重负载查询的CPU使用率。 -search.maxPointsPerTimeseries 限制每个范围查询匹配时间序列返回的计算点数。 -search.maxPointsSubqueryPerTimeseries限制了在子查询评估过程中，每个匹配时间序列可以生成的计算点数。 -search.maxSeriesPerAggrFunc 限制了在单个查询中由MetricsQL聚合函数生成的时间序列数量。 -search.maxSeries 限制了从/api/v1/series返回的时间序列数量。这个端点主要被Grafana用于自动完成指标名称、标签名称和标签值。当数据库包含大量唯一时间序列时，对该端点的查询可能会消耗大量的CPU时间和内存，因为存在高频率变化。在这种情况下，将-search.maxSeries设置为较低的值可能有助于限制CPU和内存使用。 -search.maxTagKeys 限制从/api/v1/labels返回的项目数量。此端点主要用于Grafana自动完成标签名称。当数据库包含大量唯一时间序列时，对此端点的查询可能会消耗大量的CPU时间和内存，因为存在高频率变化。在这种情况下，将-search.maxTagKeys设置为较低值可能有助于限制CPU和内存使用。 -search.maxTagValues 限制从/api/v1/label/…/values返回的项目数量。此端点主要用于Grafana自动完成标签值。由于高频率更改，当数据库包含大量唯一时间序列时，对该端点的查询可能会消耗大量CPU时间和内存。在这种情况下，将-search.maxTagValues设置为较低的值可能有助于限制CPU和内存使用。 -search.maxTagValueSuffixesPerSearch 限制了从/metrics/find端点返回的条目数量。请参阅Graphite Metrics API使用文档。 参见 cardinality limiter and capacity planning docs.\n高可用 在不同的数据中心（可用区）安装多个VictoriaMetrics实例。 将这些实例的地址通过 -remoteWrite.url 命令行标志传递给 vmagent。 /path/to/vmagent -remoteWrite.url=http://\u003cvictoriametrics-addr-1\u003e:8428/api/v1/write -remoteWrite.url=http://\u003cvictoriametrics-addr-2\u003e:8428/api/v1/write 或者这些地址可以传递给Prometheus配置中的remote_write部分：\nremote_write: - url: http://\u003cvictoriametrics-addr-1\u003e:8428/api/v1/write queue_config: max_samples_per_send: 10000 # ... - url: http://\u003cvictoriametrics-addr-N\u003e:8428/api/v1/write queue_config: max_samples_per_send: 10000 应用更新的配置： kill -HUP `pidof prometheus` 建议在高负载环境中使用vmagent而不是Prometheus。\n现在Prometheus应该并行地将数据写入所有配置的remote_write URL。 在所有的VictoriaMetrics副本前面设置Promxy。 在Grafana中设置一个指向Promxy的Prometheus数据源。 如果您在每个Prometheus HA对中有副本r1和r2，那么请将每个r1配置为将数据写入victoriametrics-addr-1，而每个r2应该将数据写入victoriametrics-addr-2。\n另一种选择是从Prometheus HA对同时向一对启用了去重功能的VictoriaMetrics实例写入数据。有关详细信息，请参阅此部分。\n监控 VictoriaMetrics在/metrics页面以Prometheus公开格式导出内部指标。这些指标可以通过vmagent或Prometheus进行抓取。另外，当-selfScrapeInterval命令行标志设置为大于0的持续时间时，单节点的VictoriaMetrics可以自动抓取指标。例如，-selfScrapeInterval=10s将启用每10秒一次的自动抓取/metrics页面。\n官方提供了适用于单节点和集群 VictoriaMetrics 的 Grafana 仪表板。还可以查看由社区创建的适用于集群 VictoriaMetrics 的替代仪表板。\n仪表板上的图表包含有用的提示 - 将鼠标悬停在每个图表左上角的 i 图标上以阅读它。\n我们建议通过vmalert或Prometheus设置警报。\nVictoriaMetrics 在/api/v1/status/active_queries 页面中展示当前正在执行的查询以及它们的运行时间。\nVictoriaMetrics /api/v1/status/top_queries 页面展示执行时间最长的查询语句。\n参见 VictoriaMetrics Monitoring 和 troubleshooting docs.\nPush Metrics 所有的VictoriaMetrics组件都支持将其在/metrics页面上公开的指标以Prometheus文本格式推送到远程存储。如果VictoriaMetrics组件位于隔离网络中，无法被本地vmagent抓取，则可以使用此功能来替代经典的类Prometheus指标抓取。\n以下命令行参数与从VictoriaMetrics组件推送指标相关：\n-pushmetrics.url - push 的目标 URL 地址。比如， -pushmetrics.url=http://victoria-metrics:8428/api/v1/import/prometheus 表示把内部指标 Push 到 /api/v1/import/prometheus 中，参见这个文档。 -pushmetrics.url 参数可以被指定多次。这种情况下 metrics 会被 Push 到所有目标 URL 地址上。URL 中也可以包含上 Basic Auth 信息，格式是http://user:pass@hostname/api/v1/import/prometheus。Metrics 是以压缩的形式被 Push 到 -pushmetrics.url 中的，请求头中带有Content-Encoding: gzip 。这可以减少 Push 所需的网络带宽。 -pushmetrics.extraLabel - 在把 metrics 数据 Push 到-pushmetrics.url之前追加一些 Label 。每一个Label都是用label=\"value\"的格式指定。命令行参数 -pushmetrics.extraLabel 也是可以被多次指定的。这种情况下会将指定的多个Label 全都追加到 metrics 数据中，再 Push 给 -pushmetrics.url地址。 -pushmetrics.interval - Push 动作的间隔，默认是 10t秒一次。 例如，以下命令指示VictoriaMetrics将/metrics页面的指标推送到https://maas.victoriametrics.com/api/v1/import/prometheus，并使用user:pass基本身份验证。在将指标发送到远程存储之前，会添加instance=\"foobar\"和job=\"vm\"标签给所有的指标：\n/path/to/victoria-metrics \\ -pushmetrics.url=https://user:pass@maas.victoriametrics.com/api/v1/import/prometheus \\ -pushmetrics.extraLabel='instance=\"foobar\"' \\ -pushmetrics.extraLabel='job=\"vm\"' 调整？ 不需要调整VictoriaMetrics - 它使用合理的默认命令行标志，这些标志会自动根据可用的CPU和RAM资源进行调整。 操作系统不需要调优 - VictoriaMetrics已经针对默认的操作系统设置进行了优化。唯一的选项是增加操作系统中打开文件数量的限制。这个建议不仅适用于VictoriaMetrics，也适用于任何处理大量HTTP连接并将数据存储在磁盘上的服务。 VictoriaMetrics是一个写入密集型应用程序，其性能取决于磁盘性能。因此，请注意其他可能耗尽磁盘资源的应用程序或实用工具（如fstrim）。 推荐使用ext4文件系统，并且推荐在GCP上使用基于持久HDD硬盘作为持久存储，因为它通过内部复制受到硬件故障保护，并且可以动态调整大小。如果您计划在ext4分区上存储超过1TB的数据或者计划将其扩展到超过16TB，则建议传递以下选项给mkfs.ext4： mkfs.ext4 ... -O 64bit,huge_file,extent -T huge ","数据运维#数据运维":"如何运用 snapshots VictoriaMetrics可以为存储在-storageDataPath目录下的所有数据创建即时快照。请访问http://:8428/snapshot/create以创建即时快照。该页面将返回以下JSON响应：\n{\"status\":\"ok\",\"snapshot\":\"\u003csnapshot-name\u003e\"} 快照是在\u003c-storageDataPath\u003e/snapshots目录下创建的，其中\u003c-storageDataPath\u003e是命令行参数。可以随时使用vmbackup将快照归档到备份存储中。\nhttp://\u003cvictoriametrics-addr\u003e:8428/snapshot/list 页面包含了可用快照列表。\nhttp://\u003cvictoriametrics-addr\u003e:8428/snapshot/delete?snapshot=\u003csnapshot-name\u003e 则可删除 \u003csnapshot-name\u003e 快照.\nhttp://\u003cvictoriametrics-addr\u003e:8428/snapshot/delete_all 可删除所有快照。\n从快照中恢复数据的步骤：\n使用命令 kill -INT停掉 VictoriaMetrics。 使用 vmrestore 将快照内容恢复到 -storageDataPath.参数指定的目录。 启动 VictoriaMetrics. 如何删除 Timeseries 发送一个请求到http://:8428/api/v1/admin/tsdb/delete_series，其中\u003ctimeseries_selector_for_delete\u003e可以包含任何用于删除指标的时间序列选择器。删除API不支持删除特定的时间范围，timeseries 只能完全删除。已删除时间序列的存储空间不会立即释放 - 它在后续数据文件的后台 Merge 过程中释放。\n请注意，对于以前月份的数据可能永远不会进行后台合并，因此历史数据将无法释放存储空间。在这种情况下，强制合并可能有助于释放存储空间。\n建议在实际删除指标之前使用调用http://:8428/api/v1/series?match[]=\u003ctimeseries_selector_for_delete\u003e验证将要被删除的指标。默认情况下，此查询仅扫描过去5分钟内的系列，因此您可能需要调整开始和结束时间以获得匹配结果。\n如果设置了-deleteAuthKey命令行参数，则可以使用authKey保护/api/v1/admin/tsdb/delete_series处理程序。\nDelete API主要适用于以下情况：\n一次性删除意外写入的无效（或不需要）时间序列。 由于GDPR而一次性删除用户数据。 以下情况不建议使用delete API，因为它会带来非零开销：\n定期清理不需要的数据。只需防止将不需要的数据写入VictoriaMetrics即可。可以通过重新标记来实现。有关详细信息，请参阅本文。 通过删除不需要的时间序列来减少磁盘空间使用情况。这种方法无法达到预期效果，因为已删除的时间序列占用磁盘空间直到下一次合并操作，而当删除过旧数据时可能永远不会发生合并操作。强制合并可用于释放由旧数据占用的磁盘空间。请注意，VictoriaMetrics不会从倒排索引（也称为indexdb）中删除已删除时间序列的条目。倒排索引每配置保留期清理一次。\n最好使用-retentionPeriod命令行参数以有效地修剪旧数据。\n强制合并 VictoriaMetrics在后台执行数据压缩，以保持在接受新数据时的良好性能特征。这些压缩（合并）是独立地针对每个月份分区进行的。这意味着如果没有将新数据注入到这些分区中，则会停止对每个月份分区进行压缩。有时需要触发旧分区的压缩，例如为了释放被删除Timeseries占用的磁盘空间。在这种情况下，可以通过向/internal/force_merge发送请求来启动指定的每月分区上的强制合并操作?partition_prefix=YYYY_MM，其中YYYY_MM是每月分区名称。例如，http://victoriametrics:8428/internal/force_merge?partition_prefix=2020_08将会启动2020年8月份分区的强制合并操作。调用/internal/force_merge会立即返回，而相应的强制合并操作将继续在后台运行。 强制合并可能需要额外的CPU、磁盘IO和存储空间资源。在正常情况下不必运行强制合并操作，因为当有新数据注入时，VictoriaMetrics会自动在后台执行最佳合并操作。\n导出 timeseries VictoriaMetrics 提供了下面的 API 接口来导出数据\n/api/v1/export 将数据一以 JSON 格式导出。参见 这篇文档 获取更多信息。 /api/v1/export/csv 将数据以 CSV 格式导出。参见 这篇文档 获取更多信息。 /api/v1/export/native 将数据以原生二进制格式导出。这是性能最好的数据导出格式。参见 这些文档获取更多信息。 如何导出 JSON 格式 发送一个请求到 http://:8428/api/v1/export?match[]=\u003ctimeseries_selector_for_export\u003e，其中 \u003ctimeseries_selector_for_export\u003e 可以是任何用于导出指标的时间序列选择器。使用 {__name__!=\"\"} 选择器来获取所有时间序列。响应将以 JSON 流格式包含所选时间序列的所有数据。每个 JSON 行都包含单个时间序列的样本。示例输出如下：\n{\"metric\":{\"__name__\":\"up\",\"job\":\"node_exporter\",\"instance\":\"localhost:9100\"},\"values\":[0,0,0],\"timestamps\":[1549891472010,1549891487724,1549891503438]} {\"metric\":{\"__name__\":\"up\",\"job\":\"prometheus\",\"instance\":\"localhost:9090\"},\"values\":[1,1,1],\"timestamps\":[1549891461511,1549891476511,1549891491511]} Optional start and end args may be added to the request in order to limit the time frame for the exported data. See allowed formats for these args.\n可选的start和end参数可以添加到请求中，以限制导出数据的时间范围。请参阅这些参数的允许格式。\n例如：\ncurl http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export -d 'match[]=\u003ctimeseries_selector_for_export\u003e' -d 'start=1654543486' -d 'end=1654543486' curl http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export -d 'match[]=\u003ctimeseries_selector_for_export\u003e' -d 'start=2022-06-06T19:25:48' -d 'end=2022-06-06T19:29:07' 可选的max_rows_per_line参数可以添加到请求中，以限制每个JSON行导出的最大行数。当导出大量时间序列数据时，可以添加可选的reduce_mem_usage=1参数来减少内存使用。在这种情况下，输出可能包含多行同一时间序列的样本。\n在向/api/v1/export发送请求时，请传递Accept-Encoding: gzip HTTP头部，以便在导出大量时间序列数据时减少网络带宽。这将为导出的数据启用gzip压缩。以下是导出gzipped数据的示例：\ncurl -H 'Accept-Encoding: gzip' http://localhost:8428/api/v1/export -d 'match[]={__name__!=\"\"}' \u003e data.jsonl.gz 每个对/api/v1/export的请求的最长持续时间受-search.maxExportDuration命令行标志限制。\n导出的数据可以通过将其POST到/api/v1/import来导入。\n默认情况下，对通过/api/v1/export导出的数据应用去重。如果在请求中传递了reduce_mem_usage=1查询参数，则不会应用去重。\n如何导出 CSV 数据 发送请求到 http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export/csv?format=\u003cformat\u003e\u0026match=\u003ctimeseries_selector_for_export\u003e， 这里：\n\u003cformat\u003e 必须包含逗号分隔的标签名称，用于导出CSV文件。支持以下特殊标签名称： __name__ - metric 名称 __value__ - 样本值 __timestamp__:\u003cts_format\u003e - 样本时间戳. \u003cts_format\u003e 可以包含以下值: unix_s - unix 秒 unix_ms - unix 毫秒 unix_ns - unix 纳秒 rfc3339 - RFC3339 格式时间 custom:\u003clayout\u003e - 自定义时间格式，可由Go的time.Format函数支持。 \u003ctimeseries_selector_for_export\u003e 用于过滤导出数据的 time series selector 。 start and end 参数是可选的，可以加到请求中以限制下导出的数据量，关于该参数可阅读系9啊 allowed formats 。\n举例：\ncurl http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export/csv -d 'format=\u003cformat\u003e' -d 'match[]=\u003ctimeseries_selector_for_export\u003e' -d 'start=1654543486' -d 'end=1654543486' curl http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export/csv -d 'format=\u003cformat\u003e' -d 'match[]=\u003ctimeseries_selector_for_export\u003e' -d 'start=2022-06-06T19:25:48' -d 'end=2022-06-06T19:29:07' 通过 /api/v1/import/csv，可以将导出的 CSV 数据导入到 VictoriaMetrics。\n默认情况下，对于以 CSV 导出的数据应用了去重功能。如果要导出原始数据而不进行去重操作，则可以在 /api/v1/export/csv 中传递 reduce_mem_usage=1 查询参数。\n如何导出原生数据 发送请求到 http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export/native?match[]=\u003ctimeseries_selector_for_export\u003e， 这里的 \u003ctimeseries_selector_for_export\u003e 可以设置任意的 time series selector 来过滤要导出的 metrics。 使用 {__name__=~\".*\"} 选择所有的 metric。\n在大型数据库上，您可能会遇到导出时间序列数量限制的问题。在这种情况下，您需要调整-search.maxExportSeries命令行参数：\n# count unique time series in database wget -O- -q 'http://your_victoriametrics_instance:8428/api/v1/series/count' | jq '.data[0]' # relaunch victoriametrics with search.maxExportSeries more than value from previous command 可选的start和end参数可以添加到请求中，以限制导出数据的时间范围。请参阅这些参数的允许格式。\n举例:\ncurl http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export/native -d 'match[]=\u003ctimeseries_selector_for_export\u003e' -d 'start=1654543486' -d 'end=1654543486' curl http://\u003cvictoriametrics-addr\u003e:8428/api/v1/export/native -d 'match[]=\u003ctimeseries_selector_for_export\u003e' -d 'start=2022-06-06T19:25:48' -d 'end=2022-06-06T19:29:07' 通过/api/v1/import/native，可以将导出的数据导入到VictoriaMetrics中。原生导出格式在不同版本的VictoriaMetrics之间可能会以不兼容的方式发生变化，因此从X版本导出的数据可能无法成功导入到Y版本的VictoriaMetrics中。\n原生格式导出的数据不会应用去重操作。预期在数据导入过程中进行去重处理。\n如何导入 timeseries 数据 VictoriaMetrics可以从与Prometheus兼容的目标（也称为“pull”协议）中发现和抓取指标-请参阅这些文档。此外，VictoriaMetrics还可以通过以下流行的数据摄入协议（也称为“push”协议）接收指标：\nPrometheus remote_write API. See these docs for details. DataDog submit metrics API. See these docs for details. InfluxDB line protocol. See these docs for details. Graphite plaintext protocol. See these docs for details. OpenTSDB telnet put protocol. See these docs for details. OpenTSDB http /api/put protocol. See these docs for details. /api/v1/import for importing data obtained from /api/v1/export. See these docs for details. /api/v1/import/native for importing data obtained from /api/v1/export/native. See these docs for details. /api/v1/import/csv for importing arbitrary CSV data. See these docs for details. /api/v1/import/prometheus for importing data in Prometheus exposition format and in Pushgateway format. See these docs for details. 请注意，大多数摄取 API（除了 Prometheus remote_write API）都经过性能优化，并以流式处理方式处理数据。这意味着客户端可以通过开放的连接传输无限量的数据。因此，导入 API 可能不会将解析错误返回给客户端，因为预期数据流不会中断。相反，请在服务器端（VictoriaMetrics 单节点或 vminsert）查找解析错误，或者检查 vm_rows_invalid_total 指标是否发生变化（由服务器端导出）。\n如何导入 JSON 格式数据 导入从 /api/v1/export获取到的数据的示例：\n# Export the data from \u003csource-victoriametrics\u003e: curl http://source-victoriametrics:8428/api/v1/export -d 'match={__name__!=\"\"}' \u003e exported_data.jsonl # Import the data to \u003cdestination-victoriametrics\u003e: curl -X POST http://destination-victoriametrics:8428/api/v1/import -T exported_data.jsonl 将 Content-Encoding: gzip 的 HTTP 请求头传递给 /api/v1/import，用于导入经过压缩的数据：\n# Export gzipped data from \u003csource-victoriametrics\u003e: curl -H 'Accept-Encoding: gzip' http://source-victoriametrics:8428/api/v1/export -d 'match={__name__!=\"\"}' \u003e exported_data.jsonl.gz # Import gzipped data to \u003cdestination-victoriametrics\u003e: curl -X POST -H 'Content-Encoding: gzip' http://destination-victoriametrics:8428/api/v1/import -T exported_data.jsonl.gz 可以通过传递extra_label=name=value查询参数，为所有导入的时间序列添加额外标签。例如，/api/v1/import?extra_label=foo=bar会将\"foo\":\"bar\"标签添加到所有导入的时间序列中。\n请注意，在导入历史数据后可能需要清除响应缓存。详细信息请参阅相关文档。\nVictoriaMetrics逐行解析输入的JSON数据。它将整个JSON行加载到内存中，然后解析并将解析后的样本保存到持久存储中。这意味着当导入过长的JSON行时，VictoriaMetrics可能占用大量RAM。解决方法是将过长的JSON行拆分成较小的行。如果单个时间序列的样本被拆分在多个JSON行中也是可以接受的。\n如何导入原生二进制数据 VictoriaMetrics的本地格式规范可能会发生变化，并且尚未正式文档化。因此，我们目前不建议外部客户尝试将自己的指标打包成本地格式文件。\n但是，如果您通过/api/v1/export/native获取了一个本地格式文件，则这是导入数据最高效的协议。\n# Export the data from \u003csource-victoriametrics\u003e: curl http://source-victoriametrics:8428/api/v1/export/native -d 'match={__name__!=\"\"}' \u003e exported_data.bin # Import the data to \u003cdestination-victoriametrics\u003e: curl -X POST http://destination-victoriametrics:8428/api/v1/import/native -T exported_data.bin 通过传递额外的查询参数 extra_label=name=value，可以为所有导入的时间序列添加额外的标签。例如，/api/v1/import/native?extra_label=foo=bar 将在所有导入的时间序列中添加 \"foo\":\"bar\" 标签。\n请注意，在导入历史数据后可能需要清除响应缓存。详细信息请参阅这些文档。\n如何导入 CSV 数据 任意的CSV数据可以通过/api/v1/import/csv导入。CSV数据根据提供的格式查询参数进行导入。格式查询参数必须包含逗号分隔的解析规则列表，用于指定CSV字段的解析方式。每个规则由三部分组成，以冒号分隔：\n\u003ccolumn_pos\u003e:\u003ctype\u003e:\u003ccontext\u003e \u003ccolumn_pos\u003e CSV列（字段）的位置是什么。列编号从1开始。解析规则的顺序可能是任意的。 \u003ctype\u003e 描述列类型。支持的类型有： metric - 对应的CSV列在\u003ccolumn_pos\u003e位置包含度量值，该值必须是整数或浮点数。度量名称从\u003ccontext\u003e中读取。CSV行至少必须有一个度量字段。每个CSV行可以有多个度量字段。 label -对应的CSV列在\u003ccolumn_pos\u003e位置包含标签值。标签名称从\u003ccontext\u003e中读取。CSV行可能有任意数量的标签字段。所有这些标签都附加到所有配置的指标上。 time - 对应的CSV列在\u003ccolumn_pos\u003e位置包含度量时间。CSV行可能包含一个或零个带有时间的列。如果CSV行没有时间，则使用当前时间。该时间适用于所有配置的指标。通过\u003ccontext\u003e来配置时间格式。支持的时间格式有： unix_s - unix 秒 unix_ms - unix 毫秒 unix_ns - unix 纳秒 rfc3339 - RFC3339 格式时间 custom:\u003clayout\u003e - 自定义时间格式，可由Go的time.Format函数支持。 每个对/api/v1/import/csv的请求可能包含任意数量的CSV行。\n通过 /api/v1/import/csv 导入 CSV 数据的示例：\ncurl -d \"GOOG,1.23,4.56,NYSE\" 'http://localhost:8428/api/v1/import/csv?format=2:metric:ask,3:metric:bid,1:label:ticker,4:label:market' curl -d \"MSFT,3.21,1.67,NASDAQ\" 'http://localhost:8428/api/v1/import/csv?format=2:metric:ask,3:metric:bid,1:label:ticker,4:label:market' 之后，数据可以通过/api/v1/export端点进行读取：\ncurl -G 'http://localhost:8428/api/v1/export' -d 'match[]={ticker!=\"\"}' 应该得到如下响应：\n{\"metric\":{\"__name__\":\"bid\",\"market\":\"NASDAQ\",\"ticker\":\"MSFT\"},\"values\":[1.67],\"timestamps\":[1583865146520]} {\"metric\":{\"__name__\":\"bid\",\"market\":\"NYSE\",\"ticker\":\"GOOG\"},\"values\":[4.56],\"timestamps\":[1583865146495]} {\"metric\":{\"__name__\":\"ask\",\"market\":\"NASDAQ\",\"ticker\":\"MSFT\"},\"values\":[3.21],\"timestamps\":[1583865146520]} {\"metric\":{\"__name__\":\"ask\",\"market\":\"NYSE\",\"ticker\":\"GOOG\"},\"values\":[1.23],\"timestamps\":[1583865146495]} 通过传递 extra_label=name=value 查询参数，可以为所有导入的行添加额外标签。例如，/api/v1/import/csv?extra_label=foo=bar 将在所有导入的行中添加 \"foo\":\"bar\" 标签。\n请注意，在导入历史数据后可能需要清除响应缓存。详细信息请参阅这些文档。\n如何导入 Prometheus Exporter 格式数据 VictoriaMetrics接受以Prometheus暴露格式、OpenMetrics格式和Pushgateway格式的数据，通过/api/v1/import/prometheus路径进行传输。\n例如，以下命令将以Prometheus导出格式的单行数据导入到VictoriaMetrics中：\ncurl -d 'foo{bar=\"baz\"} 123' -X POST 'http://localhost:8428/api/v1/import/prometheus' 以下命令可用于验证导入的数据：\ncurl -G 'http://localhost:8428/api/v1/export' -d 'match={__name__=~\"foo\"}' 应该返回类似以下的内容：\n{\"metric\":{\"__name__\":\"foo\",\"bar\":\"baz\"},\"values\":[123],\"timestamps\":[1594370496905]} 以下命令使用Pushgateway格式导入带有{job=\"my_app\",instance=\"host123\"}标签的单个指标：\ncurl -d 'metric{label=\"abc\"} 123' -X POST 'http://localhost:8428/api/v1/import/prometheus/metrics/job/my_app/instance/host123' 将 Content-Encoding: gzip 的 HTTP 请求头传递给 /api/v1/import/prometheus 以导入经过gzip压缩的数据：\n# Import gzipped data to \u003cdestination-victoriametrics\u003e: curl -X POST -H 'Content-Encoding: gzip' http://destination-victoriametrics:8428/api/v1/import/prometheus -T prometheus_data.gz 可以通过Pushgateway格式或通过传递extra_label=name=value查询参数向所有导入的指标添加额外的标签。例如，/api/v1/import/prometheus?extra_label=foo=bar将在所有导入的指标中添加{foo=\"bar\"}标签。\n如果在Prometheus暴露格式行中缺少\u003cmetric\u003e \u003cvalue\u003e \u003ctimestamp\u003e时间戳，则在数据摄取过程中使用当前时间戳。可以通过传递以毫秒为单位的Unix时间戳来覆盖它，例如，/api/v1/import/prometheus?timestamp=1594370496905。\nVictoriaMetrics接受单个请求中任意数量的行到/api/v1/import/prometheus，即支持数据流式传输。\n请注意，在导入历史数据后可能需要刷新响应缓存。有关详细信息，请参阅这些文档。\nVictoriaMetrics还可以抓取Prometheus目标-请参阅这些文档。","运行参数#运行参数":"使用-help参数来查看支持的所有运行参数列表和参数功能描述。\n-bigMergeConcurrency int Deprecated: this flag does nothing -blockcache.missesBeforeCaching int The number of cache misses before putting the block into cache. Higher values may reduce indexdb/dataBlocks cache size at the cost of higher CPU and disk read usage (default 2) -cacheExpireDuration duration Items are removed from in-memory caches after they aren't accessed for this duration. Lower values may reduce memory usage at the cost of higher CPU usage. See also -prevCacheRemovalPercent (default 30m0s) -configAuthKey value Authorization key for accessing /config page. It must be passed via authKey query arg. It overrides -httpAuth.* Flag value can be read from the given file when using -configAuthKey=file:///abs/path/to/file or -configAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -configAuthKey=http://host/path or -configAuthKey=https://host/path -csvTrimTimestamp duration Trim timestamps when importing csv data to this duration. Minimum practical duration is 1ms. Higher duration (i.e. 1s) may be used for reducing disk space usage for timestamp data (default 1ms) -datadog.maxInsertRequestSize size The maximum size in bytes of a single DataDog POST request to /datadog/api/v2/series Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 67108864) -datadog.sanitizeMetricName Sanitize metric names for the ingested DataDog data to comply with DataDog behaviour described at https://docs.datadoghq.com/metrics/custom_metrics/#naming-custom-metrics (default true) -dedup.minScrapeInterval duration Leave only the last sample in every time series per each discrete interval equal to -dedup.minScrapeInterval \u003e 0. See also -streamAggr.dedupInterval and https://docs.victoriametrics.com/#deduplication -deleteAuthKey value authKey for metrics' deletion via /api/v1/admin/tsdb/delete_series and /tags/delSeries Flag value can be read from the given file when using -deleteAuthKey=file:///abs/path/to/file or -deleteAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -deleteAuthKey=http://host/path or -deleteAuthKey=https://host/path -denyQueriesOutsideRetention Whether to deny queries outside the configured -retentionPeriod. When set, then /api/v1/query_range would return '503 Service Unavailable' error for queries with 'from' value outside -retentionPeriod. This may be useful when multiple data sources with distinct retentions are hidden behind query-tee -denyQueryTracing Whether to disable the ability to trace queries. See https://docs.victoriametrics.com/#query-tracing -downsampling.period array Comma-separated downsampling periods in the format 'offset:period'. For example, '30d:10m' instructs to leave a single sample per 10 minutes for samples older than 30 days. When setting multiple downsampling periods, it is necessary for the periods to be multiples of each other. See https://docs.victoriametrics.com/#downsampling for details. This flag is available only in VictoriaMetrics enterprise. See https://docs.victoriametrics.com/enterprise/ Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -dryRun Whether to check config files without running VictoriaMetrics. The following config files are checked: -promscrape.config, -relabelConfig and -streamAggr.config. Unknown config entries aren't allowed in -promscrape.config by default. This can be changed with -promscrape.config.strictParse=false command-line flag -enableTCP6 Whether to enable IPv6 for listening and dialing. By default, only IPv4 TCP and UDP are used -envflag.enable Whether to enable reading flags from environment variables in addition to the command line. Command line flag values have priority over values from environment vars. Flags are read only from the command line if this flag isn't set. See https://docs.victoriametrics.com/#environment-variables for more details -envflag.prefix string Prefix for environment variables if -envflag.enable is set -eula Deprecated, please use -license or -licenseFile flags instead. By specifying this flag, you confirm that you have an enterprise license and accept the ESA https://victoriametrics.com/legal/esa/ . This flag is available only in Enterprise binaries. See https://docs.victoriametrics.com/enterprise/ -filestream.disableFadvise Whether to disable fadvise() syscall when reading large data files. The fadvise() syscall prevents from eviction of recently accessed data from OS page cache during background merges and backups. In some rare cases it is better to disable the syscall if it uses too much CPU -finalMergeDelay duration Deprecated: this flag does nothing -flagsAuthKey value Auth key for /flags endpoint. It must be passed via authKey query arg. It overrides -httpAuth.* Flag value can be read from the given file when using -flagsAuthKey=file:///abs/path/to/file or -flagsAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -flagsAuthKey=http://host/path or -flagsAuthKey=https://host/path -forceFlushAuthKey value authKey, which must be passed in query string to /internal/force_flush pages Flag value can be read from the given file when using -forceFlushAuthKey=file:///abs/path/to/file or -forceFlushAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -forceFlushAuthKey=http://host/path or -forceFlushAuthKey=https://host/path -forceMergeAuthKey value authKey, which must be passed in query string to /internal/force_merge pages Flag value can be read from the given file when using -forceMergeAuthKey=file:///abs/path/to/file or -forceMergeAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -forceMergeAuthKey=http://host/path or -forceMergeAuthKey=https://host/path -fs.disableMmap Whether to use pread() instead of mmap() for reading data files. By default, mmap() is used for 64-bit arches and pread() is used for 32-bit arches, since they cannot read data files bigger than 2^32 bytes in memory. mmap() is usually faster for reading small data chunks than pread() -graphite.sanitizeMetricName Sanitize metric names for the ingested Graphite data. See https://docs.victoriametrics.com/#how-to-send-data-from-graphite-compatible-agents-such-as-statsd -graphiteListenAddr string TCP and UDP address to listen for Graphite plaintext data. Usually :2003 must be set. Doesn't work if empty. See also -graphiteListenAddr.useProxyProtocol -graphiteListenAddr.useProxyProtocol Whether to use proxy protocol for connections accepted at -graphiteListenAddr . See https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt -graphiteTrimTimestamp duration Trim timestamps for Graphite data to this duration. Minimum practical duration is 1s. Higher duration (i.e. 1m) may be used for reducing disk space usage for timestamp data (default 1s) -http.connTimeout duration Incoming connections to -httpListenAddr are closed after the configured timeout. This may help evenly spreading load among a cluster of services behind TCP-level load balancer. Zero value disables closing of incoming connections (default 2m0s) -http.disableResponseCompression Disable compression of HTTP responses to save CPU resources. By default, compression is enabled to save network bandwidth -http.header.csp string Value for 'Content-Security-Policy' header, recommended: \"default-src 'self'\" -http.header.frameOptions string Value for 'X-Frame-Options' header -http.header.hsts string Value for 'Strict-Transport-Security' header, recommended: 'max-age=31536000; includeSubDomains' -http.idleConnTimeout duration Timeout for incoming idle http connections (default 1m0s) -http.maxGracefulShutdownDuration duration The maximum duration for a graceful shutdown of the HTTP server. A highly loaded server may require increased value for a graceful shutdown (default 7s) -http.pathPrefix string An optional prefix to add to all the paths handled by http server. For example, if '-http.pathPrefix=/foo/bar' is set, then all the http requests will be handled on '/foo/bar/*' paths. This may be useful for proxied requests. See https://www.robustperception.io/using-external-urls-and-proxies-with-prometheus -http.shutdownDelay duration Optional delay before http server shutdown. During this delay, the server returns non-OK responses from /health page, so load balancers can route new requests to other servers -httpAuth.password value Password for HTTP server's Basic Auth. The authentication is disabled if -httpAuth.username is empty Flag value can be read from the given file when using -httpAuth.password=file:///abs/path/to/file or -httpAuth.password=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -httpAuth.password=http://host/path or -httpAuth.password=https://host/path -httpAuth.username string Username for HTTP server's Basic Auth. The authentication is disabled if empty. See also -httpAuth.password -httpListenAddr array TCP addresses to listen for incoming http requests. See also -tls and -httpListenAddr.useProxyProtocol Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -httpListenAddr.useProxyProtocol array Whether to use proxy protocol for connections accepted at the corresponding -httpListenAddr . See https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt . With enabled proxy protocol http server cannot serve regular /metrics endpoint. Use -pushmetrics.url for metrics pushing Supports array of values separated by comma or specified via multiple flags. Empty values are set to false. -import.maxLineLen size The maximum length in bytes of a single line accepted by /api/v1/import; the line length can be limited with 'max_rows_per_line' query arg passed to /api/v1/export Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 10485760) -influx.databaseNames array Comma-separated list of database names to return from /query and /influx/query API. This can be needed for accepting data from Telegraf plugins such as https://github.com/fangli/fluent-plugin-influxdb Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -influx.maxLineSize size The maximum size in bytes for a single InfluxDB line during parsing Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 262144) -influxDBLabel string Default label for the DB name sent over '?db={db_name}' query parameter (default \"db\") -influxListenAddr string TCP and UDP address to listen for InfluxDB line protocol data. Usually :8089 must be set. Doesn't work if empty. This flag isn't needed when ingesting data over HTTP - just send it to http://\u003cvictoriametrics\u003e:8428/write . See also -influxListenAddr.useProxyProtocol -influxListenAddr.useProxyProtocol Whether to use proxy protocol for connections accepted at -influxListenAddr . See https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt -influxMeasurementFieldSeparator string Separator for '{measurement}{separator}{field_name}' metric name when inserted via InfluxDB line protocol (default \"_\") -influxSkipMeasurement Uses '{field_name}' as a metric name while ignoring '{measurement}' and '-influxMeasurementFieldSeparator' -influxSkipSingleField Uses '{measurement}' instead of '{measurement}{separator}{field_name}' for metric name if InfluxDB line contains only a single field -influxTrimTimestamp duration Trim timestamps for InfluxDB line protocol data to this duration. Minimum practical duration is 1ms. Higher duration (i.e. 1s) may be used for reducing disk space usage for timestamp data (default 1ms) -inmemoryDataFlushInterval duration The interval for guaranteed saving of in-memory data to disk. The saved data survives unclean shutdowns such as OOM crash, hardware reset, SIGKILL, etc. Bigger intervals may help increase the lifetime of flash storage with limited write cycles (e.g. Raspberry PI). Smaller intervals increase disk IO load. Minimum supported value is 1s (default 5s) -insert.maxQueueDuration duration The maximum duration to wait in the queue when -maxConcurrentInserts concurrent insert requests are executed (default 1m0s) -internStringCacheExpireDuration duration The expiry duration for caches for interned strings. See https://en.wikipedia.org/wiki/String_interning . See also -internStringMaxLen and -internStringDisableCache (default 6m0s) -internStringDisableCache Whether to disable caches for interned strings. This may reduce memory usage at the cost of higher CPU usage. See https://en.wikipedia.org/wiki/String_interning . See also -internStringCacheExpireDuration and -internStringMaxLen -internStringMaxLen int The maximum length for strings to intern. A lower limit may save memory at the cost of higher CPU usage. See https://en.wikipedia.org/wiki/String_interning . See also -internStringDisableCache and -internStringCacheExpireDuration (default 500) -license string License key for VictoriaMetrics Enterprise. See https://victoriametrics.com/products/enterprise/ . Trial Enterprise license can be obtained from https://victoriametrics.com/products/enterprise/trial/ . This flag is available only in Enterprise binaries. The license key can be also passed via file specified by -licenseFile command-line flag -license.forceOffline Whether to enable offline verification for VictoriaMetrics Enterprise license key, which has been passed either via -license or via -licenseFile command-line flag. The issued license key must support offline verification feature. Contact info@victoriametrics.com if you need offline license verification. This flag is available only in Enterprise binaries -licenseFile string Path to file with license key for VictoriaMetrics Enterprise. See https://victoriametrics.com/products/enterprise/ . Trial Enterprise license can be obtained from https://victoriametrics.com/products/enterprise/trial/ . This flag is available only in Enterprise binaries. The license key can be also passed inline via -license command-line flag -logNewSeries Whether to log new series. This option is for debug purposes only. It can lead to performance issues when big number of new series are ingested into VictoriaMetrics -loggerDisableTimestamps Whether to disable writing timestamps in logs -loggerErrorsPerSecondLimit int Per-second limit on the number of ERROR messages. If more than the given number of errors are emitted per second, the remaining errors are suppressed. Zero values disable the rate limit -loggerFormat string Format for logs. Possible values: default, json (default \"default\") -loggerJSONFields string Allows renaming fields in JSON formatted logs. Example: \"ts:timestamp,msg:message\" renames \"ts\" to \"timestamp\" and \"msg\" to \"message\". Supported fields: ts, level, caller, msg -loggerLevel string Minimum level of errors to log. Possible values: INFO, WARN, ERROR, FATAL, PANIC (default \"INFO\") -loggerMaxArgLen int The maximum length of a single logged argument. Longer arguments are replaced with 'arg_start..arg_end', where 'arg_start' and 'arg_end' is prefix and suffix of the arg with the length not exceeding -loggerMaxArgLen / 2 (default 1000) -loggerOutput string Output for the logs. Supported values: stderr, stdout (default \"stderr\") -loggerTimezone string Timezone to use for timestamps in logs. Timezone must be a valid IANA Time Zone. For example: America/New_York, Europe/Berlin, Etc/GMT+3 or Local (default \"UTC\") -loggerWarnsPerSecondLimit int Per-second limit on the number of WARN messages. If more than the given number of warns are emitted per second, then the remaining warns are suppressed. Zero values disable the rate limit -maxConcurrentInserts int The maximum number of concurrent insert requests. Set higher value when clients send data over slow networks. Default value depends on the number of available CPU cores. It should work fine in most cases since it minimizes resource usage. See also -insert.maxQueueDuration (default 32) -maxInsertRequestSize size The maximum size in bytes of a single Prometheus remote_write API request Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 33554432) -maxLabelValueLen int The maximum length of label values in the accepted time series. Longer label values are truncated. In this case the vm_too_long_label_values_total metric at /metrics page is incremented (default 4096) -maxLabelsPerTimeseries int The maximum number of labels accepted per time series. Superfluous labels are dropped. In this case the vm_metrics_with_dropped_labels_total metric at /metrics page is incremented (default 30) -memory.allowedBytes size Allowed size of system memory VictoriaMetrics caches may occupy. This option overrides -memory.allowedPercent if set to a non-zero value. Too low a value may increase the cache miss rate usually resulting in higher CPU and disk IO usage. Too high a value may evict too much data from the OS page cache resulting in higher disk IO usage Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 0) -memory.allowedPercent float Allowed percent of system memory VictoriaMetrics caches may occupy. See also -memory.allowedBytes. Too low a value may increase cache miss rate usually resulting in higher CPU and disk IO usage. Too high a value may evict too much data from the OS page cache which will result in higher disk IO usage (default 60) -metrics.exposeMetadata Whether to expose TYPE and HELP metadata at the /metrics page, which is exposed at -httpListenAddr . The metadata may be needed when the /metrics page is consumed by systems, which require this information. For example, Managed Prometheus in Google Cloud - https://cloud.google.com/stackdriver/docs/managed-prometheus/troubleshooting#missing-metric-type -metricsAuthKey value Auth key for /metrics endpoint. It must be passed via authKey query arg. It overrides -httpAuth.* Flag value can be read from the given file when using -metricsAuthKey=file:///abs/path/to/file or -metricsAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -metricsAuthKey=http://host/path or -metricsAuthKey=https://host/path -mtls array Whether to require valid client certificate for https requests to the corresponding -httpListenAddr . This flag works only if -tls flag is set. See also -mtlsCAFile . This flag is available only in Enterprise binaries. See https://docs.victoriametrics.com/enterprise/ Supports array of values separated by comma or specified via multiple flags. Empty values are set to false. -mtlsCAFile array Optional path to TLS Root CA for verifying client certificates at the corresponding -httpListenAddr when -mtls is enabled. By default the host system TLS Root CA is used for client certificate verification. This flag is available only in Enterprise binaries. See https://docs.victoriametrics.com/enterprise/ Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -newrelic.maxInsertRequestSize size The maximum size in bytes of a single NewRelic request to /newrelic/infra/v2/metrics/events/bulk Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 67108864) -opentelemetry.usePrometheusNaming Whether to convert metric names and labels into Prometheus-compatible format for the metrics ingested via OpenTelemetry protocol; see https://docs.victoriametrics.com/#sending-data-via-opentelemetry -opentsdbHTTPListenAddr string TCP address to listen for OpenTSDB HTTP put requests. Usually :4242 must be set. Doesn't work if empty. See also -opentsdbHTTPListenAddr.useProxyProtocol -opentsdbHTTPListenAddr.useProxyProtocol Whether to use proxy protocol for connections accepted at -opentsdbHTTPListenAddr . See https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt -opentsdbListenAddr string TCP and UDP address to listen for OpenTSDB metrics. Telnet put messages and HTTP /api/put messages are simultaneously served on TCP port. Usually :4242 must be set. Doesn't work if empty. See also -opentsdbListenAddr.useProxyProtocol -opentsdbListenAddr.useProxyProtocol Whether to use proxy protocol for connections accepted at -opentsdbListenAddr . See https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt -opentsdbTrimTimestamp duration Trim timestamps for OpenTSDB 'telnet put' data to this duration. Minimum practical duration is 1s. Higher duration (i.e. 1m) may be used for reducing disk space usage for timestamp data (default 1s) -opentsdbhttp.maxInsertRequestSize size The maximum size of OpenTSDB HTTP put request Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 33554432) -opentsdbhttpTrimTimestamp duration Trim timestamps for OpenTSDB HTTP data to this duration. Minimum practical duration is 1ms. Higher duration (i.e. 1s) may be used for reducing disk space usage for timestamp data (default 1ms) -pprofAuthKey value Auth key for /debug/pprof/* endpoints. It must be passed via authKey query arg. It overrides -httpAuth.* Flag value can be read from the given file when using -pprofAuthKey=file:///abs/path/to/file or -pprofAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -pprofAuthKey=http://host/path or -pprofAuthKey=https://host/path -precisionBits int The number of precision bits to store per each value. Lower precision bits improves data compression at the cost of precision loss (default 64) -prevCacheRemovalPercent float Items in the previous caches are removed when the percent of requests it serves becomes lower than this value. Higher values reduce memory usage at the cost of higher CPU usage. See also -cacheExpireDuration (default 0.1) -promscrape.azureSDCheckInterval duration Interval for checking for changes in Azure. This works only if azure_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#azure_sd_configs for details (default 1m0s) -promscrape.cluster.memberLabel string If non-empty, then the label with this name and the -promscrape.cluster.memberNum value is added to all the scraped metrics. See https://docs.victoriametrics.com/vmagent/#scraping-big-number-of-targets for more info -promscrape.cluster.memberNum string The number of vmagent instance in the cluster of scrapers. It must be a unique value in the range 0 ... promscrape.cluster.membersCount-1 across scrapers in the cluster. Can be specified as pod name of Kubernetes StatefulSet - pod-name-Num, where Num is a numeric part of pod name. See also -promscrape.cluster.memberLabel . See https://docs.victoriametrics.com/vmagent/#scraping-big-number-of-targets for more info (default \"0\") -promscrape.cluster.memberURLTemplate string An optional template for URL to access vmagent instance with the given -promscrape.cluster.memberNum value. Every %d occurrence in the template is substituted with -promscrape.cluster.memberNum at urls to vmagent instances responsible for scraping the given target at /service-discovery page. For example -promscrape.cluster.memberURLTemplate='http://vmagent-%d:8429/targets'. See https://docs.victoriametrics.com/vmagent/#scraping-big-number-of-targets for more details -promscrape.cluster.membersCount int The number of members in a cluster of scrapers. Each member must have a unique -promscrape.cluster.memberNum in the range 0 ... promscrape.cluster.membersCount-1 . Each member then scrapes roughly 1/N of all the targets. By default, cluster scraping is disabled, i.e. a single scraper scrapes all the targets. See https://docs.victoriametrics.com/vmagent/#scraping-big-number-of-targets for more info (default 1) -promscrape.cluster.name string Optional name of the cluster. If multiple vmagent clusters scrape the same targets, then each cluster must have unique name in order to properly de-duplicate samples received from these clusters. See https://docs.victoriametrics.com/vmagent/#scraping-big-number-of-targets for more info -promscrape.cluster.replicationFactor int The number of members in the cluster, which scrape the same targets. If the replication factor is greater than 1, then the deduplication must be enabled at remote storage side. See https://docs.victoriametrics.com/vmagent/#scraping-big-number-of-targets for more info (default 1) -promscrape.config string Optional path to Prometheus config file with 'scrape_configs' section containing targets to scrape. The path can point to local file and to http url. See https://docs.victoriametrics.com/#how-to-scrape-prometheus-exporters-such-as-node-exporter for details -promscrape.config.dryRun Checks -promscrape.config file for errors and unsupported fields and then exits. Returns non-zero exit code on parsing errors and emits these errors to stderr. See also -promscrape.config.strictParse command-line flag. Pass -loggerLevel=ERROR if you don't need to see info messages in the output. -promscrape.config.strictParse Whether to deny unsupported fields in -promscrape.config . Set to false in order to silently skip unsupported fields (default true) -promscrape.configCheckInterval duration Interval for checking for changes in -promscrape.config file. By default, the checking is disabled. See how to reload -promscrape.config file at https://docs.victoriametrics.com/vmagent/#configuration-update -promscrape.consul.waitTime duration Wait time used by Consul service discovery. Default value is used if not set -promscrape.consulSDCheckInterval duration Interval for checking for changes in Consul. This works only if consul_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#consul_sd_configs for details (default 30s) -promscrape.consulagentSDCheckInterval duration Interval for checking for changes in Consul Agent. This works only if consulagent_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#consulagent_sd_configs for details (default 30s) -promscrape.digitaloceanSDCheckInterval duration Interval for checking for changes in digital ocean. This works only if digitalocean_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#digitalocean_sd_configs for details (default 1m0s) -promscrape.disableCompression Whether to disable sending 'Accept-Encoding: gzip' request headers to all the scrape targets. This may reduce CPU usage on scrape targets at the cost of higher network bandwidth utilization. It is possible to set 'disable_compression: true' individually per each 'scrape_config' section in '-promscrape.config' for fine-grained control -promscrape.disableKeepAlive Whether to disable HTTP keep-alive connections when scraping all the targets. This may be useful when targets has no support for HTTP keep-alive connection. It is possible to set 'disable_keepalive: true' individually per each 'scrape_config' section in '-promscrape.config' for fine-grained control. Note that disabling HTTP keep-alive may increase load on both vmagent and scrape targets -promscrape.discovery.concurrency int The maximum number of concurrent requests to Prometheus autodiscovery API (Consul, Kubernetes, etc.) (default 100) -promscrape.discovery.concurrentWaitTime duration The maximum duration for waiting to perform API requests if more than -promscrape.discovery.concurrency requests are simultaneously performed (default 1m0s) -promscrape.dnsSDCheckInterval duration Interval for checking for changes in dns. This works only if dns_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#dns_sd_configs for details (default 30s) -promscrape.dockerSDCheckInterval duration Interval for checking for changes in docker. This works only if docker_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#docker_sd_configs for details (default 30s) -promscrape.dockerswarmSDCheckInterval duration Interval for checking for changes in dockerswarm. This works only if dockerswarm_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#dockerswarm_sd_configs for details (default 30s) -promscrape.dropOriginalLabels Whether to drop original labels for scrape targets at /targets and /api/v1/targets pages. This may be needed for reducing memory usage when original labels for big number of scrape targets occupy big amounts of memory. Note that this reduces debuggability for improper per-target relabeling configs -promscrape.ec2SDCheckInterval duration Interval for checking for changes in ec2. This works only if ec2_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#ec2_sd_configs for details (default 1m0s) -promscrape.eurekaSDCheckInterval duration Interval for checking for changes in eureka. This works only if eureka_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#eureka_sd_configs for details (default 30s) -promscrape.fileSDCheckInterval duration Interval for checking for changes in 'file_sd_config'. See https://docs.victoriametrics.com/sd_configs/#file_sd_configs for details (default 1m0s) -promscrape.gceSDCheckInterval duration Interval for checking for changes in gce. This works only if gce_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#gce_sd_configs for details (default 1m0s) -promscrape.hetznerSDCheckInterval duration Interval for checking for changes in Hetzner API. This works only if hetzner_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#hetzner_sd_configs for details (default 1m0s) -promscrape.httpSDCheckInterval duration Interval for checking for changes in http endpoint service discovery. This works only if http_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#http_sd_configs for details (default 1m0s) -promscrape.kubernetes.apiServerTimeout duration How frequently to reload the full state from Kubernetes API server (default 30m0s) -promscrape.kubernetes.attachNodeMetadataAll Whether to set attach_metadata.node=true for all the kubernetes_sd_configs at -promscrape.config . It is possible to set attach_metadata.node=false individually per each kubernetes_sd_configs . See https://docs.victoriametrics.com/sd_configs/#kubernetes_sd_configs -promscrape.kubernetesSDCheckInterval duration Interval for checking for changes in Kubernetes API server. This works only if kubernetes_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#kubernetes_sd_configs for details (default 30s) -promscrape.kumaSDCheckInterval duration Interval for checking for changes in kuma service discovery. This works only if kuma_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#kuma_sd_configs for details (default 30s) -promscrape.maxDroppedTargets int The maximum number of droppedTargets to show at /api/v1/targets page. Increase this value if your setup drops more scrape targets during relabeling and you need investigating labels for all the dropped targets. Note that the increased number of tracked dropped targets may result in increased memory usage (default 10000) -promscrape.maxResponseHeadersSize size The maximum size of http response headers from Prometheus scrape targets Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 4096) -promscrape.maxScrapeSize size The maximum size of scrape response in bytes to process from Prometheus targets. Bigger responses are rejected Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 16777216) -promscrape.minResponseSizeForStreamParse size The minimum target response size for automatic switching to stream parsing mode, which can reduce memory usage. See https://docs.victoriametrics.com/vmagent/#stream-parsing-mode Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 1000000) -promscrape.noStaleMarkers Whether to disable sending Prometheus stale markers for metrics when scrape target disappears. This option may reduce memory usage if stale markers aren't needed for your setup. This option also disables populating the scrape_series_added metric. See https://prometheus.io/docs/concepts/jobs_instances/#automatically-generated-labels-and-time-series -promscrape.nomad.waitTime duration Wait time used by Nomad service discovery. Default value is used if not set -promscrape.nomadSDCheckInterval duration Interval for checking for changes in Nomad. This works only if nomad_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#nomad_sd_configs for details (default 30s) -promscrape.openstackSDCheckInterval duration Interval for checking for changes in openstack API server. This works only if openstack_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#openstack_sd_configs for details (default 30s) -promscrape.seriesLimitPerTarget int Optional limit on the number of unique time series a single scrape target can expose. See https://docs.victoriametrics.com/vmagent/#cardinality-limiter for more info -promscrape.streamParse Whether to enable stream parsing for metrics obtained from scrape targets. This may be useful for reducing memory usage when millions of metrics are exposed per each scrape target. It is possible to set 'stream_parse: true' individually per each 'scrape_config' section in '-promscrape.config' for fine-grained control -promscrape.suppressDuplicateScrapeTargetErrors Whether to suppress 'duplicate scrape target' errors; see https://docs.victoriametrics.com/vmagent/#troubleshooting for details -promscrape.suppressScrapeErrors Whether to suppress scrape errors logging. The last error for each target is always available at '/targets' page even if scrape errors logging is suppressed. See also -promscrape.suppressScrapeErrorsDelay -promscrape.suppressScrapeErrorsDelay duration The delay for suppressing repeated scrape errors logging per each scrape targets. This may be used for reducing the number of log lines related to scrape errors. See also -promscrape.suppressScrapeErrors -promscrape.yandexcloudSDCheckInterval duration Interval for checking for changes in Yandex Cloud API. This works only if yandexcloud_sd_configs is configured in '-promscrape.config' file. See https://docs.victoriametrics.com/sd_configs/#yandexcloud_sd_configs for details (default 30s) -pushmetrics.disableCompression Whether to disable request body compression when pushing metrics to every -pushmetrics.url -pushmetrics.extraLabel array Optional labels to add to metrics pushed to every -pushmetrics.url . For example, -pushmetrics.extraLabel='instance=\"foo\"' adds instance=\"foo\" label to all the metrics pushed to every -pushmetrics.url Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -pushmetrics.header array Optional HTTP request header to send to every -pushmetrics.url . For example, -pushmetrics.header='Authorization: Basic foobar' adds 'Authorization: Basic foobar' header to every request to every -pushmetrics.url Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -pushmetrics.interval duration Interval for pushing metrics to every -pushmetrics.url (default 10s) -pushmetrics.url array Optional URL to push metrics exposed at /metrics page. See https://docs.victoriametrics.com/#push-metrics . By default, metrics exposed at /metrics page aren't pushed to any remote storage Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -relabelConfig string Optional path to a file with relabeling rules, which are applied to all the ingested metrics. The path can point either to local file or to http url. See https://docs.victoriametrics.com/#relabeling for details. The config is reloaded on SIGHUP signal -reloadAuthKey value Auth key for /-/reload http endpoint. It must be passed via authKey query arg. It overrides -httpAuth.* Flag value can be read from the given file when using -reloadAuthKey=file:///abs/path/to/file or -reloadAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -reloadAuthKey=http://host/path or -reloadAuthKey=https://host/path -retentionFilter array Retention filter in the format 'filter:retention'. For example, '{env=\"dev\"}:3d' configures the retention for time series with env=\"dev\" label to 3 days. See https://docs.victoriametrics.com/#retention-filters for details. This flag is available only in VictoriaMetrics enterprise. See https://docs.victoriametrics.com/enterprise/ Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -retentionPeriod value Data with timestamps outside the retentionPeriod is automatically deleted. The minimum retentionPeriod is 24h or 1d. See also -retentionFilter The following optional suffixes are supported: s (second), m (minute), h (hour), d (day), w (week), y (year). If suffix isn't set, then the duration is counted in months (default 1) -retentionTimezoneOffset duration The offset for performing indexdb rotation. If set to 0, then the indexdb rotation is performed at 4am UTC time per each -retentionPeriod. If set to 2h, then the indexdb rotation is performed at 4am EET time (the timezone with +2h offset) -search.cacheTimestampOffset duration The maximum duration since the current time for response data, which is always queried from the original raw data, without using the response cache. Increase this value if you see gaps in responses due to time synchronization issues between VictoriaMetrics and data sources. See also -search.disableAutoCacheReset (default 5m0s) -search.disableAutoCacheReset Whether to disable automatic response cache reset if a sample with timestamp outside -search.cacheTimestampOffset is inserted into VictoriaMetrics -search.disableCache Whether to disable response caching. This may be useful when ingesting historical data. See https://docs.victoriametrics.com/#backfilling . See also -search.resetRollupResultCacheOnStartup -search.disableImplicitConversion Whether to return an error for queries that rely on implicit subquery conversions, see https://docs.victoriametrics.com/metricsql/#subqueries for details. See also -search.logImplicitConversion -search.graphiteMaxPointsPerSeries int The maximum number of points per series Graphite render API can return (default 1000000) -search.graphiteStorageStep duration The interval between datapoints stored in the database. It is used at Graphite Render API handler for normalizing the interval between datapoints in case it isn't normalized. It can be overridden by sending 'storage_step' query arg to /render API or by sending the desired interval via 'Storage-Step' http header during querying /render API (default 10s) -search.ignoreExtraFiltersAtLabelsAPI Whether to ignore match[], extra_filters[] and extra_label query args at /api/v1/labels and /api/v1/label/.../values . This may be useful for decreasing load on VictoriaMetrics when extra filters match too many time series. The downside is that superfluous labels or series could be returned, which do not match the extra filters. See also -search.maxLabelsAPISeries and -search.maxLabelsAPIDuration -search.latencyOffset duration The time when data points become visible in query results after the collection. It can be overridden on per-query basis via latency_offset arg. Too small value can result in incomplete last points for query results (default 30s) -search.logImplicitConversion Whether to log queries with implicit subquery conversions, see https://docs.victoriametrics.com/metricsql/#subqueries for details. Such conversion can be disabled using -search.disableImplicitConversion -search.logQueryMemoryUsage size Log query and increment vm_memory_intensive_queries_total metric each time the query requires more memory than specified by this flag. This may help detecting and optimizing heavy queries. Query logging is disabled by default. See also -search.logSlowQueryDuration and -search.maxMemoryPerQuery Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 0) -search.logSlowQueryDuration duration Log queries with execution time exceeding this value. Zero disables slow query logging. See also -search.logQueryMemoryUsage (default 5s) -search.maxConcurrentRequests int The maximum number of concurrent search requests. It shouldn't be high, since a single request can saturate all the CPU cores, while many concurrently executed requests may require high amounts of memory. See also -search.maxQueueDuration and -search.maxMemoryPerQuery (default 16) -search.maxExportDuration duration The maximum duration for /api/v1/export call (default 720h0m0s) -search.maxExportSeries int The maximum number of time series, which can be returned from /api/v1/export* APIs. This option allows limiting memory usage (default 10000000) -search.maxFederateSeries int The maximum number of time series, which can be returned from /federate. This option allows limiting memory usage (default 1000000) -search.maxGraphiteSeries int The maximum number of time series, which can be scanned during queries to Graphite Render API. See https://docs.victoriametrics.com/#graphite-render-api-usage (default 300000) -search.maxGraphiteTagKeys int The maximum number of tag keys returned from Graphite API, which returns tags. See https://docs.victoriametrics.com/#graphite-tags-api-usage (default 100000) -search.maxGraphiteTagValues int The maximum number of tag values returned from Graphite API, which returns tag values. See https://docs.victoriametrics.com/#graphite-tags-api-usage (default 100000) -search.maxLabelsAPIDuration duration The maximum duration for /api/v1/labels, /api/v1/label/.../values and /api/v1/series requests. See also -search.maxLabelsAPISeries and -search.ignoreExtraFiltersAtLabelsAPI (default 5s) -search.maxLabelsAPISeries int The maximum number of time series, which could be scanned when searching for the matching time series at /api/v1/labels and /api/v1/label/.../values. This option allows limiting memory usage and CPU usage. See also -search.maxLabelsAPIDuration, -search.maxTagKeys, -search.maxTagValues and -search.ignoreExtraFiltersAtLabelsAPI (default 1000000) -search.maxLookback duration Synonym to -search.lookback-delta from Prometheus. The value is dynamically detected from interval between time series datapoints if not set. It can be overridden on per-query basis via max_lookback arg. See also '-search.maxStalenessInterval' flag, which has the same meaning due to historical reasons -search.maxMemoryPerQuery size The maximum amounts of memory a single query may consume. Queries requiring more memory are rejected. The total memory limit for concurrently executed queries can be estimated as -search.maxMemoryPerQuery multiplied by -search.maxConcurrentRequests . See also -search.logQueryMemoryUsage Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 0) -search.maxPointsPerTimeseries int The maximum points per a single timeseries returned from /api/v1/query_range. This option doesn't limit the number of scanned raw samples in the database. The main purpose of this option is to limit the number of per-series points returned to graphing UI such as VMUI or Grafana. There is no sense in setting this limit to values bigger than the horizontal resolution of the graph. See also -search.maxResponseSeries (default 30000) -search.maxPointsSubqueryPerTimeseries int The maximum number of points per series, which can be generated by subquery. See https://valyala.medium.com/prometheus-subqueries-in-victoriametrics-9b1492b720b3 (default 100000) -search.maxQueryDuration duration The maximum duration for query execution. It can be overridden on a per-query basis via 'timeout' query arg (default 30s) -search.maxQueryLen size The maximum search query length in bytes Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 16384) -search.maxQueueDuration duration The maximum time the request waits for execution when -search.maxConcurrentRequests limit is reached; see also -search.maxQueryDuration (default 10s) -search.maxResponseSeries int The maximum number of time series which can be returned from /api/v1/query and /api/v1/query_range . The limit is disabled if it equals to 0. See also -search.maxPointsPerTimeseries and -search.maxUniqueTimeseries -search.maxSamplesPerQuery int The maximum number of raw samples a single query can process across all time series. This protects from heavy queries, which select unexpectedly high number of raw samples. See also -search.maxSamplesPerSeries (default 1000000000) -search.maxSamplesPerSeries int The maximum number of raw samples a single query can scan per each time series. This option allows limiting memory usage (default 30000000) -search.maxSeries int The maximum number of time series, which can be returned from /api/v1/series. This option allows limiting memory usage (default 30000) -search.maxSeriesPerAggrFunc int The maximum number of time series an aggregate MetricsQL function can generate (default 1000000) -search.maxStalenessInterval duration The maximum interval for staleness calculations. By default, it is automatically calculated from the median interval between samples. This flag could be useful for tuning Prometheus data model closer to Influx-style data model. See https://prometheus.io/docs/prometheus/latest/querying/basics/#staleness for details. See also '-search.setLookbackToStep' flag -search.maxStatusRequestDuration duration The maximum duration for /api/v1/status/* requests (default 5m0s) -search.maxStepForPointsAdjustment duration The maximum step when /api/v1/query_range handler adjusts points with timestamps closer than -search.latencyOffset to the current time. The adjustment is needed because such points may contain incomplete data (default 1m0s) -search.maxTSDBStatusSeries int The maximum number of time series, which can be processed during the call to /api/v1/status/tsdb. This option allows limiting memory usage (default 10000000) -search.maxTagKeys int The maximum number of tag keys returned from /api/v1/labels . See also -search.maxLabelsAPISeries and -search.maxLabelsAPIDuration (default 100000) -search.maxTagValueSuffixesPerSearch int The maximum number of tag value suffixes returned from /metrics/find (default 100000) -search.maxTagValues int The maximum number of tag values returned from /api/v1/label/\u003clabel_name\u003e/values . See also -search.maxLabelsAPISeries and -search.maxLabelsAPIDuration (default 100000) -search.maxUniqueTimeseries int The maximum number of unique time series, which can be selected during /api/v1/query and /api/v1/query_range queries. This option allows limiting memory usage (default 300000) -search.maxWorkersPerQuery int The maximum number of CPU cores a single query can use. The default value should work good for most cases. The flag can be set to lower values for improving performance of big number of concurrently executed queries. The flag can be set to bigger values for improving performance of heavy queries, which scan big number of time series (\u003e10K) and/or big number of samples (\u003e100M). There is no sense in setting this flag to values bigger than the number of CPU cores available on the system (default 16) -search.minStalenessInterval duration The minimum interval for staleness calculations. This flag could be useful for removing gaps on graphs generated from time series with irregular intervals between samples. See also '-search.maxStalenessInterval' -search.minWindowForInstantRollupOptimization value Enable cache-based optimization for repeated queries to /api/v1/query (aka instant queries), which contain rollup functions with lookbehind window exceeding the given value The following optional suffixes are supported: s (second), m (minute), h (hour), d (day), w (week), y (year). If suffix isn't set, then the duration is counted in months (default 3h) -search.noStaleMarkers Set this flag to true if the database doesn't contain Prometheus stale markers, so there is no need in spending additional CPU time on its handling. Staleness markers may exist only in data obtained from Prometheus scrape targets -search.queryStats.lastQueriesCount int Query stats for /api/v1/status/top_queries is tracked on this number of last queries. Zero value disables query stats tracking (default 20000) -search.queryStats.minQueryDuration duration The minimum duration for queries to track in query stats at /api/v1/status/top_queries. Queries with lower duration are ignored in query stats (default 1ms) -search.resetCacheAuthKey value Optional authKey for resetting rollup cache via /internal/resetRollupResultCache call Flag value can be read from the given file when using -search.resetCacheAuthKey=file:///abs/path/to/file or -search.resetCacheAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -search.resetCacheAuthKey=http://host/path or -search.resetCacheAuthKey=https://host/path -search.resetRollupResultCacheOnStartup Whether to reset rollup result cache on startup. See https://docs.victoriametrics.com/#rollup-result-cache . See also -search.disableCache -search.setLookbackToStep Whether to fix lookback interval to 'step' query arg value. If set to true, the query model becomes closer to InfluxDB data model. If set to true, then -search.maxLookback and -search.maxStalenessInterval are ignored -search.treatDotsAsIsInRegexps Whether to treat dots as is in regexp label filters used in queries. For example, foo{bar=~\"a.b.c\"} will be automatically converted to foo{bar=~\"a\\\\.b\\\\.c\"}, i.e. all the dots in regexp filters will be automatically escaped in order to match only dot char instead of matching any char. Dots in \".+\", \".*\" and \".{n}\" regexps aren't escaped. This option is DEPRECATED in favor of {__graphite__=\"a.*.c\"} syntax for selecting metrics matching the given Graphite metrics filter -selfScrapeInstance string Value for 'instance' label, which is added to self-scraped metrics (default \"self\") -selfScrapeInterval duration Interval for self-scraping own metrics at /metrics page -selfScrapeJob string Value for 'job' label, which is added to self-scraped metrics (default \"victoria-metrics\") -smallMergeConcurrency int Deprecated: this flag does nothing -snapshotAuthKey value authKey, which must be passed in query string to /snapshot* pages Flag value can be read from the given file when using -snapshotAuthKey=file:///abs/path/to/file or -snapshotAuthKey=file://./relative/path/to/file . Flag value can be read from the given http/https url when using -snapshotAuthKey=http://host/path or -snapshotAuthKey=https://host/path -snapshotCreateTimeout duration Deprecated: this flag does nothing -snapshotsMaxAge value Automatically delete snapshots older than -snapshotsMaxAge if it is set to non-zero duration. Make sure that backup process has enough time to finish the backup before the corresponding snapshot is automatically deleted The following optional suffixes are supported: s (second), m (minute), h (hour), d (day), w (week), y (year). If suffix isn't set, then the duration is counted in months (default 0) -sortLabels Whether to sort labels for incoming samples before writing them to storage. This may be needed for reducing memory usage at storage when the order of labels in incoming samples is random. For example, if m{k1=\"v1\",k2=\"v2\"} may be sent as m{k2=\"v2\",k1=\"v1\"}. Enabled sorting for labels can slow down ingestion performance a bit -storage.cacheSizeIndexDBDataBlocks size Overrides max size for indexdb/dataBlocks cache. See https://docs.victoriametrics.com/single-server-victoriametrics/#cache-tuning Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 0) -storage.cacheSizeIndexDBIndexBlocks size Overrides max size for indexdb/indexBlocks cache. See https://docs.victoriametrics.com/single-server-victoriametrics/#cache-tuning Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 0) -storage.cacheSizeIndexDBTagFilters size Overrides max size for indexdb/tagFiltersToMetricIDs cache. See https://docs.victoriametrics.com/single-server-victoriametrics/#cache-tuning Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 0) -storage.cacheSizeStorageTSID size Overrides max size for storage/tsid cache. See https://docs.victoriametrics.com/single-server-victoriametrics/#cache-tuning Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 0) -storage.maxDailySeries int The maximum number of unique series can be added to the storage during the last 24 hours. Excess series are logged and dropped. This can be useful for limiting series churn rate. See https://docs.victoriametrics.com/#cardinality-limiter . See also -storage.maxHourlySeries -storage.maxHourlySeries int The maximum number of unique series can be added to the storage during the last hour. Excess series are logged and dropped. This can be useful for limiting series cardinality. See https://docs.victoriametrics.com/#cardinality-limiter . See also -storage.maxDailySeries -storage.minFreeDiskSpaceBytes size The minimum free disk space at -storageDataPath after which the storage stops accepting new data Supports the following optional suffixes for size values: KB, MB, GB, TB, KiB, MiB, GiB, TiB (default 10000000) -storageDataPath string Path to storage data (default \"victoria-metrics-data\") -streamAggr.config string Optional path to file with stream aggregation config. See https://docs.victoriametrics.com/stream-aggregation/ . See also -streamAggr.keepInput, -streamAggr.dropInput and -streamAggr.dedupInterval -streamAggr.dedupInterval duration Input samples are de-duplicated with this interval before optional aggregation with -streamAggr.config . See also -streamAggr.dropInputLabels and -dedup.minScrapeInterval and https://docs.victoriametrics.com/stream-aggregation/#deduplication -streamAggr.dropInput Whether to drop all the input samples after the aggregation with -streamAggr.config. By default, only aggregated samples are dropped, while the remaining samples are stored in the database. See also -streamAggr.keepInput and https://docs.victoriametrics.com/stream-aggregation/ -streamAggr.dropInputLabels array An optional list of labels to drop from samples before stream de-duplication and aggregation . See https://docs.victoriametrics.com/stream-aggregation/#dropping-unneeded-labels Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -streamAggr.ignoreFirstIntervals int Number of aggregation intervals to skip after the start. Increase this value if you observe incorrect aggregation results after restarts. It could be caused by receiving unordered delayed data from clients pushing data into the database. See https://docs.victoriametrics.com/stream-aggregation/#ignore-aggregation-intervals-on-start -streamAggr.ignoreOldSamples Whether to ignore input samples with old timestamps outside the current aggregation interval. See https://docs.victoriametrics.com/stream-aggregation/#ignoring-old-samples -streamAggr.keepInput Whether to keep all the input samples after the aggregation with -streamAggr.config. By default, only aggregated samples are dropped, while the remaining samples are stored in the database. See also -streamAggr.dropInput and https://docs.victoriametrics.com/stream-aggregation/ -tls array Whether to enable TLS for incoming HTTP requests at the given -httpListenAddr (aka https). -tlsCertFile and -tlsKeyFile must be set if -tls is set. See also -mtls Supports array of values separated by comma or specified via multiple flags. Empty values are set to false. -tlsAutocertCacheDir string Directory to store TLS certificates issued via Let's Encrypt. Certificates are lost on restarts if this flag isn't set. This flag is available only in Enterprise binaries. See https://docs.victoriametrics.com/enterprise/ -tlsAutocertEmail string Contact email for the issued Let's Encrypt TLS certificates. See also -tlsAutocertHosts and -tlsAutocertCacheDir .This flag is available only in Enterprise binaries. See https://docs.victoriametrics.com/enterprise/ -tlsAutocertHosts array Optional hostnames for automatic issuing of Let's Encrypt TLS certificates. These hostnames must be reachable at -httpListenAddr . The -httpListenAddr must listen tcp port 443 . The -tlsAutocertHosts overrides -tlsCertFile and -tlsKeyFile . See also -tlsAutocertEmail and -tlsAutocertCacheDir . This flag is available only in Enterprise binaries. See https://docs.victoriametrics.com/enterprise/ Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -tlsCertFile array Path to file with TLS certificate for the corresponding -httpListenAddr if -tls is set. Prefer ECDSA certs instead of RSA certs as RSA certs are slower. The provided certificate file is automatically re-read every second, so it can be dynamically updated. See also -tlsAutocertHosts Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -tlsCipherSuites array Optional list of TLS cipher suites for incoming requests over HTTPS if -tls is set. See the list of supported cipher suites at https://pkg.go.dev/crypto/tls#pkg-constants Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -tlsKeyFile array Path to file with TLS key for the corresponding -httpListenAddr if -tls is set. The provided key file is automatically re-read every second, so it can be dynamically updated. See also -tlsAutocertHosts Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -tlsMinVersion array Optional minimum TLS version to use for the corresponding -httpListenAddr if -tls is set. Supported values: TLS10, TLS11, TLS12, TLS13 Supports an array of values separated by comma or specified via multiple flags. Value can contain comma inside single-quoted or double-quoted string, {}, [] and () braces. -usePromCompatibleNaming Whether to replace characters unsupported by Prometheus with underscores in the ingested metric names and label names. For example, foo.bar{a.b='c'} is transformed into foo_bar{a_b='c'} during data ingestion if this flag is set. See https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels -version Show VictoriaMetrics version -vmalert.proxyURL string Optional URL for proxying requests to vmalert. For example, if -vmalert.proxyURL=http://vmalert:8880 , then alerting API requests such as /api/v1/rules from Grafana will be proxied to http://vmalert:8880/api/v1/rules -vmui.customDashboardsPath string Optional path to vmui dashboards. See https://github.com/VictoriaMetrics/VictoriaMetrics/tree/master/app/vmui/packages/vmui/public/dashboards -vmui.defaultTimezone string The default timezone to be used in vmui. Timezone must be a valid IANA Time Zone. For example: America/New_York, Europe/Berlin, Etc/GMT+3 or Local ","高级特性#高级特性":"Relabeling VictoriaMetrics支持对所有接收到的指标进行与Prometheus兼容的重标签处理，只需使用-relabelConfig命令行参数指定一个包含relabel_config条目列表的文件即可。-relabelConfig也可以指向http或https URL。例如，-relabelConfig=https://config-server/relabel_config.yml。\n以下文档可能对理解重标签处理有所帮助：\nCookbook for common relabeling tasks. Relabeling tips and tricks. -relabelConfig文件中可以包含特殊的占位符，形式为%{ENV_VAR}，它们将被相应的环境变量值替换。\n-relabelConfig文件示例内容：\n# Add {cluster=\"dev\"} label. - target_label: cluster replacement: dev # Drop the metric (or scrape target) with `{__meta_kubernetes_pod_container_init=\"true\"}` label. - action: drop source_labels: [__meta_kubernetes_pod_container_init] regex: true VictoriaMetrics提供了额外的重标签功能，例如Graphite风格的重标签。有关更多详细信息，请参阅这些文档。\n可以在http://victoriametrics:8428/metric-relabel-debug页面或我们的公共游乐场上调试重标签。有关更多详细信息，请参阅这些文档。\nCache removal VictoriaMetrics使用各种内部缓存。这些缓存在优雅关闭时（例如通过发送SIGINT信号停止VictoriaMetrics）被存储到\u003c-storageDataPath\u003e/cache目录中。下次启动VictoriaMetrics时会读取这些缓存。有时需要在下次启动时删除此类缓存。可以通过以下方式完成：\n通过在 VictoriaMetrics 停止时手动删除 \u003c-storageDataPath\u003e/cache 目录。 通过在重新启动VictoriaMetrics之前将reset_cache_on_startup文件放置在\u003c-storageDataPath\u003e/cache目录中。 在这种情况下，VictoriaMetrics将自动在下次启动时删除所有缓存。 有关详细信息，请参阅此issue。 Cache tuning VictoriaMetrics使用各种内存缓存来加快数据摄取和查询性能。每种类型的缓存都在/metrics路径下暴露以下指标。\nvm_cache_size_bytes - 实际的 cache 大小 vm_cache_size_max_bytes - cache 最大限制 limit vm_cache_requests_total - cache 的请求数 vm_cache_misses_total - cache miss 的数量 vm_cache_entries - cache 中的实体数 单节点VictoriaMetrics和集群VictoriaMetrics的Grafana仪表板都包含了缓存部分，其中展示了缓存指标的可视化。面板显示了每种类型缓存的当前内存使用情况，以及缓存命中率。如果命中率接近100%，则表示缓存效率已经非常高，不需要进行任何调整。在故障排除部分的面板\"Cache usage %“显示了按类型使用的缓存大小与允许大小之间的百分比。如果百分比低于100%，则无需进一步调整。\n请注意，默认缓存大小已根据最实际的场景和工作负载进行了精心调整。只有在您理解其影响并且vmstorage具有足够空闲内存来容纳新的缓存大小时才更改默认值。\n要覆盖默认值，请参阅带有-storage.cacheSize前缀的命令行标志。可以在此处查看所有标志的完整描述。\n补数据 VictoriaMetrics通过任何支持的摄取方法以任意时间顺序接受历史数据。请参阅如何使用vmalert中的记录规则回填数据。确保配置的-retentionPeriod覆盖了回填数据的时间戳。\n建议在写入过去时间戳的历史数据时，使用-search.disableCache命令行标志禁用查询缓存，因为缓存假设数据是使用当前时间戳编写的。可以在回填完成后启用查询缓存。\n另一种解决方案是在回填完成后查询/internal/resetRollupResultCache处理程序。这将重置查询缓存，其中可能包含在回填期间缓存的不完整数据。\n还有一种解决方案是增加-search.cacheTimestampOffset标志值，以禁用与当前时间接近的时间戳数据的缓存。单节点VictoriaMetrics会自动在其上摄取早于now - search.cacheTimestampOffset 的样本时重置响应缓存。\n数据更新 VictoriaMetrics不支持将已存在的样本值更新为新值。它会将所有被摄取的数据点存储在具有相同时间戳的同一时间序列中。虽然可以通过删除旧时间序列并写入新时间序列来替换旧时间序列，但这种方法只适用于一次性更新。由于与数据删除相关的非零开销，不应频繁使用此方法进行更新。\n备份 VictoriaMetrics 支持使用 vmbackup and vmrestore 工具执行备份和恢复。\n去重特性 VictoriaMetrics每个时间序列在每个-dedup.minScrapeInterval离散间隔内只保留一个具有最大时间戳的原始样本，如果-dedup.minScrapeInterval设置为正持续时间。例如，-dedup.minScrapeInterval=60s将在每个离散的60秒间隔内保留一个具有最大时间戳的原始样本。这与Prometheus中的过期规则相一致。\n如果给定的-dedup.minScrapeInterval离散间隔上有多个具有相同时间戳的原始样本，则保留值最大的样本。\n请注意，要进行去重操作，原始样本的标签必须完全相同。例如，这就是为什么vmagents HA对需要配置完全相同。\n如果启用了降采样功能，则-dedup.minScrapeInterval=D等效于-downsampling.period=0s:D。因此可以同时使用去重和降采样而不会出现问题。\n建议将 -dedup.minScrapeInterval 的推荐值设置为 Prometheus 配置文件中 scrape_interval 的值。建议所有抓取目标都使用统一的抓取间隔，请参阅详细信息文章。\n通过去重操作可以减少磁盘空间占用量，特别是当多个配置完全相同的 vmagent 或 Prometheus 实例以 HA 对形式写入数据到同一个 VictoriaMetrics 实例时更加有效。这些 vmagent 或 Prometheus 实例必须在其配置文件中具有相同的external_labels 部分，以便将数据写入同一个时间序列。另请参阅如何设置多个 vmagent 实例来抓取相同目标。\n建议为每个不同的 vmagent HA 对实例传递不同的 -promscrape.cluster.name 值，这样去重操作就会一致地保留一个 vmagent 实例的样本，并从其他 vmagent 实例中删除重复样本。请参阅详细文档了解更多信息。\nStorage VictoriaMetrics将接收的数据缓存在内存中，最多一秒钟。然后将缓冲的数据写入内存部分，在查询期间可以进行搜索。这些in-memory part定期持久化到磁盘上，以便在发生不正常关闭（如内存崩溃、硬件断电或SIGKILL信号）时能够恢复。刷新内存数据到磁盘的时间间隔可以通过-inmemoryDataFlushInterval命令行标志进行配置（请注意，过短的刷新间隔可能会显著增加磁盘IO）。\n将内存部分持久化到磁盘时，它们被保存在\u003c-storageDataPath\u003e/data/small/YYYY_MM/文件夹下的part目录中，其中YYYY_MM是所保存数据的月份分区。例如，2022_11是包含来自2022年11月原始样本的部分所属的分区。每个分区目录都包含一个parts.json文件，其中列出了该分区中实际存在的部分。\n每个 part 目录还包含一个metadata.json文件，其中包含以下字段：\nRowsCount - 存储在零件中的原始样本数量。 BlocksCount - 存储在该部分中的块数量（有关块的详细信息请参见下文）。 MinTimestamp和MaxTimestamp - 存储在该部分中原始样本的最小和最大时间戳。 MinTimestamp and MaxTimestamp - minimum and maximum timestamps across raw samples stored in the part MinDedupInterval - 给定部分应用的去重间隔。 每个 part 由按内部时间序列ID（也称为TSID）排序的 block 组成。每个 block 包含最多8K个原始样本，这些样本属于单个时间序列。每个 block 中的原始样本按照时间戳进行排序。同一时间序列的块按第一个样本的时间戳进行排序。所有块的时间戳和值以压缩形式存储在 part 目录下的单独文件中 - timestamps.bin和values.bin。\npart 目录还包含index.bin和metaindex.bin文件 - 这些文件包含了快速块查找的索引，这些块属于给定的TSID并覆盖给定的时间范围。\n部分会周期性地在后台合并成更大的part。后台合并提供以下好处：\n保持数据文件数量在控制范围内，以免超过打开文件的限制。 改进的数据压缩，因为通常较大的部分比较小的部分更容易被压缩。 查询速度提升了，因为对较少部分的查询执行更快。 各种后台维护任务都是在合并过程中发生的，比如de-duplication, downsampling and freeing up disk space for the deleted time series 新添加的 part 要么成功出现在存储中，要么无法出现。新添加的 part 在完全写入并通过fsync同步到存储后，会自动注册到相应分区下的parts.json文件中。由于这个算法，即使在将part写入磁盘过程中发生硬件断电，在下一次VictoriaMetrics启动时也会自动删除这些未完全写入的部分，因此存储永远不会包含部分创建的part。\n合并过程也是如此——parts 要么完全合并为一个新的部分，要么无法合并，使得源部分保持不变。然而，由于硬件问题，在VictoriaMetrics处理过程中可能会导致磁盘上的数据损坏。VictoriaMetrics可以在解压缩、解码或对数据块进行健康检查时检测到损坏。但它无法修复已损坏的数据。启动时加载失败的数据部分需要被删除或从备份中恢复。因此建议定期进行备份操作。\nVictoriaMetrics在存储数据块时不使用校验和。请点击此处了解原因。\nVictoriaMetrics在合并部分时，如果它们的摘要大小超过了可用磁盘空间，则不会进行合并。这样可以防止在合并过程中出现磁盘空间不足的错误。在磁盘空间紧缺的情况下，部分数量可能会显著增加。这会增加数据查询时的开销，因为VictoriaMetrics需要从更多的部分中读取数据来处理每个请求。因此建议使用-storageDataPath命令行标志指定的目录下至少保留20% 的可用磁盘空间。\n关于合并的处理过程可以参见 the dashboard for single-node VictoriaMetrics 和 the dashboard for VictoriaMetrics cluster. 更多详情参见监控文档.\n更多详情可阅读 这篇文章，也可以阅读 how to work with snapshots.\n多租户 单节点的VictoriaMetrics不支持多租户。请使用集群版本。\n多副本 单节点的VictoriaMetrics不支持应用级别的复制。请使用集群版本代替。详细信息请参阅这些文档。\n存储级别的复制可以转移到持久性存储，如Google Cloud磁盘。\n还可以查看高可用性文档和备份文档。\n可扩展和集群版本 尽管单节点的VictoriaMetrics无法扩展到多个节点，但它在资源使用方面进行了优化 - 存储大小/带宽/IOPS、RAM和CPU。这意味着一个单节点的VictoriaMetrics可以在垂直方向上扩展，并替代使用竞争解决方案（如Thanos、Uber M3、InfluxDB或TimescaleDB）构建的中等规模集群。请参阅垂直可伸缩性基准测试结果。\n首先尝试使用单节点的VictoriaMetrics，如果您仍然需要针对大型Prometheus部署进行横向扩展的长期远程存储，则可以切换到集群版本。\n基数限制 默认情况下，VictoriaMetrics不限制存储的时间序列数量。可以通过设置以下命令行标志来强制执行限制：\n-storage.maxHourlySeries - 限制了在最后一个小时内可以添加的时间序列数量。对于限制活动时间序列的数量非常有用。 -storage.maxDailySeries - 限制了最后一天可以添加的时间序列数量。对于限制每日流失率非常有用。 同时可以设置这两个限制。如果达到任何一个限制，那么新时间序列的输入样本将被丢弃。被丢弃的系列样本会以警告级别记录在日志中。\n超出限制的情况可以通过以下指标进行监控：\nvm_hourly_series_limit_rows_dropped_total - 由于超过每小时限制的唯一时间序列数量，指标数量减少了。 vm_hourly_series_limit_max_series - 每小时系列限制通过-storage.maxHourlySeries命令行参数设置。 vm_hourly_series_limit_current_series - 过去一小时内独特系列的当前数量。当过去一小时内独特系列的数量超过 -storage.maxHourlySeries 的90%时，以下查询可能会有用于警报：\nvm_hourly_series_limit_current_series / vm_hourly_series_limit_max_series \u003e 0.9 vm_daily_series_limit_rows_dropped_total - 由于超过每日唯一时间序列数量限制，指标数量下降。 vm_daily_series_limit_max_series - 每日系列限制是通过-storage.maxDailySeries命令行标志设置的。 vm_daily_series_limit_current_series - 在过去的一天中，唯一系列的当前数量。当唯一系列在过去的一天内超过 -storage.maxDailySeries 的90%时，以下查询可能会有用于警报：\nvm_daily_series_limit_current_series / vm_daily_series_limit_max_series \u003e 0.9 这些限制是近似值，所以VictoriaMetrics可以在限制范围内溢出/下溢一个小百分比（通常小于1%）。\n更多进阶内容参见 cardinality limiter in vmagent and cardinality explorer docs.\nTSDB状态 VictoriaMetrics在/api/v1/status/tsdb页面以类似Prometheus的方式返回TSDB统计信息-请参阅这些Prometheus文档。VictoriaMetrics在/api/v1/status/tsdb页面接受以下可选查询参数：\ntopN=N表示在响应中返回的前N个顶级条目数量。默认情况下，返回前10个条目。 date=YYYY-MM-DD 是收集统计数据的日期，其中 YYYY-MM-DD 代表具体的日期。默认情况下，统计数据是针对当天进行收集的。如果要跨所有日期收集全局统计数据，请传递 date=1970-01-01。 focusLabel=LABEL_NAME在seriesCountByFocusLabelValue列表中返回具有最高时间序列数量的给定LABEL_NAME的标签值。 match[]=SELECTOR where SELECTOR is an arbitrary time series selector for series to take into account during stats calculation. By default all the series are taken into account. match[]=SELECTOR 是一个任意的时间序列选择器，用于在统计计算中考虑的系列。默认情况下，所有系列都会被纳入考虑范围内。 extra_label=LABEL=VALUE. 更多信息参见 这些文档。 在VictoriaMetrics的集群版本中，每个vmstorage都会单独跟踪存储的时间序列。vmselect通过从每个vmstorage节点请求/api/v1/status/tsdb API来获取统计信息，并通过对每个系列的统计数据进行求和来合并结果。当相同时间序列的样本分布在多个vmstorage节点上时，可能会导致值被夸大，这是由于复制或重定向造成的。\nVictoriaMetrics /api/v1/status/tsdb 之上提供了-UI支持，具体参见 cardinality explorer docs.\nQuery 追踪 VictoriaMetrics支持查询追踪，可用于确定查询处理过程中的瓶颈。这类似于Postgresql的EXPLAIN ANALYZE。\n可以通过传递trace=1查询参数来启用特定查询的查询追踪。在这种情况下，VictoriaMetrics将查询跟踪放入输出JSON的trace字段中。\n例如，以下命令：\ncurl http://localhost:8428/api/v1/query_range -d 'query=2*rand()' -d 'start=-1h' -d 'step=1m' -d 'trace=1' | jq '.trace' 会返回下面的 trace 信息:\n{ \"duration_msec\": 0.099, \"message\": \"/api/v1/query_range: start=1654034340000, end=1654037880000, step=60000, query=\\\"2*rand()\\\": series=1\", \"children\": [ { \"duration_msec\": 0.034, \"message\": \"eval: query=2 * rand(), timeRange=[1654034340000..1654037880000], step=60000, mayCache=true: series=1, points=60, pointsPerSeries=60\", \"children\": [ { \"duration_msec\": 0.032, \"message\": \"binary op \\\"*\\\": series=1\", \"children\": [ { \"duration_msec\": 0.009, \"message\": \"eval: query=2, timeRange=[1654034340000..1654037880000], step=60000, mayCache=true: series=1, points=60, pointsPerSeries=60\" }, { \"duration_msec\": 0.017, \"message\": \"eval: query=rand(), timeRange=[1654034340000..1654037880000], step=60000, mayCache=true: series=1, points=60, pointsPerSeries=60\", \"children\": [ { \"duration_msec\": 0.015, \"message\": \"transform rand(): series=1\" } ] } ] } ] }, { \"duration_msec\": 0.004, \"message\": \"sort series by metric name and labels\" }, { \"duration_msec\": 0.044, \"message\": \"generate /api/v1/query_range response for series=1, points=60\" } ] } 所有跟踪中的持续时间和时间戳都以毫秒为单位。\n查询跟踪默认是允许的。可以通过在VictoriaMetrics上传递-denyQueryTracing命令行标志来禁止它。\nVMUI 提供了一个 UI 界面:\n对于 query 追踪 - 只需要选中 Trace query 复选框，然后重新跑一下查询语句就可以得到执行 Trace。 对于探索自定义追踪 - 进入 Trace analyzer 页面，然后上传或粘贴 trace 的 JSON 数据信息。 安全 一般安全建议：\n所有的VictoriaMetrics组件必须在受保护的私有网络中运行，不能直接从不可信任的网络（如互联网）访问。例外情况是vmauth和vmgateway。 来自不可信任网络到达VictoriaMetrics组件的所有请求都必须通过认证代理（例如vmauth或vmgateway）进行。代理必须设置适当的身份验证和授权。 在配置位于VictoriaMetrics组件前面的认证代理时，最好使用允许API端点列表，并禁止对其他端点进行访问。 VictoriaMetrics 提供了下面这些安全相关的命令行参数：\n-tls, -tlsCertFile and -tlsKeyFile 用来开启 HTTPS. -httpAuth.username and -httpAuth.password 使用 HTTP Basic Authentication 来保护所有的 HTTP 接口。 -deleteAuthKey 用来保护 /api/v1/admin/tsdb/delete_series 接口。参见 how to delete time series. -snapshotAuthKey 用来保护 /snapshot* 一系列接口。参见 how to work with snapshots. -forceMergeAuthKey 用来保护 /internal/force_merge 接口。参见 force merge docs. -search.resetCacheAuthKey 用来保护 /internal/resetRollupResultCache 接口。 更多详情参见 backfilling。 -configAuthKey 用来保护 /config 接口，因为它可能包含一些敏感的信息，比如密码。 -flagsAuthKey 用来保护 /flags 接口。 -pprofAuthKey 用来保护 /debug/pprof/* 接口，这是用来做性能分析的 profiling。 -denyQueryTracing 用来禁用 query tracing. Explicitly set internal network interface for TCP and UDP ports for data ingestion with Graphite and OpenTSDB formats. For example, substitute -graphiteListenAddr=:2003 with -graphiteListenAddr=\u003cinternal_iface_ip\u003e:2003. This protects from unexpected requests from untrusted network interfaces.\n明确设置用于使用Graphite和OpenTSDB格式进行数据摄取的TCP和UDP端口的内部网络接口。例如，将-graphiteListenAddr=:2003替换为-graphiteListenAddr=\u003cinternal_iface_ip\u003e:2003。这样可以防止来自不受信任的网络接口的意外请求。\n参见 security recommendation for VictoriaMetrics cluster and the general security page at VictoriaMetrics website."},"title":"单机版本"},"/docs/query/http/":{"data":{"":"","单机版#单机版":"Prometheus 查询接口 VictoriaMetrics 支持下面这些 Prometheus 查询 API:\n/api/v1/query /api/v1/query_range /api/v1/series /api/v1/labels /api/v1/label/…/values /api/v1/status/tsdb. See these docs for details. /api/v1/targets - see these docs for more details. /federate - see these docs for more details. 这些接口可以被Prometheus兼容的客户端（如Grafana或curl）查询。所有Prometheus查询API处理程序都可以使用/prometheus前缀进行查询。例如，/prometheus/api/v1/query和/api/v1/query都可以正常工作。\n查询优化 VictoriaMetrics 接受extra_label=\u003clabel_name\u003e=\u003clabel_value\u003e查询参数（可选），可以用于强制使用额外 Label 过滤器执行查询。例如，/api/v1/query_range?extra_label=user_id=123\u0026extra_label=group_id=456\u0026query=\u003cquery\u003e会自动将{user_id=\"123\",group_id=\"456\"}Label 过滤器添加到给定的查询中。此功能可用于限制给定租户可见的 timeseries 范围。一般extra_label查询参数由位于 VictoriaMetrics 前面的查询代理服务自动设置。例如，可以参考使用 vmauth 和 vmgateway 作为查询代理的示例。 VictoriaMetrics 接受extra_filters[]=series_selector查询参数（可选），可用于对查询强制执行任意的 Label 过滤器。例如，/api/v1/query_range?extra_filters[]={env=~\"prod|staging\",user=\"xyz\"}\u0026query=\u003cquery\u003e将自动将{env=~\"prod|staging\",user=\"xyz\"}Label 过滤器添加到给定的查询中。此功能可用于限制给定租户可见的 timeseries 范围。我们建议在 VictoriaMetrics 前面的查询代理自动设置extra_filters[]查询参数。您可以将vmauth和vmgateway作为这种代理的示例。 VictoriaMetrics 接受多种格式的 time，start 和 end 查询参数，可参考这些文档。 VictoriaMetrics对于/api/v1/query和/api/v1/query_range接口支持round_digits查询参数。它可用于指定返回的指标值的保留小数点位数。例如，/api/v1/query?query=avg_over_time(temperature[1h])\u0026round_digits=2会将让返回的指标值保留小数点后面 2 位。 VictoriaMetrics允许在/api/v1/labels和/api/v1/label//values接口中使用limit查询参数来限制返回的条目数量。例如，对/api/v1/labels?limit=5的查询请求最多返回5个唯一的 Label 值，并忽略其他 Label。如果提供的limit值超过了相应的-command-line命令行参数-search.maxTagKeys或-search.maxTagValues，则会使用命令行参数中指定的限制。 默认情况下，VictoriaMetrics从/api/v1/series、/api/v1/labels和/api/v1/label//values返回最近一天从00:00 UTC开始的 series 数据，而Prometheus API默认返回所有时间的数据。如果要选择特定的时间范围的 series 数据，可使用 start 和 end 参数指定。由于性能优化的考虑，VictoriaMetrics会将指定的 start..end 时间范围舍入到天的粒度。如果您需要在给定时间范围内获取精确的 Label 集合，请将查询发送到/api/v1/query或/api/v1/query_range。 VictoriaMetrics在/api/v1/series中接受limit查询参数，用于限制返回的条目数量。例如，对/api/v1/series?limit=5的查询将最多返回5个 series，并忽略其余的时间序列。如果提供的limit值超过了相应的命令行参数-search.maxSeries的值，则会使用命令行中指定的限制。 此外，VictoriaMetrics还提供了以下接口： /vmui - 基本的 Web UI 界面，阅读这些文档。 /api/v1/series/count - 返回数据库中 time series 的总数量。注意： 该接口扫描了整个数据库的倒排索引，所以如果数据库包含数千万个 series 时间序列，它可能会变慢。 该接口可能把删除 time series 计算在内，这是内部实现导致的。 /api/v1/status/active_queries - 返回当前正在执行的查询。 /api/v1/status/top_queries - 返回下面几个查询列表: 执行最频繁的查询列表 - topByCount 平均执行时间最长的查询列表 - topByAvgDuration 执行时间最长的查询列表 - topBySumDuration 返回的查询个数可以使用 topN 参数进行限制。历史查询可以使用 maxLifetime 参数过滤掉。比如，请求/api/v1/status/top_queries?topN=5\u0026maxLifetime=30s返回最近 30 秒内每个类型的 Top5 个查询列表。VictoriaMetrics 会跟踪统计最近-s earch.queryStats.lastQueriesCount时间内，且执行时间大于search.queryStats.minQueryDuration的查询。 Timestamp 格式 VictoriaMetrics 接受下面这些格式的 time, start and end 参数， 在 query APIs 和 export APIs 中皆是如此。\nUnix 秒级时间戳，float 类型，小数部分代表的是毫秒。比如，1562529662.678。 Unix 毫秒级时间戳。比如，1562529662678。 RFC3339。比如， 2022-03-29T01:02:03Z or 2022-03-29T01:02:03+02:30. RFC3339 的省略格式。比如：2022, 2022-03, 2022-03-29, 2022-03-29T01, 2022-03-29T01:02, 2022-03-29T01:02:03。该 RFC3339 格式默认是使用 UTC 时区的。可以使用 +hh:mm or -hh:mm 后缀来指定时区。比如，2022-03-01+06:30 代表 2022-03-01 是 06:30 时区。 基于当前时间的相对时间。比如，1h5m, -1h5m或 now-1h5m 均代表 1小时5分钟之前，这里的 now 表示当前时间。 Graphite API VictoriaMetrics支持Graphite协议的数据摄入——详见这些文档。VictoriaMetrics支持以下Graphite查询API，这些API对于Grafana中的Graphite数据源是必需的：\nRender API - 看 这些文档。 Metrics API - 看 这些文档。 Tags API - 看 这些文档。 所有Graphite处理程序都可以使用/graphite前缀。例如，/graphite/metrics/find和/metrics/find都应该有效。\nVictoriaMetrics接受可选查询参数：extra_label=\u003c标签名\u003e=\u003c标签值\u003e和extra_filters[]=series_selector，这些参数适用于所有Graphite API。这些参数可用于限制给定租户可见的时间序列范围。预计extra_label查询参数将由位于VictoriaMetrics前方的身份验证代理自动设置。vmauth和vmgateway是此类代理的示例。\nVictoriaMetrics支持__graphite__伪标签，用于在MetricsQL中使用与Graphite兼容的过滤器过滤时间序列。详见这些文档。\nGraphite Render API 用法 VictoriaMetrics在/render url 上支持Graphite Render API子集，Grafana中的Graphite数据源会使用这一功能。在Grafana中配置Graphite数据源时，必须将Storage-Step HTTP请求头设置为VictoriaMetrics中存储的Graphite数据点之间的步长。例如，Storage-Step: 10s表示VictoriaMetrics中存储的Graphite数据点之间相隔10秒。\nGraphite Metrics API 用法 VictoriaMetrics 支持 Graphite Metrics API 中的一下接口：\n/metrics/find /metrics/expand /metrics/index.json VictoriaMetrics /metrics/find 和 /metrics/expand接口上支持以下额外的参数:\nlabel - 用于选择任意标签值。默认情况下，label=__name__，即选择度量名称。 delimiter - 用于在度量名称层次结构中使用不同的分隔符。例如，/metrics/find?delimiter=``\u0026query=node``* 将返回所有以node_开头的度量名称前缀。默认情况下，delimiter=.。 Graphite Tags API usage VictoriaMetrics 支持下面这些 Graphite Tags API:\n/tags/tagSeries /tags/tagMultiSeries /tags /tags/{tag_name} /tags/findSeries /tags/autoComplete/tags /tags/autoComplete/values /tags/delSeries ","集群版#集群版":"集群版本和单机版的API接口主要区别是数据的读取和写入是由独立组件完成的，而且也有了租户的支持。集群版本也支持/prometheus/api/v1来接收 jsonl, csv, native 和 prometheus数据格式，而不仅仅是prometheus数据格式。可以在这里查看VictoriaMetrics的API的使用范例。\nPrometheus 查询 API http://\u003cvmselect\u003e:8481/select/\u003caccountID\u003e/prometheus/\u003csuffix\u003e, 其中:\n\u003caccountID\u003e 是一个任意32位数字，用来标识查询的空间（即租户）。 \u003csuffix\u003e 可以是一下的内容： api/v1/query - 执行 PromQL instant. api/v1/query_range - 执行 PromQL range 查询。 api/v1/series - 执行 series 查询。 api/v1/labels - 返回 label 名称列表。 api/v1/label/\u003clabel_name\u003e/values - 返回指定 \u003clabel_name\u003e 的所有值，参考这个 API. federate - 返回 federated metrics. api/v1/export - 导出 JSON line 格式的原始数据，更多信息看这篇文章。 api/v1/export/native - 导出原生二进制格式的原始数据，该数据可以通过另一个接口api/v1/import/native导入到 VictoriaMetrics (见上文). api/v1/export/csv - 导出 CSV 格式原始数据。它可以使用另外一个接口 api/v1/import/csv 导入到 VictoriaMetrics（见上文）。 api/v1/series/count - 返回 series 的总数。 api/v1/status/tsdb - 返回时序数据的统计信息。更多详细信息见这些文档。 api/v1/status/active_queries - 返回当前活跃的查询请求。逐一每个 vmselect 实例都有独立的活跃查询列表。 api/v1/status/top_queries - 返回执行频率最高以及查询耗时最长的查询列表。 metric-relabel-debug - 用于对 relabeling 规则 Debug。 Graphite Metrics API http://\u003cvmselect\u003e:8481/select/\u003caccountID\u003e/graphite/\u003csuffix\u003e, 其中:\n\u003caccountID\u003e 是一个任意32位数字，用来标识查询的空间（即租户）。 \u003csuffix\u003e 可以是一下的内容： render - 实现 Graphite Render API. 看 these docs. metrics/find - 搜索 Graphite metrics. See these docs. metrics/expand - 扩展 Graphite metrics. See these docs. metrics/index.json - returns 所有的 names. See these docs. tags/tagSeries - 注册 time series. See these docs. tags/tagMultiSeries - 批量注册 time series. See these docs. tags - 返回 tag 名称列表. See these docs. tags/\u003ctag_name\u003e - 返回指定 \u003ctag_name\u003e的值列表 See these docs. tags/findSeries - 返回匹配expr的 series，these docs. tags/autoComplete/tags - 返回匹配 tagPrefix 和/或 expr的tag名称列表。 See these docs. tags/autoComplete/values - 返回匹配 valuePrefix 和/或 expr tag值列表 See these docs. tags/delSeries - deletes series matching the given path. See these docs. "},"title":"HTTP 查询接口"},"/docs/query/metricsql/":{"data":{"":"VictoriaMetrics提供了一种特殊的查询语言，用于执行查询语句 - MetricsQL。它是一个类似PromQL的查询语言，具有强大的函数和功能集，专门用于处理时间序列数据。MetricsQL完全兼容PromQL，因此他们之间大部分概念都是共享的。\n所以，使用VictoriaMetrics替换Prometheus后，由Prometheus数据源创建的Grafana仪表板不会收到任何影响。然而，这两种语言之间存在一定的差异。\n一个独立的 MetricQL 库可用于在其他应用中解析 MetricQL 语句。\n如果你对 PromQL 不熟，建议阅读一下这篇文章。\nMetricsQL在以下功能上与PromQL实现方式不同，它们改进了用户体验：\nMetricsQL在计算范围函数（如rate和increase）时，考虑了方括号中窗口之前的上一个点。这样可以返回用户对于increase(metric[$__interval])查询所期望的精确结果，而不是Prometheus为此类查询返回的不完整结果。 MetricsQL不会推断范围函数的结果。这解决了Prometheus中存在的问题。有关VictoriaMetrics和Prometheus计算rate和increase的技术细节，请参阅 issue。 MetricsQL对于 step 小于抓取间隔的rate查询返回预期非空响应。这解决了Grafana中存在的问题。还请参阅这篇文章。 MetricsQL将scalar类型与没有 Label 的instant vector视为相同，因为这些类型之间微小差异通常会让用户感到困惑。有关详细信息，请参阅相应的Prometheus文档。 MetricsQL从输出中删除所有NaN值，因此一些查询（例如(-1)^0.5）在VictoriaMetrics中返回空结果，在Prometheus中则返回一系列NaN值。请注意，Grafana不会为NaN值绘制任何线条或点，因此最终结果在VictoriaMetrics和Prometheus上看起来是相同的。 在应用函数后， MetricsQL保留指标名称，并且该函数不改变原始时间序列的含义。例如，min_over_time(foo)或round(foo)将在结果中保留foo指标名称。有关详细信息，请参阅issue。 ","keep_metric_names#keep_metric_names":"By default, metric names are dropped after applying functions, which change the meaning of the original time series. This may result in duplicate time series error when the function is applied to multiple time series with different names. This error can be fixed by applying keep_metric_names modifier to the function.\nFor example, rate({__name__=~\"foo|bar\"}) keep_metric_names leaves foo and bar metric names in the returned time series.","metricql-功能特性#MetricQL 功能特性":"MetricsQL implements PromQL and provides additional functionality mentioned below, which is aimed towards solving practical cases. Feel free filing a feature request if you think MetricsQL misses certain useful functionality.\nThis functionality can be evaluated at VictoriaMetrics playground or at your own VictoriaMetrics instance.\nThe list of MetricsQL features:\nGraphite-compatible filters can be passed via {__graphite__=\"foo.*.bar\"} syntax. See these docs. VictoriaMetrics also can be used as Graphite datasource in Grafana. See these docs for details. See also label_graphite_group function, which can be used for extracting the given groups from Graphite metric name. Lookbehind window in square brackets may be omitted. VictoriaMetrics automatically selects the lookbehind window depending on the current step used for building the graph (e.g. step query arg passed to /api/v1/query_range). For instance, the following query is valid in VictoriaMetrics: rate(node_network_receive_bytes_total). It is equivalent to rate(node_network_receive_bytes_total[$__interval]) when used in Grafana. Series selectors accept multiple or filters. For example, {env=\"prod\",job=\"a\" or env=\"dev\",job=\"b\"} selects series with either {env=\"prod\",job=\"a\"} or {env=\"dev\",job=\"b\"} labels. See these docs for details. Aggregate functions accept arbitrary number of args. For example, avg(q1, q2, q3) would return the average values for every point across time series returned by q1, q2 and q3. @ modifier can be put anywhere in the query. For example, sum(foo) @ end() calculates sum(foo) at the end timestamp of the selected time range [start ... end]. Arbitrary subexpression can be used as @ modifier. For example, foo @ (end() - 1h) calculates foo at the end - 1 hour timestamp on the selected time range [start ... end]. offset, lookbehind window in square brackets and step value for subquery may refer to the current step aka $__interval value from Grafana with [Ni] syntax. For instance, rate(metric[10i] offset 5i) would return per-second rate over a range covering 10 previous steps with the offset of 5 steps. offset may be put anywhere in the query. For instance, sum(foo) offset 24h. Lookbehind window in square brackets and offset may be fractional. For instance, rate(node_network_receive_bytes_total[1.5m] offset 0.5d). The duration suffix is optional. The duration is in seconds if the suffix is missing. For example, rate(m[300] offset 1800) is equivalent to rate(m[5m]) offset 30m. The duration can be placed anywhere in the query. For example, sum_over_time(m[1h]) / 1h is equivalent to sum_over_time(m[1h]) / 3600. Numeric values can have K, Ki, M, Mi, G, Gi, T and Ti suffixes. For example, 8K is equivalent to 8000, while 1.2Mi is equivalent to 1.2*1024*1024. Trailing commas on all the lists are allowed - label filters, function args and with expressions. For instance, the following queries are valid: m{foo=\"bar\",}, f(a, b,), WITH (x=y,) x. This simplifies maintenance of multi-line queries. Metric names and label names may contain any unicode letter. For example температура{город=\"Киев\"} is a value MetricsQL expression. Metric names and labels names may contain escaped chars. For example, foo\\-bar{baz\\=aa=\"b\"} is valid expression. It returns time series with name foo-bar containing label baz=aa with value b. Additionally, the following escape sequences are supported: \\xXX, where XX is hexadecimal representation of the escaped ascii char. \\uXXXX, where XXXX is a hexadecimal representation of the escaped unicode char. Aggregate functions support optional limit N suffix in order to limit the number of output series. For example, sum(x) by (y) limit 3 limits the number of output time series after the aggregation to 3. All the other time series are dropped. histogram_quantile accepts optional third arg - boundsLabel. In this case it returns lower and upper bounds for the estimated percentile. See this issue for details. default binary operator. q1 default q2 fills gaps in q1 with the corresponding values from q2. if binary operator. q1 if q2 removes values from q1 for missing values from q2. ifnot binary operator. q1 ifnot q2 removes values from q1 for existing values from q2. WITH templates. This feature simplifies writing and managing complex queries. Go to WITH templates playground and try it. String literals may be concatenated. This is useful with WITH templates: WITH (commonPrefix=\"long_metric_prefix_\") {__name__=commonPrefix+\"suffix1\"} / {__name__=commonPrefix+\"suffix2\"}. keep_metric_names modifier can be applied to all the rollup functions and transform functions. This modifier prevents from dropping metric names in function results. See these docs. "},"title":"MetricQL"},"/docs/query/metricsql/basic/":{"data":{"":"","keep_metric_names#keep_metric_names":"默认情况下，Metric 名称会在应用函数或算数运算后被丢弃，因为它们会改变原始指标的含义。当函数作用于多个名称不同的时间序列时，可能会导致duplicate time series错误。这个错误可以使用keep_metric_names修改器来解决。\n例如：\nrate({__name__=~\"foo|bar\"}) keep_metric_names会在查询结算结果中保留foo和bar这 2 个 Metric 名称。 ({__name__=~\"foo|bar\"} / 10) keep_metric_names会在查询结算结果中保留foo和bar这 2 个 Metric 名称。 ","比较运算#比较运算":"MetricsQL 支持下面这些比较运算符：\n等于 - == 不等于 - != 大于 - \u003e 大于等于 - \u003e= 小于 - \u003c 小于等于 - \u003c= 这些运算符可以像算术运算符一样应用于任意的 MetricsQL 表达式。比较运算的结果是只包含 value 匹配成功的的 Timeseries。例如，下面的查询将仅返回内存使用超过100MB的进程列表。\nprocess_resident_memory_bytes \u003e 100*1024*1024 ","算数运算#算数运算":"MetricsQL 支持所有基本的算数运算：\n加法 - + 减法 - - 乘法 - * 除法 - / 取模 - % 指数 - ^ 我们可以在多个指标之间进行各种计算。比如，下面的查询语句就是计算错误请求率：\n(requests_error_total / (requests_error_total + requests_success_total)) * 100 合并多个 Timeseries 要使用算术运算合并多个 Timeseries ，我们需要了解匹配规则。否则，查询会出错或给出错误的结果。匹配规则的逻辑很简单：\nMetricsQL引擎在不影响 Label 的情况下，从算术操作左右两侧的所有 Timeseries 中去除指标名称。 对于左侧的每个 Timeseries，MetricsQL 引擎会在右侧搜索具有相同 Label Set 的 Timeseries，对每个数据点执行运算操作，并返回具有相同 Label Set 的结果时间序列。如果没有匹配项，则结果时间序列将从结果中删除。 匹配规则可以通过ignore、on、group_left和group_right运算符进行扩展。详细信息请参阅这些文档。 ","聚合与分组函数#聚合与分组函数":"MetricsQL 支持对 Timeseries 进行分组聚合。Timeseries 使用指定的一组 Label 进行分组，然后使用指定的聚合方法对每组 Timeseries 的 value 做聚合计算。 比如，下面的查询返回每个 job 的 内存使用率总和：\nsum(process_resident_memory_bytes) by (job) 更多参见 MetricsQL 的聚合函数文档。","计算速率#计算速率":"对于 Counter 类型指标使用最广泛的的一个函数是 rate。它对每一个 Timeseries 独立计算每秒的平均增长率。比如，下面的查询返回的是每一个 node_exporter 实例监控到的每秒平均入流量， node_network_receive_bytes_total 指标是它暴露出来的一个监控指标。\nrate(node_network_receive_bytes_total) 默认情况下，无论是 Instance Query 还是 Range Query，VictoriaMetrics 都使用 step 参数指定的窗口大小，对回溯区间内的样本执行 rate 计算。rate 需要计算的时间间隔可以在一个中括号中指定。比如：\nrate(node_network_receive_bytes_total[5m]) 在这个例子中，VictoriaMetrics 使用指定的回溯窗口 5m(5分钟)。来计算平均每秒增长。通常情况下回溯窗口越大，曲线图形就约平滑。\nrate 会保留 timeseries 中的所有 Label，除了 Metric 名称。如果你想要保留 Metric 名称，就需要在 rate(...) 后面使用 keep_metric_names 修改器。比如，下面的语句就是在计算 rate() 后保留 Metric 名称：\nrate(node_network_receive_bytes_total) keep_metric_names rate() 能且只能用于 Counter 类指标。对 Gauge 类型指标应用 rate 是没意义的。","过滤器#过滤器":"在数据查询部分我们已经用 MetricsQL 获取了指标 foo_bar 的数据。只需在查询中写入指标名称，就能轻松完成：\nfoo_bar 一个简单的指标名称会得到拥有不同 label 组合的多个 Timeseries 返回响应值。比如：\nrequests_total{path=\"/\", code=\"200\"} requests_total{path=\"/\", code=\"403\"} 要选择具有特定 Label 的 Timeseries，需要在花括号中指定匹配 Label 的过滤器：\nrequests_total{code=\"200\"} 上面的查询语句返回所有名字是 requests_total 并且 Label 带有code=\"200\"的所有Timeseries。我们用=运算符来匹配 Label 值。对于反匹配使用!=运算符。过滤器也通过=~实现正则匹配，用!~实现正则反匹配。\nrequests_total{code=~\"2.*\"} 过滤器也可以被组合使用：\nrequests_total{code=~\"200\", path=\"/home\"} 上面的查询返回所有名字是request_total，同时带有 code=\"200\" 和 path=\"/home\" Label 的所有 Timeseries。\n使用名字过滤 有时我们可能需要同时返回多个监控指标。就如同数据模型中提到的，Metric 名称本质上也是一个普通的 Label 的值，其 Label 名是__name__。所以可以通过对 Metric 名使用正则的方式，来过滤出多个指标名的数据：\n{__name__=~\"requests_(error|success)_total\"} 上面的查询语句会返回 2 个 Metric 的 Timeseries：requests_error_total 和requests_success_total.\n利用 or 使用多个过滤器 MetricsQL 支持查询至少满足多个过滤器中的一个方式来获取 Timeseries。这些过滤器必须在花括号内使用 or 分割。 比如，下面的查询代表查询 Label 满足 {job=\"app1\",env=\"prod\"} 或 {job=\"app2\",env=\"dev\"} 的 Timeseries：\n{job=\"app1\",env=\"prod\" or job=\"app2\",env=\"dev\"} 过滤器的个数是没有限制的。这个功能可以对查询到的 series 直接运用 rollup 函数（比如 rate），这样就不需要使用子查询了：\nrate({job=\"app1\",env=\"prod\" or job=\"app2\",env=\"dev\"}[5m]) 如果你需要对同一 Label 使用多个过滤器来查询 Timeseries，从性能角度来看，最好使用正则表达式{label=~\"value1|...|valueN\"} 而不是使用{label=\"value1\" or ... or label=\"valueN\"}。"},"title":"基本用法"},"/docs/query/metricsql/functions/aggregation/":{"data":{"":"","#":"Aggregate functions calculate aggregates over groups of rollup results.\nAdditional details:\nBy default, a single group is used for aggregation. Multiple independent groups can be set up by specifying grouping labels in by and without modifiers. For example, count(up) by (job) would group rollup results by job label value and calculate the count aggregate function independently per each group, while count(up) without (instance) would group rollup results by all the labels except instance before calculating count aggregate function independently per each group. Multiple labels can be put in by and without modifiers. If the aggregate function is applied directly to a series_selector, then the default_rollup() function is automatically applied before calculating the aggregate. For example, count(up) is implicitly transformed to count(default_rollup(up)). Aggregate functions accept arbitrary number of args. For example, avg(q1, q2, q3) would return the average values for every point across time series returned by q1, q2 and q3. Aggregate functions support optional limit N suffix, which can be used for limiting the number of output groups. For example, sum(x) by (y) limit 3 limits the number of groups for the aggregation to 3. All the other groups are ignored. See also implicit query conversions.\nThe list of supported aggregate functions:\nany # any(q) by (group_labels) is aggregate function, which returns a single series per group_labels out of time series returned by q.\nSee also group.\navg # avg(q) by (group_labels) is aggregate function, which returns the average value per group_labels for time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nbottomk # bottomk(k, q) is aggregate function, which returns up to k points with the smallest values across all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nSee also topk, bottomk_min and #bottomk_last.\nbottomk_avg # bottomk_avg(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the smallest averages. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, bottomk_avg(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the smallest averages plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also topk_avg.\nbottomk_last # bottomk_last(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the smallest last values. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, bottomk_max(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the smallest maximums plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also topk_last.\nbottomk_max # bottomk_max(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the smallest maximums. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, bottomk_max(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the smallest maximums plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also topk_max.\nbottomk_median # bottomk_median(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the smallest medians. If an optionalother_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, bottomk_median(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the smallest medians plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also topk_median.\nbottomk_min # bottomk_min(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the smallest minimums. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, bottomk_min(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the smallest minimums plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also topk_min.\ncount # count(q) by (group_labels) is aggregate function, which returns the number of non-empty points per group_labels for time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\ncount_values # count_values(\"label\", q) is aggregate function, which counts the number of points with the same value and stores the counts in a time series with an additional label, which contains each initial value. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nSee also count_values_over_time and label_match.\ndistinct # distinct(q) is aggregate function, which calculates the number of unique values per each group of points with the same timestamp.\nSee also distinct_over_time.\ngeomean # geomean(q) is aggregate function, which calculates geometric mean per each group of points with the same timestamp.\ngroup # group(q) by (group_labels) is aggregate function, which returns 1 per each group_labels for time series returned by q.\nThis function is supported by PromQL. See also any.\nhistogram # histogram(q) is aggregate function, which calculates VictoriaMetrics histogram per each group of points with the same timestamp. Useful for visualizing big number of time series via a heatmap. See this article for more details.\nSee also histogram_over_time and histogram_quantile.\nlimitk # limitk(k, q) by (group_labels) is aggregate function, which returns up to k time series per each group_labels out of time series returned by q. The returned set of time series remain the same across calls.\nSee also limit_offset.\nmad # mad(q) by (group_labels) is aggregate function, which returns the Median absolute deviation per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nSee also range_mad, mad_over_time, outliers_mad and stddev.\nmax # max(q) by (group_labels) is aggregate function, which returns the maximum value per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nmedian # median(q) by (group_labels) is aggregate function, which returns the median value per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nmin # min(q) by (group_labels) is aggregate function, which returns the minimum value per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nmode # mode(q) by (group_labels) is aggregate function, which returns mode per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\noutliers_iqr # outliers_iqr(q) is aggregate function, which returns time series from q with at least a single point outside e.g. Interquartile range outlier bounds [q25-1.5*iqr .. q75+1.5*iqr] comparing to other time series at the given point, where:\niqr is an Interquartile range calculated independently per each point on the graph across q series. q25 and q75 are 25th and 75th percentiles calculated independently per each point on the graph across q series. The outliers_iqr() is useful for detecting anomalous series in the group of series. For example, outliers_iqr(temperature) by (country) returns per-country series with anomalous outlier values comparing to the rest of per-country series.\nSee also outliers_mad, outliersk and outlier_iqr_over_time.\noutliers_mad # outliers_mad(tolerance, q) is aggregate function, which returns time series from q with at least a single point outside Median absolute deviation (aka MAD) multiplied by tolerance. E.g. it returns time series with at least a single point below median(q) - mad(q) or a single point above median(q) + mad(q).\nSee also outliers_iqr, outliersk and mad.\noutliersk # outliersk(k, q) is aggregate function, which returns up to k time series with the biggest standard deviation (aka outliers) out of time series returned by q.\nSee also outliers_iqr and outliers_mad.\nquantile # quantile(phi, q) by (group_labels) is aggregate function, which calculates phi-quantile per each group_labels for all the time series returned by q. phi must be in the range [0...1]. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nSee also quantiles and histogram_quantile.\nquantiles # quantiles(\"phiLabel\", phi1, ..., phiN, q) is aggregate function, which calculates phi*-quantiles for all the time series returned by q and return them in time series with {phiLabel=\"phi*\"} label. phi* must be in the range [0...1]. The aggregate is calculated individually per each group of points with the same timestamp.\nSee also quantile.\nshare # share(q) by (group_labels) is aggregate function, which returns shares in the range [0..1] for every non-negative points returned by q per each timestamp, so the sum of shares per each group_labels equals 1.\nThis function is useful for normalizing histogram bucket shares into [0..1] range:\nshare( sum( rate(http_request_duration_seconds_bucket[5m]) ) by (le, vmrange) ) MetricsQL\nCopy\nSee also range_normalize.\nstddev # stddev(q) by (group_labels) is aggregate function, which calculates standard deviation per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nstdvar # stdvar(q) by (group_labels) is aggregate function, which calculates standard variance per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nsum # sum(q) by (group_labels) is aggregate function, which returns the sum per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nsum2 # sum2(q) by (group_labels) is aggregate function, which calculates the sum of squares per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\ntopk # topk(k, q) is aggregate function, which returns up to k points with the biggest values across all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp.\nThis function is supported by PromQL.\nSee also bottomk, topk_max and topk_last.\ntopk_avg # topk_avg(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the biggest averages. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, topk_avg(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the biggest averages plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also bottomk_avg.\ntopk_last # topk_last(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the biggest last values. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, topk_max(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the biggest maximums plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also bottomk_last.\ntopk_max # topk_max(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the biggest maximums. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, topk_max(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the biggest maximums plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also bottomk_max.\ntopk_median # topk_median(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the biggest medians. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, topk_median(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the biggest medians plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also bottomk_median.\ntopk_min # topk_min(k, q, \"other_label=other_value\") is aggregate function, which returns up to k time series from q with the biggest minimums. If an optional other_label=other_value arg is set, then the sum of the remaining time series is returned with the given label. For example, topk_min(3, sum(process_resident_memory_bytes) by (job), \"job=other\") would return up to 3 time series with the biggest minimums plus a time series with {job=\"other\"} label with the sum of the remaining series if any.\nSee also bottomk_min.\nzscore # zscore(q) by (group_labels) is aggregate function, which returns z-score values per each group_labels for all the time series returned by q. The aggregate is calculated individually per each group of points with the same timestamp. This function is useful for detecting anomalies in the group of related time series.\nSee also zscore_over_time, range_trim_zscore and outliers_iqr."},"title":"聚合统计"},"/docs/query/metricsql/functions/label/":{"data":{"":"","#":"Label 操作函数对选定的 Rollup 计算结果进行 Label 转换。\n附加细节：\n如果 Label 操作函数直接应用于\u003cfont style=\"color:rgb(34, 34, 34);\"\u003eseries_selector\u003c/font\u003e，那么在执行 Label 转换之前，会自动应用[default_rollup](https://docs.victoriametrics.com/metricsql/#default_rollup)\u003cfont style=\"color:rgb(34, 34, 34);\"\u003e()\u003c/font\u003e函数。例如，\u003cfont style=\"color:rgb(34, 34, 34);\"\u003ealias(temperature, \"foo\")\u003c/font\u003e 会被隐式转换为 \u003cfont style=\"color:rgb(34, 34, 34);\"\u003ealias(default_rollup(temperature), \"foo\")\u003c/font\u003e。 请参阅[隐式查询转换](implicit query conversions)。\n支持的 Label 操作函数如下：\nalias alias(q, \"name\") 将q返回的所有时间序列更名为name。例如，alias(up, \"foobar\") 会将up序列重命名为foobar 序列。\ndrop_common_labels drop_common_labels(q1, ...., qN)会删除 q1, ..., qN 返回的时间序列中共有的label=\"value\"。\nlabel_copy label_copy(q, \"src_label1\", \"dst_label1\", ..., \"src_labelN\", \"dst_labelN\")将\u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_label*\u003c/font\u003e的 Label 值复制到\u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e返回的所有时间序列的\u003cfont style=\"color:rgb(31, 35, 41);\"\u003edst_label*\u003c/font\u003e。如果\u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_label\u003c/font\u003e为空，则相应的 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003edst_label\u003c/font\u003e保持不变。\nlabel_del label_del(q, \"label1\", ..., \"labelN\") 删除\u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e返回的所有时间序列中名为\u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel*\u003c/font\u003e的所有 Label。\nlabel_join label_join(q, \"dst_label\", \"separator\", \"src_label1\", ..., \"src_labelN\")\n它将\u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_label*\u003c/font\u003e的值用给定的\u003cfont style=\"color:rgb(31, 35, 41);\"\u003eseparator\u003c/font\u003e连接起来，并将结果存储在\u003cfont style=\"color:rgb(31, 35, 41);\"\u003edst_label\u003c/font\u003e中。这是针对 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e 返回的每条时间序列独立执行的。例如，\u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel_join(up{instance=\"xxx\",job=\"yyy\"}, \"foo\", \"-\", \"instance\", \"job\")\u003c/font\u003e 会将\u003cfont style=\"color:rgb(31, 35, 41);\"\u003exxx-yyy\u003c/font\u003e标签值存储到\u003cfont style=\"color:rgb(31, 35, 41);\"\u003efoo\u003c/font\u003e标签中。\n该函数在 PromQL 中也支持。\nlabel_keep label_keep(q, \"label1\", ..., \"labelN\")删除 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e 返回的所有时间序列中除列出的 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel*\u003c/font\u003e Label 之外的其他所有 Label。\nlabel_lowercase label_lowercase(q, \"label1\", ..., \"labelN\")将 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e 返回的所有时间序列中名为\u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel*\u003c/font\u003e的 Label 值转换成小写字母。\nlabel_map label_map(q, \"label\", \"src_value1\", \"dst_value1\", ..., \"src_valueN\", \"dst_valueN\")遍历 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e 返回的所有时间序列，将所有 Label 值是\u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_value*\u003c/font\u003e的 Label 值对应的\u003cfont style=\"color:rgb(31, 35, 41);\"\u003edst_value*\u003c/font\u003e。\nlabel_match label_match(q, \"label\", \"regexp\")会删除 \u003cfont style=\"color:rgb(34, 34, 34);\"\u003eq\u003c/font\u003e 中\u003cfont style=\"color:rgb(34, 34, 34);\"\u003elabel\u003c/font\u003e值不匹配给定正则表达式\u003cfont style=\"color:rgb(34, 34, 34);\"\u003eregexp\u003c/font\u003e的时间序列。此函数在类 rollup 函数之后会比较有用，因为这些类 rollup 函数可能会为每个输入序列返回多个时间序列。\n另请参见 label_mismatch 和 labels_equal。\nlabel_mismatch label_mismatch(q, \"label\", \"regexp\")会删除 \u003cfont style=\"color:rgb(34, 34, 34);\"\u003eq\u003c/font\u003e 中\u003cfont style=\"color:rgb(34, 34, 34);\"\u003elabel\u003c/font\u003e值匹配给定正则表达式\u003cfont style=\"color:rgb(34, 34, 34);\"\u003eregexp\u003c/font\u003e的时间序列。此函数在类 rollup 函数之后会比较有用，因为这些类 rollup 函数可能会为每个输入序列返回多个时间序列。\nSee also label_match and labels_equal.\nlabel_move label_move(q, \"src_label1\", \"dst_label1\", ..., \"src_labelN\", \"dst_labelN\")它将\u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_label*\u003c/font\u003e的 Label 值移动到\u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e返回的所有时间序列的\u003cfont style=\"color:rgb(31, 35, 41);\"\u003edst_label*\u003c/font\u003e。如果 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_label\u003c/font\u003e 为空，则相应的 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003edst_label\u003c/font\u003e 保持不变。\nlabel_replace label_replace(q, \"dst_label\", \"replacement\", \"src_label\", \"regex\")它将给定的正则表达式 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eregexp\u003c/font\u003e 应用于 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_label\u003c/font\u003e，如果给定的正则表达式匹配 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003esrc_label\u003c/font\u003e，则将替换内容存储在 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003edst_label\u003c/font\u003e 中。替换内容可以包含对正则表达式捕获组的引用，例如 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003e$1\u003c/font\u003e、\u003cfont style=\"color:rgb(31, 35, 41);\"\u003e$2\u003c/font\u003e 等。这些引用会被相应的正则表达式捕获组替换。例如，\u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel_replace(up{job=\"node-exporter\"}, \"foo\", \"bar-$1\", \"job\", \"node-(.+)\")\u003c/font\u003e 会将 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003ebar-exporter\u003c/font\u003e 标签值存储到 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003efoo\u003c/font\u003e 标签中。\n该函数在 PromQL 中也支持。\nlabel_set label_set(q, \"label1\", \"value1\", ..., \"labelN\", \"valueN\")将{label1=\"value1\", ..., labelN=\"valueN\"}这些 Label 添加到q返回的每条时间序列数据里。\nlabel_transform label_transform(q, \"label\", \"regexp\", \"replacement\") 将给定 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel\u003c/font\u003e 中所有匹配正则表达式 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eregexp\u003c/font\u003e 的部分替换为指定的 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003ereplacement\u003c/font\u003e。\nlabel_uppercase label_uppercase(q, \"label1\", ..., \"labelN\")将 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e 返回的所有时间序列中名为\u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel*\u003c/font\u003e的 Label 值转换成大写字母。\n另请参见 label_lowercase.\nlabel_value label_value(q, \"label\")它为 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003eq\u003c/font\u003e 返回的每条时间序列中的给定 label 的值作为指标 value 返回（原指标 value 被忽略）。\n例如，如果 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003elabel_value(foo, \"bar\")\u003c/font\u003e 应用于 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003efoo{bar=\"1.234\"}\u003c/font\u003e，那么它将返回一个值为\u003cfont style=\"color:rgb(31, 35, 41);\"\u003e1.234\u003c/font\u003e的时间序列\u003cfont style=\"color:rgb(31, 35, 41);\"\u003efoo{bar=\"1.234\"}\u003c/font\u003e. 对于 label 值是非数值类型情况，该函数将不返回数据。\nlabels_equal labels_equal(q, \"label1\", \"label2\", ...)在 q 返回每条时间序列里，寻找 \u003cfont style=\"color:rgb(34, 34, 34);\"\u003e“label1”\u003c/font\u003e、\u003cfont style=\"color:rgb(34, 34, 34);\"\u003e“label2”\u003c/font\u003e 值相等的时间序列，并返回。\n另请参阅 label_match 和 label_mismatch.\nsort_by_label \u003cfont style=\"color:rgb(31, 35, 41);\"\u003esort_by_label(q, \"label1\", ... \"labelN\")\u003c/font\u003e根据给定的一组 Label 按升序排序序列。例如，\u003cfont style=\"color:rgb(31, 35, 41);\"\u003esort_by_label(foo, \"bar\")\u003c/font\u003e 会根据这些序列中 Label \u003cfont style=\"color:rgb(31, 35, 41);\"\u003ebar\u003c/font\u003e的值对\u003cfont style=\"color:rgb(31, 35, 41);\"\u003efoo\u003c/font\u003e序列进行排序。\n另请参阅 sort_by_label_desc 和 sort_by_label_numeric.\nsort_by_label_desc \u003cfont style=\"color:rgb(31, 35, 41);\"\u003esort_by_label\u003c/font\u003e 的反向操作，即降序排列。\nsort_by_label_numeric sort_by_label_numeric(q, \"label1\", ... \"labelN\") is label manipulation function, which sorts series in ascending order by the given set of labels using numeric sort. For example, if foo series have bar label with values 1, 101, 15 and 2, then sort_by_label_numeric(foo, \"bar\") would return series in the following order of bar label values: 1, 2, 15 and 101.\n\u003cfont style=\"color:rgb(31, 35, 41);\"\u003esort_by_label_numeric(q, \"label1\", ... \"labelN\")\u003c/font\u003e根据给定的一组 Label 使用数值排序，按升序排序序列。例如，如果 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003efoo\u003c/font\u003e 序列的 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003ebar\u003c/font\u003e 标签值为 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003e1\u003c/font\u003e、\u003cfont style=\"color:rgb(31, 35, 41);\"\u003e101\u003c/font\u003e、\u003cfont style=\"color:rgb(31, 35, 41);\"\u003e15\u003c/font\u003e 和 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003e2\u003c/font\u003e，那么 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003esort_by_label_numeric(foo, \"bar\")\u003c/font\u003e会按 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003ebar\u003c/font\u003e 标签值的以下顺序返回序列：\u003cfont style=\"color:rgb(31, 35, 41);\"\u003e1\u003c/font\u003e、\u003cfont style=\"color:rgb(31, 35, 41);\"\u003e2\u003c/font\u003e、\u003cfont style=\"color:rgb(31, 35, 41);\"\u003e15\u003c/font\u003e 和 \u003cfont style=\"color:rgb(31, 35, 41);\"\u003e101\u003c/font\u003e。\n另请参阅 sort_by_label_numeric_desc 和 sort_by_label.\nsort_by_label_numeric_desc sort_by_label_numeric的反向操作，即降序排列。"},"title":"操作 Label"},"/docs/query/metricsql/functions/rollup/":{"data":{"":"","与-prometheus-的普遍差异#与 Prometheus 的普遍差异":"凡是涉及对回溯窗口样本值首尾样本值进行计算的 rollup 函数，比如 rate、delta、increase 等函数；其MetricsQL 和 PromQL 都存在统一的计算差异。因此 VictoriaMetrics 使用 xxx_prometheus 的命名提供了兼容 Prometheus 统计方式的 rollup 函数，如 rate_prometheus、delta_prometheus、increase_prometheus 等。而默认则使用 MetricsQL 的统计方式。\n具体的差异细节请阅读这篇文档。","什么是rollup#什么是Rollup":"Rollup函数（也称为范围函数或窗口函数）在所选 timeseries 的给定回溯窗口上对原始样本的汇总计算。例如，avg_over_time(temperature[24h])计算过去 24 小时内所有原始样本的平均温度值。\n更多细节：\n如果在Grafana中使用rollup函数来构建图形，那么每个点上的rollup都是独立计算的。例如，avg_over_time(temperature[24h])图表中的每个点显示了截止到该时间点的过去24小时内的平均温度。点之间的间隔由Grafana传递给/api/v1/query_range接口作为step查询参数设置。 如果给定的查询语句返回多个 timeseries，则每个返回的序列都会单独计算汇总。 如果方括号中的回溯窗口缺失，则MetricsQL会自动将回溯窗口设置为图表上点之间的间隔（即/api/v1/query_range中的step查询参数，Grafana中的$__interval值或MetricsQL中的1i持续时间）。例如，rate(http_requests_total)在Grafana中等同于rate(http_requests_total[$__interval])。它也等同于rate(http_requests_total[1i])。 每个在MetricsQL中的系列选择器都必须包装在一个rollup函数中。否则，它会自动被包装成default_rollup。例如，foo{bar=\"baz\"} 在执行计算之前会自动转换为 default_rollup(foo{bar=\"baz\"}[1i])。 如果在rollup函数中传递的参数不是series selector，那么内部的参数会自动转换为子查询。 所有的汇总函数都接受可选的 keep_metric_names 修饰符。如果设置了该修饰符，函数将在结果中保留指标名称。请参阅这些文档。 更多参见隐式查询转换。","函数列表#函数列表":"absent_over_time absent_over_time(series_selector[d])是一个 rollup 函数，如果给定的向前窗口d不包含原始样本，则返回1。否则，它将返回一个空结果。\n这个函数在PromQL中得到支持。另请参阅present_over_time。\naggr_over_time aggr_over_time((\"rollup_func1\", \"rollup_func2\", ...), series_selector[d]) 计算给定回溯窗口 d 上所有列出的 rollup_func* 对原始样本进行汇总。根据给定的series_selector，对每个返回的时间序列进行单独计算。\nrollup_func* 可以是任意一个 rollup 函数。比如，aggr_over_time((\"min_over_time\", \"max_over_time\", \"rate\"), m[d]) 就会对m[d]计算 min_over_time, max_over_time 和 rate 。\nascent_over_time ascent_over_time(series_selector[d]) 计算给定时间窗口d上原始样本值的上升。针对series_selector查询返回的每个时间序列单独执行计算。\n该功能用于在GPS跟踪中跟踪高度增益。Metric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 descent_over_time。\navg_over_time avg_over_time(series_selector[d]) 计算给定时间窗口d上原始样本值的平均值。针对series_selector查询返回的每个时间序列单独执行计算。\n这个函数在 PromQL 中也支持，另请参阅 median_over_time。\nchanges changes(series_selector[d]) 计算给定时间窗口d上原始样本值的变化。针对series_selector查询返回的每个时间序列单独执行计算。\n不像 Prometheus里的 changes() ，它考虑了给定时间窗口 d 中最后一个样本的变化，详情请参阅这篇文章。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n这个函数 PromQL 中也支持，另请参阅 changes_prometheus。\nchanges_prometheus changes_prometheus(series_selector[d]) 计算时间窗口 d 中原始样本值变化的次数。针对series_selector查询返回的每个时间序列单独执行计算。\n它不考虑在时间窗口 d 之前的最后一个样本值的变化，这和 Prometheus 的逻辑是一样的。详情请参阅这篇文章。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n这个函数 PromQL 中也支持，另请参阅 changes。\ncount_eq_over_time count_eq_over_time(series_selector[d], eq) 计算时间窗口 d 中原始样本值等于eq的个数。它针对series_selector查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 count_over_time。\ncount_gt_over_time count_gt_over_time(series_selector[d], gt) 计算时间窗口 d 中原始样本值大于gt的个数。它针对series_selector查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 count_over_time。\ncount_le_over_time count_le_over_time(series_selector[d], le) 计算时间窗口 d 中原始样本值小于lt的个数。它针对series_selector查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 count_over_time。\ncount_ne_over_time count_ne_over_time(series_selector[d], ne) 计算时间窗口 d 中原始样本值不等于ne的个数。它针对series_selector查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 count_over_time。\ncount_over_time count_over_time(series_selector[d]) 计算时间窗口 d 中原始样本值的个数。它针对series_selector查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n这个函数 PromQL 中也支持，另请参阅 count_le_over_time, count_gt_over_time, count_eq_over_time 和 count_ne_over_time。\ndecreases_over_time decreases_over_time(series_selector[d]) 计算给定时间窗口d上原始样本值的下降值。针对series_selector查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 increases_over_time。\ndefault_rollup default_rollup(series_selector[d]) 返回给定时间窗口d中最后一个原始样本。针对series_selector查询返回的每个时间序列单独执行计算。\ndelta delta(series_selector[d]) is a rollup function,\n计算给定回溯窗口 d 之前的最后一个样本和该窗口的最后一个样本的差异。针对series_selector查询返回的每个时间序列单独执行计算。\nMetricsQL中 delta() 函数的计算逻辑和 Prometheus 中的 delta() 函数计算逻辑存在轻微差异，详情看这里。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数 PromQL 也支持. 另请参阅 increase 和 delta_prometheus。\ndelta_prometheus delta_prometheus(series_selector[d]) 计算回溯窗口中第一个样本和最后一个样本的差异。针对series_selector查询返回的每个时间序列单独执行计算。\ndelta_prometheus() 的计算逻辑和 Prometheus delta() 一致。 详情看这里。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参见 delta。\nderiv deriv(series_selector[d]) 计算给定回溯窗口 d 中时序数据的每秒导数。针对 series_selector 查询返回的每个时间序列单独执行计算。该导数使用线性回归计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数 PromQL 也支持. 另请参阅 deriv_fast 和 ideriv。\nderiv_fast deriv_fast(series_selector[d])使用给定回溯窗口 d 中第一个和最后一个 raw sample 来计算每秒导数。针对series_selector查询返回的每个时间序列单独执行计算。该导数使用线性回归计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 deriv 和 ideriv。\ndescent_over_time descent_over_time(series_selector[d]) 计算给定回溯窗口 d 中 raw sample 值的下降量。针对 series_selector 查询查询返回的每个时间序列单独执行计算。\n这个功能对于追踪GPS定位中的海拔高度损失非常有用。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 ascent_over_time。\ndistinct_over_time distinct_over_time(series_selector[d]) 返回给定回溯窗口 d 中 raw sample 值的种类数。针对 series_selector 查询查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 count_values_over_time。\nduration_over_time duration_over_time(series_selector[d], max_interval) 返回给定的 series_selector 返回的时间序列在给定的回溯窗口\u003cfont style=\"color:rgb(6, 6, 7);\"\u003ed\u003c/font\u003e内存在的持续时间，以秒为单位。预期每个序列相邻样本之间的间隔不超过\u003cfont style=\"color:rgb(6, 6, 7);\"\u003emax_interval\u003c/font\u003e。否则，这样的间隔被忽略不计。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参见 lifetime 和 lag。\nfirst_over_time first_over_time(series_selector[d]) 返回给定的 series_selector 返回的时间序列在给定的回溯窗口d内的第一个 raw sample 值。\n另请参见 last_over_time 和 tfirst_over_time。\ngeomean_over_time geomean_over_time(series_selector[d]) 计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw sample 值的geometric mean。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n这个函数通常应用于 gauges。\nhistogram_over_time histogram_over_time(series_selector[d]) 对给定的回溯窗口d中的 raw samples 计算 VictoriaMetrics histogram。针对 series_selector 查询查询返回的每个时间序列单独执行计算。其计算出来的histograms 可被用来传递给histogram_quantile，用于计算多个gauges指标的分位值。比如，下面的语句计算每个国家过去 24 小时的温度中位数：\nhistogram_quantile(0.5, sum(histogram_over_time(temperature[24h])) by (vmrange,country))。\n该函数通常应用于 gauges。\nholt_winters holt_winters(series_selector[d], sf, tf) 使用平滑因子sf和趋势因子tf对给定回溯窗口d中的 raw samples 计算 Holt-Winters（通过double exponential smoothing） 值。sf和tf的取值范围必须是[0...1]。\n该函数通常应用于 gauges。PromQL 也支持该函数。\n另请参阅 range_linear_regression。\nidelta idelta(series_selector[d]) 计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内最后 2 个 raw sample 值的差异。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\nPromQL 也支持该函数。\n另请参阅 delta。\nideriv ideriv(series_selector[d])基于给定回溯窗口d中最后五个 raw samples 计算秒级导数。该导数针对 series_selector 查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 deriv。\nincrease increase(series_selector[d]) 计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内样本值的增量。\n和 Prometheus 不同，它考虑了回溯窗口 d 之前的最后一个 raw sample 值。细节请阅读这篇文档。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 counters.PromQL 也支持该函数。\n另请参阅 increase_pure, increase_prometheus and delta.\nincrease_prometheus increase_prometheus(series_selector[d]) 计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内样本值的增量。\n计算方式和 Prometheus 一样，它不考虑回溯窗口 d 之前的最后一个 raw sample 值。细节请阅读这篇文档。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 counters.\n另请参阅 increase_pure and increase.\nincrease_pure increase_pure(series_selector[d])的工作机制和 increase 一样，除了一种情况：它假定 counters 总是从 0 开始计数，而 increase 在第一个值过大时会忽略掉它。\n该函数通常应用于 counters.\n另请参阅 increase and increase_prometheus.\nincreases_over_time increases_over_time(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内出现增加的 raw sample 值的数量。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 decreases_over_time.\nintegrate integrate(series_selector[d]) 计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 积分。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\nirate irate(series_selector[d]) 使用给定的 series_selector 返回的时间序列在给定的回溯窗口d内最后 2 个 raw sample 计算出每秒增量。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 counters，PromQL 也支持该函数。\n另请参阅 rate and rollup_rate.\nlag lag(series_selector[d])返回给定的回溯窗口d内最后一个样本的时间与当前时间的间隔，以秒为单位。其针对 series_selector 查询返回的每个时间序列单独执行计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 lifetime and duration_over_time.\nlast_over_time last_over_time(series_selector[d])返回给定的 series_selector 返回的时间序列在给定的回溯窗口d内最后 1 个 raw sample。\nPromQL 也支持该函数。\n另请参阅 first_over_time and tlast_over_time。\nlifetime lifetime(series_selector[d])返回给定的 series_selector 返回的时间序列在给定的回溯窗口d内第一个和最后一个 raw sample 的时间间隔，以秒为单位。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 duration_over_time and lag。\nmad_over_time mad_over_time(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw sample 的 median absolute deviation。\n该函数通常应用于 gauges.\n另请参阅 mad, range_mad and outlier_iqr_over_time.\nmax_over_time max_over_time(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的最大值。\n该函数通常应用于 gauges，PromQL 也支持该函数。\n另请参阅 tmax_over_time and min_over_time.\nmedian_over_time median_over_time(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的中位数。\n该函数通常应用于 gauges.\n另请参阅 avg_over_time.\nmin_over_time min_over_time(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的最小值。\n该函数通常应用于 gauges，PromQL 也支持该函数。\n另请参阅 tmin_over_time and max_over_time.\nmode_over_time mode_over_time(series_selector[d]) 计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的高频值。它假定 raw sample 值都是离散的\n该函数通常应用于 gauges.\noutlier_iqr_over_time outlier_iqr_over_time(series_selector[d]) 返回给定回溯窗口 d 中最后一个样本，如果它的值小于 q25-1.5*iqr 或大于 q75+1.5*iqr，其中：\niqr 回溯窗口d中 raw samples 的 Interquartile range。 q25和q75 回溯窗口d中 raw samples 的是 25th and 75th 分位值。 outlier_iqr_over_time() 主要用于基于 gauge 指标的历史数据来检测异常。例如，outlier_iqr_over_time(memory_usage_bytes[1h]) 会在memory_usage_bytes指标突然超出过去一小时的平均值时触发。\n该函数通常应用于 gauges.\n另请参阅 outliers_iqr.\npredict_linear predict_linear(series_selector[d], t) 使用回溯窗口 d 中的 raw samples 值，使用线性规划计算在未来 t 秒后的指标值。预测值是针对 series_selector 查询返回的每个时间序列单独执行计算。\nPromQL 也支持该函数。\n另请参阅 range_linear_regression.\npresent_over_time present_over_time(series_selector[d]) 返回 1 ，如果给定的回溯窗口 d 中至少包含一个 raw sample，否则就返回空。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\nPromQL 也支持该函数。\nquantile_over_time quantile_over_time(phi, series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的phi分位值。其中 phi 值的取值范围必须是[0...1]。\n该函数通常应用于 gauges，PromQL 也支持该函数。\n另请参阅 quantiles_over_time.\nquantiles_over_time quantiles_over_time(\"phiLabel\", phi1, ..., phiN, series_selector[d]) 计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的phi*分位值，给函数针对每一个phi*都返回一个独立的带有{phiLabel=\"phi*\"}Label 的序列。phi* 的取值范围必须是[0...1].\n该函数通常应用于 gauges.\n另请参阅 quantile_over_time.\nrange_over_time range_over_time(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的取值范围（最大值-最小值）。它等价于max_over_time(series_selector[d]) - min_over_time(series_selector[d]).\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\nrate rate(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 的平均每秒增长值。\n如果中括号里的回溯窗口大小没有指定，则自动使用max(step, scrape_interval)，其中 step 是传递给 /api/v1/query_range 或 /api/v1/query 的请求参数，而scrape_interval则是 raw samples 之间的间隔。这避免当 step 小于scrape_interval时，图表中出现了非预期的断点现象。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\nPromQL 也支持该函数。\n另请参阅 irate and rollup_rate.\nrate_over_sum rate_over_sum(series_selector[d])计算给定回溯窗口d中 raw samples 总和的每秒增量。该计算针对 series_selector 查询返回的每个时间序列单独执行计算。\n该函数通常应用于 gauges.\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\nresets resets(series_selector[d])计算给定的 series_selector 返回的时间序列在给定的回溯窗口d内 raw samples 中出现 counter 重置的次数。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 counters，Counter 重置通常代表服务发生了重启。\nPromQL 也支持该函数。\nrollup rollup(series_selector[d]) 对给定的回溯窗口d中的 raw samples 计算最小值、最大值和平均值，并在返回的时序数据中带上rollup=\"min\", rollup=\"max\" 和 rollup=\"avg\"Label。该计算针对 series_selector 查询返回的每个时间序列单独执行计算。\n支持第二个参数，是可选参数，可传入\"min\", \"max\" 或 \"avg\" 代表只计算一种值并且不需要追加额外的 rollup label。另请参阅 label_match.\n该函数通常应用于 gauges.\n另请参阅 rollup_rate.\nrollup_candlestick rollup_candlestick(series_selector[d])对给定的回溯窗口d中的 raw samples 使用 OHLC 计算open, high, low and close，并在返回的时序数据中带上rollup=\"open\", rollup=\"high\", rollup=\"low\" and rollup=\"close\"Label。该计算针对 series_selector 查询返回的每个时间序列单独执行计算。\n支持第二个参数，是可选参数，可传入\"open\", \"high\"或\"low\"或\"close\" 代表只计算一种值并且不需要追加额外的 rollup label。另请参阅 label_match.\n该函数通常应用于 gauges.\nrollup_delta rollup_delta(series_selector[d]) 计算给定回溯窗口d上相邻 raw samples 之间的差异，并返回计算出的差异的最小值、最大值和平均值，并在时间序列中附加rollup=\"min\"、rollup=\"max\" 和 rollup=\"avg\" Label。计算是针对从给定 series_selector 返回的每个时间序列单独进行的。\n可以传递可选的第二个参数 \"min\"、\"max\" 或 \"avg\" 来仅保留一个计算结果，并且不添加标签。\nMetric 名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 rollup_increase.\nrollup_deriv rollup_deriv(series_selector[d]) 计算给定回溯窗口d上相邻 raw samples 之间的每秒导数，并返回计算出的差异的最小值、最大值和平均值，并在时间序列中附加rollup=\"min\"、rollup=\"max\" 和 rollup=\"avg\" Label。计算是针对从给定 series_selector 返回的每个时间序列单独进行的。\n可以传递可选的第二个参数 \"min\"、\"max\" 或 \"avg\" 来仅保留一个计算结果，并且不添加标签。另请参阅 label_match。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 rollup and rollup_rate.\nrollup_increase rollup_increase(series_selector[d]) 计算给定回溯窗口d上相邻 raw samples 之间的增加值，并返回计算出的差异的最小值、最大值和平均值，并在时间序列中附加rollup=\"min\"、rollup=\"max\" 和 rollup=\"avg\" Label。计算是针对从给定 series_selector 返回的每个时间序列单独进行的。\n可以传递可选的第二个参数 \"min\"、\"max\" 或 \"avg\" 来仅保留一个计算结果，并且不添加标签。另请参阅 label_match。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。 另请参阅 rollup_delta.\n该函数通常应用于 counters.\n另请参阅 rollup and rollup_rate.\nrollup_rate rollup_rate(series_selector[d]) 计算给定回溯窗口d上相邻 raw samples 之间的每秒变化量，并返回计算出的差异的最小值、最大值和平均值，并在时间序列中附加rollup=\"min\"、rollup=\"max\" 和 rollup=\"avg\" Label。计算是针对从给定 series_selector 返回的每个时间序列单独进行的。\n可以传递可选的第二个参数 \"min\"、\"max\" 或 \"avg\" 来仅保留一个计算结果，并且不添加标签。另请参阅 label_match。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 counters.\n另请参阅 rollup and rollup_increase.\nrollup_scrape_interval rollup_scrape_interval(series_selector[d]) 计算给定回溯窗口d上相邻 raw samples 之间的间隔的秒数（通常是数据的采集间隔），并返回计算出的差异的最小值、最大值和平均值，并在时间序列中附加rollup=\"min\"、rollup=\"max\" 和 rollup=\"avg\" Label。计算是针对从给定 series_selector 返回的每个时间序列单独进行的。\n可以传递可选的第二个参数 \"min\"、\"max\" 或 \"avg\" 来仅保留一个计算结果，并且不添加标签。另请参阅 label_match。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。 另请参阅 scrape_interval.\nscrape_interval scrape_interval(series_selector[d]) 计算给定回溯窗口d上相邻 raw samples 之间的间隔的平均秒数（通常是数据的采集间隔）并返回。计算是针对从给定 series_selector 返回的每个时间序列单独进行的。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 rollup_scrape_interval.\nshare_gt_over_time share_gt_over_time(series_selector[d], gt) 返回给定回溯窗口d上大于gt的原始样本的比例（范围在[0...1]之间）。该比例是针对从给定series_selector返回的每个时间序列独立计算的。\n此函数对于计算 SLI 和 SLO 非常有用。例如：share_gt_over_time(up[24h], 0) - 返回过去 24 小时的服务可用性。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\n另请参阅 share_le_over_time and count_gt_over_time.\nshare_le_over_time share_le_over_time(series_selector[d], le) 返回给定回溯窗口d上小于le的原始样本的比例（范围在[0...1]之间）。该比例是针对从给定series_selector返回的每个时间序列独立计算的。\n此函数对于计算 SLI 和 SLO 非常有用。例如：share_le_over_time(memory_usage_bytes[24h], 100*1024*1024) - 返回过去 24 小时的内存使用率小于等于100MB的时间占比。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\n另请参阅 share_gt_over_time and count_le_over_time.\nshare_eq_over_time share_eq_over_time(series_selector[d], eq) 返回给定回溯窗口d上等于eq的原始样本的比例（范围在[0...1]之间）。该比例是针对从给定series_selector返回的每个时间序列独立计算的。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\n另请参阅 count_eq_over_time.\nstddev_over_time stddev_over_time(series_selector[d]) 对 series_selector返回的每个时间序列计算给定回溯窗口d上原始样本的标准差。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\nPromQL 也支持该函数。\n另请参阅 stdvar_over_time.\nstdvar_over_time stdvar_over_time(series_selector[d]) 针对series_selector返回的每条时间序列独立计算，算出给定回溯窗口d上 raw samples 的方差并返回。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\nPromQL 也支持该函数。\n另请参阅 stddev_over_time.\nsum_eq_over_time sum_eq_over_time(series_selector[d], eq) 针对 series_selector 返回的每条时间序列独立计算，算出给定回溯窗口 d 上等于 eq 的 raw samples 值的总和并返回。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\n另请参阅 sum_over_time and count_eq_over_time.\nsum_gt_over_time sum_gt_over_time(series_selector[d], gt) 针对series_selector返回的每条时间序列独立计算，算出给定回溯窗口 d 上大于 gt 的 raw samples 值的总和并返回。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\n另请参阅 sum_over_time and count_gt_over_time.\nsum_le_over_time sum_le_over_time(series_selector[d], le) 针对series_selector返回的每条时间序列独立计算，算出给定回溯窗口d上小于或等于 le 的 raw samples 值的总和并返回。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\n另请参阅 sum_over_time and count_le_over_time.\nsum_over_time sum_over_time(series_selector[d])是一个汇总函数，它针对 series_selector 返回的每条时间序列独立计算，算出给定回溯窗口d上 raw samples 值的总和并返回。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\nPromQL 也支持该函数。\nsum2_over_time sum2_over_time(series_selector[d])针对series_selector返回的每条时间序列独立计算，算出给定回溯窗口d上 raw samples 值的平方和并返回。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\ntimestamp timestamp(series_selector[d]) 针对 series_selector 返回的每条时间序列独立计算，返回给定回溯窗口 d 上最后一个 raw sample 的时间戳（以秒为单位，精确到毫秒）。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\nPromQL 也支持该函数。\n另请参阅 time 和 now.\ntimestamp_with_name timestamp_with_name(series_selector[d])针对 series_selector 返回的每条时间序列独立计算，返回给定回溯窗口 d 上最后一个 raw sample 的时间戳（以秒为单位，精确到毫秒）。\n和 timestamp 函数区别是在汇总结果中保留了 Metric 名称。\n另请参阅 timestamp 和 keep_metric_names 修改器.\ntfirst_over_time tfirst_over_time(series_selector[d])针对 series_selector 返回的每条时间序列独立计算，返回给定回溯窗口 d 上第一个 raw sample 的时间戳（以秒为单位，精确到毫秒）。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 first_over_time.\ntlast_change_over_time tlast_change_over_time (series_selector [d]) 针对 series_selector 返回的每条时间序列独立计算，返回给定回溯窗口 d 上最后一次变化的时间戳（以秒为单位，精确到毫秒）。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 last_over_time.\ntlast_over_time tlast_over_time 是 timestamp 函数的别名。\n另请参阅 tlast_change_over_time.\ntmax_over_time tmax_over_time(series_selector[d])返回给定回溯窗口 d 上具有最大值的 raw sample 的时间戳（以秒为单位，精确到毫秒）。它针对 series_selector 返回的每条时间序列独立计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 max_over_time.\ntmin_over_time tmin_over_time(series_selector[d])返回给定回溯窗口 d 上具有最小值的 raw sample 的时间戳（以秒为单位，精确到毫秒）。它针对 series_selector 返回的每条时间序列独立计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n另请参阅 min_over_time.\nzscore_over_time zscore_over_time(series_selector[d]) is a rollup function, which returns z-score for raw samples on the given lookbehind window d. It is calculated independently per each time series returned from the given series_selector.\nzscore_over_time(series_selector[d])返回给定回溯窗口 d 上 raw samples 的 z-score。它针对 series_selector 返回的每条时间序列独立计算。\nMetric名称将从计算结果中剥离。增加 keep_metric_names 修改器来保留 Metric 名称。\n该函数通常应用于 gauges.\n另请参阅 zscore, range_trim_zscore and outlier_iqr_over_time."},"title":"汇总（Rollup）"},"/docs/query/metricsql/functions/transmit/":{"data":{"":"","#":"Transform functions calculate transformations over rollup results. For example, abs(delta(temperature[24h])) calculates the absolute value for every point of every time series returned from the rollup delta(temperature[24h]).\nAdditional details:\nIf transform function is applied directly to a series selector, then the default_rollup() function is automatically applied before calculating the transformations. For example, abs(temperature) is implicitly transformed to abs(default_rollup(temperature)). All the transform functions accept optional keep_metric_names modifier. If it is set, then the function doesn’t drop metric names from the resulting time series. See these docs. See also implicit query conversions.\nabs # abs(q) is a transform function, which calculates the absolute value for every point of every time series returned by q.\nThis function is supported by PromQL.\nabsent # absent(q) is a transform function, which returns 1 if q has no points. Otherwise, returns an empty result.\nThis function is supported by PromQL.\nSee also absent_over_time.\nacos # acos(q) is a transform function, which returns inverse cosine for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also asin and cos.\nacosh # acosh(q) is a transform function, which returns inverse hyperbolic cosine for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also sinh.\nasin # asin(q) is a transform function, which returns inverse sine for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also acos and sin.\nasinh # asinh(q) is a transform function, which returns inverse hyperbolic sine for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also sinh.\natan # atan(q) is a transform function, which returns inverse tangent for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also tan.\natanh # atanh(q) is a transform function, which returns inverse hyperbolic tangent for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also tanh.\nbitmap_and # bitmap_and(q, mask) is a transform function, which calculates bitwise v \u0026 mask for every v point of every time series returned from q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nbitmap_or # bitmap_or(q, mask) is a transform function, which calculates bitwise v | mask for every v point of every time series returned from q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nbitmap_xor # bitmap_xor(q, mask) is a transform function, which calculates bitwise v ^ mask for every v point of every time series returned from q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nbuckets_limit # buckets_limit(limit, buckets) is a transform function, which limits the number of histogram buckets to the given limit.\nSee also prometheus_buckets and histogram_quantile.\nceil # ceil(q) is a transform function, which rounds every point for every time series returned by q to the upper nearest integer.\nThis function is supported by PromQL.\nSee also floor and round.\nclamp # clamp(q, min, max) is a transform function, which clamps every point for every time series returned by q with the given min and max values.\nThis function is supported by PromQL.\nSee also clamp_min and clamp_max.\nclamp_max # clamp_max(q, max) is a transform function, which clamps every point for every time series returned by q with the given max value.\nThis function is supported by PromQL.\nSee also clamp and clamp_min.\nclamp_min # clamp_min(q, min) is a transform function, which clamps every point for every time series returned by q with the given min value.\nThis function is supported by PromQL.\nSee also clamp and clamp_max.\ncos # cos(q) is a transform function, which returns cos(v) for every v point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also sin.\ncosh # cosh(q) is a transform function, which returns hyperbolic cosine for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also acosh.\nday_of_month # day_of_month(q) is a transform function, which returns the day of month for every point of every time series returned by q. It is expected that q returns unix timestamps. The returned values are in the range [1...31].\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also day_of_week and day_of_year.\nday_of_week # day_of_week(q) is a transform function, which returns the day of week for every point of every time series returned by q. It is expected that q returns unix timestamps. The returned values are in the range [0...6], where 0 means Sunday and 6 means Saturday.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also day_of_month and day_of_year.\nday_of_year # day_of_year(q) is a transform function, which returns the day of year for every point of every time series returned by q. It is expected that q returns unix timestamps. The returned values are in the range [1...365] for non-leap years, and [1 to 366] in leap years.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also day_of_week and day_of_month.\ndays_in_month # days_in_month(q) is a transform function, which returns the number of days in the month identified by every point of every time series returned by q. It is expected that q returns unix timestamps. The returned values are in the range [28...31].\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\ndeg # deg(q) is a transform function, which converts Radians to degrees for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also rad.\ndrop_empty_series # drop_empty_series(q) is a transform function, which drops empty series from q.\nThis function can be used when default operator should be applied only to non-empty series. For example, drop_empty_series(temperature \u003c 30) default 42 returns series, which have at least a single sample smaller than 30 on the selected time range, while filling gaps in the returned series with 42.\nOn the other hand (temperature \u003c 30) default 40 returns all the temperature series, even if they have no samples smaller than 30, by replacing all the values bigger or equal to 30 with 40.\nend # end() is a transform function, which returns the unix timestamp in seconds for the last point. It is known as end query arg passed to /api/v1/query_range.\nSee also start, time and now.\nexp # exp(q) is a transform function, which calculates the e^v for every point v of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also ln.\nfloor # floor(q) is a transform function, which rounds every point for every time series returned by q to the lower nearest integer.\nThis function is supported by PromQL.\nSee also ceil and round.\nhistogram_avg # histogram_avg(buckets) is a transform function, which calculates the average value for the given buckets. It can be used for calculating the average over the given time range across multiple time series. For example, histogram_avg(sum(histogram_over_time(response_time_duration_seconds[5m])) by (vmrange,job)) would return the average response time per each job over the last 5 minutes.\nhistogram_quantile # histogram_quantile(phi, buckets) is a transform function, which calculates phi-percentile over the given histogram buckets. phi must be in the range [0...1]. For example, histogram_quantile(0.5, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) would return median request duration for all the requests during the last 5 minutes.\nThe function accepts optional third arg - boundsLabel. In this case it returns lower and upper bounds for the estimated percentile with the given boundsLabel label. See this issue for details.\nWhen the percentile is calculated over multiple histograms, then all the input histograms must have buckets with identical boundaries, e.g. they must have the same set of le or vmrange labels. Otherwise, the returned result may be invalid. See this issue for details.\nThis function is supported by PromQL (except of the boundLabel arg).\nSee also histogram_quantiles, histogram_share and quantile.\nhistogram_quantiles # histogram_quantiles(\"phiLabel\", phi1, ..., phiN, buckets) is a transform function, which calculates the given phi*-quantiles over the given histogram buckets. Argument phi* must be in the range [0...1]. For example, histogram_quantiles('le', 0.3, 0.5, sum(rate(http_request_duration_seconds_bucket[5m]) by (le)). Each calculated quantile is returned in a separate time series with the corresponding {phiLabel=\"phi*\"} label.\nSee also histogram_quantile.\nhistogram_share # histogram_share(le, buckets) is a transform function, which calculates the share (in the range [0...1]) for buckets that fall below le. This function is useful for calculating SLI and SLO. This is inverse to histogram_quantile.\nThe function accepts optional third arg - boundsLabel. In this case it returns lower and upper bounds for the estimated share with the given boundsLabel label.\nhistogram_stddev # histogram_stddev(buckets) is a transform function, which calculates standard deviation for the given buckets.\nhistogram_stdvar # histogram_stdvar(buckets) is a transform function, which calculates standard variance for the given buckets. It can be used for calculating standard deviation over the given time range across multiple time series. For example, histogram_stdvar(sum(histogram_over_time(temperature[24])) by (vmrange,country)) would return standard deviation for the temperature per each country over the last 24 hours.\nhour # hour(q) is a transform function, which returns the hour for every point of every time series returned by q. It is expected that q returns unix timestamps. The returned values are in the range [0...23].\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\ninterpolate # interpolate(q) is a transform function, which fills gaps with linearly interpolated values calculated from the last and the next non-empty points per each time series returned by q.\nSee also keep_last_value and keep_next_value.\nkeep_last_value # keep_last_value(q) is a transform function, which fills gaps with the value of the last non-empty point in every time series returned by q.\nSee also keep_next_value and interpolate.\nkeep_next_value # keep_next_value(q) is a transform function, which fills gaps with the value of the next non-empty point in every time series returned by q.\nSee also keep_last_value and interpolate.\nlimit_offset # limit_offset(limit, offset, q) is a transform function, which skips offset time series from series returned by q and then returns up to limit of the remaining time series per each group.\nThis allows implementing simple paging for q time series. See also limitk.\nln # ln(q) is a transform function, which calculates ln(v) for every point v of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also exp and log2.\nlog2 # log2(q) is a transform function, which calculates log2(v) for every point v of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also log10 and ln.\nlog10 # log10(q) is a transform function, which calculates log10(v) for every point v of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also log2 and ln.\nminute # minute(q) is a transform function, which returns the minute for every point of every time series returned by q. It is expected that q returns unix timestamps. The returned values are in the range [0...59].\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nmonth # month(q) is a transform function, which returns the month for every point of every time series returned by q. It is expected that q returns unix timestamps. The returned values are in the range [1...12], where 1 means January and 12 means December.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nnow # now() is a transform function, which returns the current timestamp as a floating-point value in seconds.\nSee also time.\npi # pi() is a transform function, which returns Pi number.\nThis function is supported by PromQL.\nrad # rad(q) is a transform function, which converts degrees to Radians for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nSee also deg.\nprometheus_buckets # prometheus_buckets(buckets) is a transform function, which converts VictoriaMetrics histogram buckets with vmrange labels to Prometheus histogram buckets with le labels. This may be useful for building heatmaps in Grafana.\nSee also histogram_quantile and buckets_limit.\nrand # rand(seed) is a transform function, which returns pseudo-random numbers on the range [0...1] with even distribution. Optional seed can be used as a seed for pseudo-random number generator.\nSee also rand_normal and rand_exponential.\nrand_exponential # rand_exponential(seed) is a transform function, which returns pseudo-random numbers with exponential distribution. Optional seed can be used as a seed for pseudo-random number generator.\nSee also rand and rand_normal.\nrand_normal # rand_normal(seed) is a transform function, which returns pseudo-random numbers with normal distribution. Optional seed can be used as a seed for pseudo-random number generator.\nSee also rand and rand_exponential.\nrange_avg # range_avg(q) is a transform function, which calculates the avg value across points per each time series returned by q.\nrange_first # range_first(q) is a transform function, which returns the value for the first point per each time series returned by q.\nrange_last # range_last(q) is a transform function, which returns the value for the last point per each time series returned by q.\nrange_linear_regression # range_linear_regression(q) is a transform function, which calculates simple linear regression over the selected time range per each time series returned by q. This function is useful for capacity planning and predictions.\nrange_mad # range_mad(q) is a transform function, which calculates the median absolute deviation across points per each time series returned by q.\nSee also mad and mad_over_time.\nrange_max # range_max(q) is a transform function, which calculates the max value across points per each time series returned by q.\nrange_median # range_median(q) is a transform function, which calculates the median value across points per each time series returned by q.\nrange_min # range_min(q) is a transform function, which calculates the min value across points per each time series returned by q.\nrange_normalize # range_normalize(q1, ...) is a transform function, which normalizes values for time series returned by q1, ... into [0 ... 1] range. This function is useful for correlating time series with distinct value ranges.\nSee also share.\nrange_quantile # range_quantile(phi, q) is a transform function, which returns phi-quantile across points per each time series returned by q. phi must be in the range [0...1].\nrange_stddev # range_stddev(q) is a transform function, which calculates standard deviation per each time series returned by q on the selected time range.\nrange_stdvar # range_stdvar(q) is a transform function, which calculates standard variance per each time series returned by q on the selected time range.\nrange_sum # range_sum(q) is a transform function, which calculates the sum of points per each time series returned by q.\nrange_trim_outliers # range_trim_outliers(k, q) is a transform function, which drops points located farther than k*range_mad(q) from the range_median(q). E.g. it is equivalent to the following query: q ifnot (abs(q - range_median(q)) \u003e k*range_mad(q)).\nSee also range_trim_spikes and range_trim_zscore.\nrange_trim_spikes # range_trim_spikes(phi, q) is a transform function, which drops phi percent of biggest spikes from time series returned by q. The phi must be in the range [0..1], where 0 means 0% and 1 means 100%.\nSee also range_trim_outliers and range_trim_zscore.\nrange_trim_zscore # range_trim_zscore(z, q) is a transform function, which drops points located farther than z*range_stddev(q) from the range_avg(q). E.g. it is equivalent to the following query: q ifnot (abs(q - range_avg(q)) \u003e z*range_avg(q)).\nSee also range_trim_outliers and range_trim_spikes.\nrange_zscore # range_zscore(q) is a transform function, which calculates z-score for points returned by q, e.g. it is equivalent to the following query: (q - range_avg(q)) / range_stddev(q).\nremove_resets # remove_resets(q) is a transform function, which removes counter resets from time series returned by q.\nround # round(q, nearest) is a transform function, which rounds every point of every time series returned by q to the nearest multiple. If nearest is missing then the rounding is performed to the nearest integer.\nThis function is supported by PromQL.\nSee also floor and ceil.\nru # ru(free, max) is a transform function, which calculates resource utilization in the range [0%...100%] for the given free and max resources. For instance, ru(node_memory_MemFree_bytes, node_memory_MemTotal_bytes) returns memory utilization over node_exporter metrics.\nrunning_avg # running_avg(q) is a transform function, which calculates the running avg per each time series returned by q.\nrunning_max # running_max(q) is a transform function, which calculates the running max per each time series returned by q.\nrunning_min # running_min(q) is a transform function, which calculates the running min per each time series returned by q.\nrunning_sum # running_sum(q) is a transform function, which calculates the running sum per each time series returned by q.\nscalar # scalar(q) is a transform function, which returns q if q contains only a single time series. Otherwise, it returns nothing.\nThis function is supported by PromQL.\nsgn # sgn(q) is a transform function, which returns 1 if v\u003e0, -1 if v\u003c0 and 0 if v==0 for every point v of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nsin # sin(q) is a transform function, which returns sin(v) for every v point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by MetricsQL.\nSee also cos.\nsinh # sinh(q) is a transform function, which returns hyperbolic sine for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by MetricsQL.\nSee also cosh.\ntan # tan(q) is a transform function, which returns tan(v) for every v point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by MetricsQL.\nSee also atan.\ntanh # tanh(q) is a transform function, which returns hyperbolic tangent for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by MetricsQL.\nSee also atanh.\nsmooth_exponential # smooth_exponential(q, sf) is a transform function, which smooths points per each time series returned by q using exponential moving average with the given smooth factor sf.\nsort # sort(q) is a transform function, which sorts series in ascending order by the last point in every time series returned by q.\nThis function is supported by PromQL.\nSee also sort_desc and sort_by_label.\nsort_desc # sort_desc(q) is a transform function, which sorts series in descending order by the last point in every time series returned by q.\nThis function is supported by PromQL.\nSee also sort and sort_by_label.\nsqrt # sqrt(q) is a transform function, which calculates square root for every point of every time series returned by q.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL.\nstart # start() is a transform function, which returns unix timestamp in seconds for the first point.\nIt is known as start query arg passed to /api/v1/query_range.\nSee also end, time and now.\nstep # step() is a transform function, which returns the step in seconds (aka interval) between the returned points. It is known as step query arg passed to /api/v1/query_range.\nSee also start and end.\ntime # time() is a transform function, which returns unix timestamp for every returned point.\nThis function is supported by PromQL.\nSee also timestamp, now, start and end.\ntimezone_offset # timezone_offset(tz) is a transform function, which returns offset in seconds for the given timezone tz relative to UTC. This can be useful when combining with datetime-related functions. For example, day_of_week(time()+timezone_offset(\"America/Los_Angeles\")) would return weekdays for America/Los_Angeles time zone.\nSpecial Local time zone can be used for returning an offset for the time zone set on the host where VictoriaMetrics runs.\nSee the list of supported timezones.\nttf # ttf(free) is a transform function, which estimates the time in seconds needed to exhaust free resources. For instance, ttf(node_filesystem_avail_byte) returns the time to storage space exhaustion. This function may be useful for capacity planning.\nunion # union(q1, ..., qN) is a transform function, which returns a union of time series returned from q1, …, qN. The union function name can be skipped - the following queries are equivalent: union(q1, q2) and (q1, q2).\nIt is expected that each q* query returns time series with unique sets of labels. Otherwise, only the first time series out of series with identical set of labels is returned. Use alias and label_set functions for giving unique labelsets per each q* query:\nvector # vector(q) is a transform function, which returns q, e.g. it does nothing in MetricsQL.\nThis function is supported by PromQL.\nyear # year(q) is a transform function, which returns the year for every point of every time series returned by q. It is expected that q returns unix timestamps.\nMetric names are stripped from the resulting series. Add keep_metric_names modifier in order to keep metric names.\nThis function is supported by PromQL."},"title":"数值转换"},"/docs/query/metricsql/promql-diff/":{"data":{"better-rate#Better rate()":"凡是涉及对回溯窗口样本值首尾样本值进行计算的 rollup 函数，比如 rate、delta、increase 等函数；其MetricsQL 和 PromQL 都存在统一的计算差异。因此 VictoriaMetrics 使用 xxx_prometheus 的命名提供了兼容 Prometheus 统计方式的 rollup 函数，如 rate_prometheus、delta_prometheus、increase_prometheus 等。而默认则使用 MetricsQL 的统计方式。\n以 increase 函数为例，MetricsQL 的计算方式更加精准，如下图所示。\n假设我们有5个样本值，当回溯窗口大小是$__interval 时，我们期望得到的就是V3-V1和V5-V3两个值。即当前回溯窗口的最后一个样本值应该与前一个回溯窗口的最后一个样本值计算，而不是和本窗口的第一个样本值计算。\n再看 Prometheus 的计算方式，如下图所示。它使用一个回溯窗口的最后一个样本值，与该窗口的第一个值进行计算。因为 V1 样本不在第一个窗口内，V3 不再第二个窗口内，这就导致 Prometheus 计算出来的值是V3-V2和V5-V4，结果并不正确。\n此外，Prometheus 的这种统计方式还有另外一个问题。就是如果$_interval大小的时间窗口内只有一个样本值，那么rate和increase这种汇总函数的结果为空。\nMetricsQL doesn’t apply extrapolation when calculating rate and increase. This solves the issue of fractional increase() results over integer counters:\nincrease() query over time series generated by integer counter results in decimal values for Prometheus due to extrapolation.\nIt is quite important to choose the correct lookbehind window for rate and increase in Prometheus. Otherwise, incorrect or no data may be returned. Grafana even introduced a special variable $__rate_interval to address this issue, but it may cause more problems than it solves:\nUsers need to configure the scrape interval value in datasource settings to get it to work; Users still need to add $__rate_interval manually to every query that uses rate; It won’t work if the datasource stores metrics with different scrape intervals (e.g. global view across multiple datasources); It only works in Grafana. In MetricsQL, a lookbehind window in square brackets may be omitted. VictoriaMetrics automatically selects the lookbehind window depending on the current step, so rate(node_network_receive_bytes_total) works just as rate(node_network_receive_bytes_total[$__interval]). And even if the interval is too small to capture enough data points, MetricsQL will automatically expand it. That’s why queries like deriv(demo_disk_usage_bytes[1s]) return no data for Prometheus and VictoriaMetrics expands the lookbehind window prior to making calculations.\nThere are 39 (~7% of 529 tests total) queries (rate, increase, deriv, changes, irate, idelta, resets, etc.) exercising this logic which cause the difference in results between VictoriaMetrics and Prometheus:\nQUERY: rate(demo_cpu_usage_seconds_total[5m]) - Value: Inverse(TranslateFloat64, float64(1.9953032056421414)), + Value: Inverse(TranslateFloat64, float64(1.993400981075324)), For more details about how rate/increase works in MetricsQL please check docs and example on github.","keeping-metric-name#Keeping metric name":"According to PromQL, functions that transform a metric’s data should drop the metric name from the result, since the meaning of the initial metric has changed. However, this approach has some drawbacks. For example, the max_over_time function calculates the max value of the series without changing its physical meaning. Therefore, MetricsQL keeps the metric name for such functions. It also enables queries over multiple metric names: max_over_time({__name__=~\"process_(resident|virtual)_memory_bytes\"}[1h]). While in PromQL such query fails with vector cannot contain metrics with the same labelset error.\nHence, test suit functions like *_over_time, ceil , floor , round , clamp_* , holt_winters , predict_linear in VictoriaMetrics do intentionally contain the metric name in the results:\nQUERY: avg_over_time(demo_memory_usage_bytes[1s]) - Metric: s`{instance=\"demo.promlabs.com:10002\", job=\"demo\", type=\"buffers\"}`, + Metric: s`demo_memory_usage_bytes{instance=\"demo.promlabs.com:10002\", job=\"demo\", type=\"buffers\"}`, There were 92 (~17% of 529 tests total) such queries in the test suite which failed because the metric name is present in the response from VictoriaMetrics, while the values in the response are identical. VictoriaMetrics isn’t going to change this behavior as their users find this is more logical and rely on it.","nans#NaNs":"NaNs are unexpectedly complicated. Let’s begin with the fact that in Prometheus there are two types of NaNs: normal NaN and stale NaN. Stale NaNs are used as “staleness makers” — special values used to identify a time series that had become stale. VictoriaMetrics didn’t initially support this because VictoriaMetrics needed to integrate with many systems beyond just Prometheus and had to have a way to detect staleness uniformly for series ingested via Graphite, Influx, OpenTSDB and other supported data ingestion protocols. Support of Prometheus staleness markers was recently added.\nNormal NaNs are results of mathematical operations, e.g. 0/0=NaN. However, in OpenMetrics there is no special meaning or use case for NaNs.\nWhile NaNs are expected when evaluating mathematical expressions, it is not clear how useful they are for users, or if there are any benefits to return NaNs in the result. It looks like the opposite is true because users are oftenconfusedwith the receivedresults.\nMetricsQL consistently deletes NaN from query responses. This behavior is intentional because there is no meaningful way to use such results. That’s why testing queries such as demo_num_cpus * NaN or sqrt(-demo_num_cpus) return an empty response in MetricsQL, and returns NaNs in PromQL.\nThere were 6 (~1% of 529 tests total) queries in thetest suite expecting NaNs in responses: sqrt(-metric) , ln(-metric) , log2(-metric) , log10(-metric) and metric * NaN .","negative-offsets#Negative offsets":"VictoriaMetrics supports negative offsets and Prometheus also does as well starting with version 2.26 if a specific feature flag is enabled. However, query results are different even with the enabled feature flag due to the fact that Prometheus continues the last value of the metric during the additional 5min:\nVictoriaMetrics vs Prometheus negative offset query. VictoriaMetrics response value is shifted by 1e7 to show the difference between the lines visually. Without this shift, they are identical except the last 5min.\nSuch behavior was unexpected to us. To get more details about it please check the following discussion:\nSeries with negative offset are continued with the last value up to 5min · Discussion #9428 ·…You can’t perform that action at this time. You signed in with another tab or window. You signed out in another tab or…github.com\nVictoriaMetrics isn’t going to change the logic of negative offsets because this feature was released 2 years before Prometheus did it and users rely on that.\nThere were 3 (~0.5% of 529 tests total) queries for -1m, -5m, -10m offsets in the test suite:\nQUERY: demo_memory_usage_bytes offset -1m RESULT: FAILED: Query succeeded, but should have failed. ","precision-loss#Precision loss":"VictoriaMetrics fails the following test case:\nQUERY: demo_memory_usage_bytes % 1.2345 Timestamp: s\"1633073960\", - Value: Inverse(TranslateFloat64, float64(0.038788650870683394)), + Value: Inverse(TranslateFloat64, float64(0.038790081382158004)), The result is indeed different. It is off on the 5th digit after the decimal point and the reason for this is not in MetricsQL but in VictoriaMetrics itself. The query result isn’t correct because the raw data point value for this specific metric doesn’t match between Prometheus and VictoriaMetrics:\ncurl --data-urlencode 'query=demo_memory_usage_bytes{instance=\"demo.promlabs.com:10000\", type=\"buffers\"}' --data-urlencode 'time=1633504838' ...\"value\":[1633504838,\"148164507.40843752\"]}]}}% curl --data-urlencode 'query=demo_memory_usage_bytes{instance=\"demo.promlabs.com:10000\", type=\"buffers\"}' --data-urlencode 'time=1633504838' ...\"value\":[1633504838,\"148164507.4084375\"]}]}}% VictoriaMetrics may reduce the precision of values with more than 15 decimal digits due to the used compression algorithm. If you want to get more details about how and why this happens, please read the “Precision loss” section in Evaluating Performance and Correctness. In fact, any solution that works with floating point values has precision loss issues because of the nature of floating-point arithmetic.\nWhile such precision loss may be important in rare cases, it doesn’t matter in most practical cases because the measurement error is usually much larger than the precision loss.\nWhile VictoriaMetrics does have higher precision loss than Prometheus, we believe it is completely justified by the compression gains our solution generates. Moreover, only 3 (~0.5% of 529 tests total) queries from the test suite fail due to precision loss.","query-succeeded-but-should-have-failed#Query succeeded, but should have failed":"The following query fails for PromQL but works in MetricsQL:\nQUERY: {__name__=~\".*\"} RESULT: FAILED: Query succeeded, but should have failed. PromQL rejects such a query to prevent database overload because query selects all the metrics from it. At the same time, PromQL does not prevent a user from running an almost identical query{__name__=~\".+\"} , which serves the same purpose.\nThe other example of a failing query is the following:\nQUERY: label_replace(demo_num_cpus, \"~invalid\", \"\", \"src\", \"(.*)\") RESULT: FAILED: Query succeeded, but should have failed. The query fails for PromQL because it doesn’t allow using ~ char in label names. VictoriaMetrics accepts data ingestion from various protocols and systems where such char is allowed, so it has to support a wider list of allowed chars.\nThere were 2 (~0.3% of 529 tests total) queries that failed because of incompatibility but we can’t imagine a situation where it would harm a user’s experience.","summary#Summary":"There are differences between MetricsQL and PromQL. MetricsQL was created long after the PromQL with the goal of improving the user experience and making the language easier to use and understand.\nHow compatibility is measured in the Prometheus Conformance Program isn’t ideal because it really only shows if the tested software uses Prometheus PromQL library under the hood or not. This is particularly complicated for solutions written in programming languages other than Go.\nBy the way, the percentage of failing tests is easy to increase or decrease by changing the number of range intervals (e.g. 1m, 5m etc.) in tests. In the case of VictoriaMetrics, about 90 tests have failed not because of wrong calculations, but because of the metric name present in the response. Of course, there is no ideal way to be fair to everyone. That’s why this post exists to explain the differences.\nWe also want to say a big thank you to Julius Volz, the author of these compliance tests. Thanks to his work and patience we were able to fix most of the real incompatibility issues in MetricsQL.","兼容性测试#兼容性测试":"MetricsQL is a query language inspired by PromQL. It is used as a primary query language in VictoriaMetrics, time series database and monitoring solution. MetricsQL claims to be backward-compatible with PromQL, so Grafana dashboards backed by a Prometheus datasource should work the same after switching from Prometheus to VictoriaMetrics.\nHowever, VictoriaMetrics is not 100% compatible with PromQL and never will be. Please read on and we will discuss why that is.\nFor a long time, there was no way to measure compatibility with PromQL. There was not even a fully defined PromQL specification. But, some time ago, the Prometheus Conformance Program was announced with the aim to certify software with a mark of compatibility with Prometheus — “Upon reaching 100%, the mark will be granted\". The open-source tool, prometheus/compliance was created to check for compatibility.\nCompatibility is measured in quite a simple way— the tool requires a configuration file with a list of PromQL queries to run, a Prometheus server to use as a reference and any other software meant to be tested. The tool sends PromQL queries to both Prometheus and the tested software, and if their responses don’t match — it marks the query as having failed.\n兼容性测试We ran compatibility testing between Prometheus v2.30.0 and VictoriaMetrics v1.67.0 and got the following result:\n==================================================================== General query tweaks: * VictoriaMetrics aligns incoming query timestamps to a multiple of the query resolution step. ==================================================================== Total: 385 / 529 (72.78%) passed, 0 unsupported According to the test, VictoriaMetrics failed 149 tests and was compatible with Prometheus by 72.59% of the time. Let’s take a closer look at the queries that failed."},"title":"对比PromQL"},"/docs/query/metricsql/promql/":{"data":{"":"PromQL 是 Prometheus 系统的查询语言。它是为绘图、告警或派生 Timeseries（通过 recording rules） 场景而设计的强大且简单的语言。PromQL 是从零开始设计的，与其他在时间序列数据库中使用的查询语言（比如 TimescaleDB 的 SQL，InfluxQL 或者 Flux）没有任何共同之处。\n这样做可以为典型的 TSDB 查询创建一个清晰的语言。但是它也有代价 - 初学者通常需要花费几个小时阅读官方的PromQL文档，才能理解其工作原理。让我们简化和缩短 PromQL 的学习曲线。","一个查询返回多个结果#一个查询返回多个结果":"有时候我们需要使用一个 PromQl 语句查询多个时间序列结果。可以使用 or 操作符。比如，下面的语句将会返回名为 metric1、metric2 和 metric3 的时序数据结果：\nmetric1 or metric2 or metric3 VictoriaMetrics 简化了语句的写法，只需要把这些指标用括号（）包围起来：\n(metric1, metric2, metric3) 请注意，这里可以放置任何 PromQL 语句，而不仅仅只是指标名称。\n使用组合表达式 or 时候时，经常会掉进一个陷阱：具有重复标签集（Label Set）的数据结果将被跳过。 例如，以下查询将跳过 sum(b)，因为 sum(a) 和 sum(b) 具有相同的标签集（它们根本没有标签）：\nsum(a) or sum(b) ","使用-gauge#使用 Gauge":"Gauge 是随时可能上下波动的时间序列。 例如，内存使用情况、温度或压力。 绘制仪表图表时，预计会看到图表上每个点的最小值、最大值、平均值和/或分位数值。PromQL 支持使用下面的函数完成这些：\nmin_over_time max_over_time avg_over_time quantile_over_time 比如，以下查询将在图表上绘制每个时间序列的可用内存的最小值：\nmin_over_time(node_memory_MemFree_bytes[5m]) VictoriaMetrics 为 PromQL 增添了 rollup_* 函数，当处理 Gauge 时，它会自动返回 min, max 和 avg 值，例如:\nrollup(node_memory_MemFree_bytes) ","使用label过滤#使用Label过滤":"一个指标名称可能返回多个具有不同 Label Set 的 timeseries，就像上面的例子一样。如何选择只匹配{device=\"eth1\"}的 timeseries？只需在查询中提及所需的 Label 即可：\nnode_network_receive_bytes_total{device=\"eth1\"} 如果你想要查询除了 eth1 的所有 timeseries，只需要把语句里的=换成!=就可以：\nnode_network_receive_bytes_total{device!=\"eth1\"} 如何选择device以 eth 开头的所有 timeseries 呢？只需要使用正则表达式：\nnode_network_receive_bytes_total{device=~\"eth.+\"} 这个正则过滤器支持 Go 语言（RE2）支持的所有写法。\n要查询所有device不以 eth 开头的 timeseries，则只需要把 =~ 替换为 !~：\nnode_network_receive_bytes_total{device!~\"eth.+\"} ","使用多个label过滤#使用多个Label过滤":"Label 过滤器可以被联合使用。举个例子：下面的查询语句只会返回node42:9100实例中device以eth开头的 timeseries。\nnode_network_receive_bytes_total{instance=\"node42:9100\", device=~\"eth.+\"} 这些 Label 过滤器之间是与运算关系。意思是『返回即匹配这个过滤器，又匹配那个过滤器的数据』。\n那如果实现或运算逻辑呢？当前的 PromQL 是不支持或运算的，但大多数场景是可以通过正则表达式来解决的。举个例子，下面的查询语句就会返回 device 是 eth1 或 lo 的 timeseries。\nnode_network_receive_bytes_total{device=~\"eth1|lo\"} ","分组聚合函数#分组聚合函数":"PromQL 支持对时间序列进行分组聚合。时间序列按给定的标签集（Labels）进行分组，然后将给定的聚合函数应用于每个组。 例如，以下查询将返回按实例分组的所有网络接口的入口流量总和：\nsum(rate(node_network_receive_bytes_total[5m])) by (instance) ","对-metric-名称使用正则过滤#对 Metric 名称使用正则过滤":"有时我们可能需要同时返回多个监控指标。Metric 名称本质上也是一个普通的 Label 的值，其 Label 名是__name__。所以可以通过对 Metric 名使用正则的方式，来过滤出多个指标名的数据。举个例子，下面的查询语句会返回 node_network_receive_bytes_total 和node_network_transmit_bytes_total两个指标的 timeseries 数据：\n{__name__=~\"node_network_(receive|transmit)_bytes_total\"} ","对比最新数据和历史数据#对比最新数据和历史数据":"PromQL 支持查询历史数据，并将它与当前最新数据进行合并或对比。只需要给查询语句增加一个 offset。举个例子，下面的查询语句会返回一周前名字是node_network_receive_bytes_total的所有 timeseries：\nnode_network_receive_bytes_total offset 7d The following query would return points where the current GC overhead exceeds hour-old GC overhead by 1.5x.\n下面的查询将返回当前GC开销超过一小时前GC开销1.5倍的数据点。\ngo_memstats_gc_cpu_fraction \u003e 1.5 * (go_memstats_gc_cpu_fraction offset 1h) 运算符 \u003e 和 * 在下面会有介绍。","总结#总结":"PromQL 是一种简单但功能强大的时间序列数据库查询语言。 它允许以简洁而清晰的方式编写典型的 TSDB 查询，特别是与 SQL、InfluxQL 或 Flux 进行比较时。 虽然它可能不支持一些查询，而这些场景是由强大的 SQL 查询支持的，但这些场景在实践中非常罕见，以至于我现在至少记不起一个。 如果您知道此类情况，请在评论中提及。\n本文并没有提及 PromQL 中所有的功能，因为本文仅针对初学者：\n本文没有提及很多函数和逻辑运算符 。 本文没有包含子查询内容。 本文没有包含查询模板(通过 CTE or WITH templates), 它可以大大简化复杂的 PromQL 语句。 本味没有提及很多 VictoriaMetrics 所支持的 MetricsQL 诸多有用特性。 我建议可以通过这个备忘单来学习 PromQL。","操纵label#操纵Label":"PromQL 提供了 2 个函数用于 Label 修改，丰富、删除或创建：\nlabel_replace label_join 尽管这些函数使用起来很困难，但它们允许对所选时间序列上的标签进行强大的动态操作。 label_ 函数的主要用例是将标签转换为所需的值。\nVictoriaMetrics 提供了更丰富的而方便的 Label 改写方法了扩展了这方面的能力。\nlabel_set — 为时间序列额外增加 Label label_del — 从时间序列中删除指定的 Label label_keep — 从时间序列中保留指定的 Label，而删除其他所有 Label label_copy — 把某个 Label Values 复制成其他 Label label_move— 重命名 Label Name label_transform — 将所有匹配了正则表达式的子串，替换到模板中。 label_value — 将规定 Label 的 Value 转换为数字，作为 Value 返回。 ","查询一个-timeseries#查询一个 Timeseries":"选择使用 PromQL 查询 Timeseries 就像在查询中写入一个时间序列名称一样简单。例如，下面的查询将返回所有名称为node_network_receive_bytes_total的 timeseries：\nnode_network_receive_bytes_total 这个名称源自于node_exporter指标，它包含了在各种网络接口上接收的字节数。这样一个简单的查询可能会返回具有相同名称但带有不同 Label Set 的多个 Timeseries。例如，上面的查询可能会返回以下 device Label 等于eth0、eth1和eth2的 Timeseries：\nnode_network_receive_bytes_total{device=\"eth0\"} node_network_receive_bytes_total{device=\"eth1\"} node_network_receive_bytes_total{device=\"eth2\"} 不通的Label被放在了花括号中：{device=\"eth0\"}, {device=\"eth1\"}, {device=\"eth2\"}.\n让我们来看下 TimescaleDB 的 SQL 来达到同样的效果：\nSELECT ts.metric_name_plus_tags, r.timestamps, r.values FROM ( (SELECT time_series_id, array_agg(timestamp ORDER BY timestamp) AS timestamps, array_agg(value ORDER BY timestamp) AS values FROM metrics WHERE time_series_id IN ( SELECT id FROM time_series WHERE metric_name = 'node_network_receive_bytes_total' ) GROUP BY time_series_id ) ) AS r JOIN time_series AS ts ON (r.time_series_id = ts.id) 对比下来是不是觉得很简单。SQL 不得不写得更加复杂，才能与上述的PromQL查询结果相媲美。因为 SQL 不会自带时间范围和降采样机制，但这些都会被 PromQL 的 /query_range 接口 使用start，end和step参数自动完成。","比较运算#比较运算":"PromQL 支持下面几种比较运算：\n等于 (==) 不等于 (!=) 大于 (\u003e) 大于等于 (\u003e=) 小于 (\u003c) 小于等于 (\u003c=) 这些运算符可以像算术运算符一样应用于任意 PromQL 表达式。 比较操作的结果是具有唯一匹配数据点的时间序列。 例如，以下查询将仅返回小于 2300 字节/秒的带宽\nrate(node_network_receive_bytes_total[5m]) \u003c 2300 其结果如下图所示，图中会出现带宽超过 2300 字节/秒的间隙：\n比较运算符的结果可以使用 bool 修饰符进行修改：\nrate(node_network_receive_bytes_total[5m]) \u003c bool 2300 在这个例子中，对于有数据的部分会被转化为true（1），没有数据的转换成false（0）：","算术运算#算术运算":"PromQL 支持所有基础的算术运算\n加法 (+) 减法 (-) 乘法 (*) 除法 (/) 取模 (%) 指数 (^) 这样就可以进行各种数据转换。比如，将bytes/s转换成bits/s：\nrate(node_network_receive_bytes_total[5m]) * 8 此外，也可以进行跨指标运算。例如，该文中巨大的 Flux 查询就可以简单地用下面的 PromQL 语句表达：\nco2 * (((temp_c + 273.15) * 1013.25) / (pressure * 298.15)) 将多个时间序列与算术运算结合起来需要了解匹配规则。否则查询可能会导致数据中断或不正确的结果。匹配规则的基础很简单：\nPromQL 引擎从算术运算左侧和右侧的所有时间序列中剥离指标名称（Metric Name），但不触及标签（Label） 对于左侧的每个时间序列，PromQL 引擎搜索右侧具有相同标签集（Label Set）的相应时间序列，对每个数据点应用运算操作，并返回具有相同标签集（Label Set）的运算结果。如果没有找到匹配的标签集合（Label Set），则时间序列会被从结果中忽略丢弃。 匹配规则可以通过 ignoring,on,group_left和group_right修饰符进行增强。不过其逻辑非常复杂，大多数场景都不需要使用。","计算速率#计算速率":"细心的读者会注意到上面的查询语句在 Grafana 上绘制的线条都是下面这样递增的样式：\n这样的图表实用性几乎为零，因为它们显示的是难以解释的不断增长的Counter值，而我们想要的是网络带宽图表 —— 在图表左侧看到MB/s。PromQL有一个神奇的函数可以实现这个功能 —— rate()。它可以计算所有匹配时间序列的每秒速率：\nrate(node_network_receive_bytes_total[5m]) 这样监控图就变正确了：\n查询语句中的 [5m] 是什么意思呢？这是一个代表 5m（5分钟）时间区间。在这个场景中，在计算每个时间点的每秒平均增长率时， 会往回看5m的数据，即最近5分钟的每秒平均增长。每个数据点的计算公式可以简化为(Vcurr-Vprev)/(Tcurr-Tprev)，Vcurr 代表当前时间Tcurr上的数值，Vprev 代表在时间Tprev 上的数值，其中Tprev=Tcurr-5m。\n如果这看起来太复杂，那么就记住，这个时间区间越大，监控图就会约平滑；而更小的时间区间会让监控图变得更加跳跃（抖动）。VictoriaMetrics 对 PromQL 进行了扩展，这个时间区间[d]可以省略不写，缺省情况下就是2个数据点之间的间隔（通过step参数指定的），而step的默认缺省值是5m。\nrate(node_network_receive_bytes_total) ","速率rate的缺陷#速率(rate)的缺陷":"Rate 删除度量名称，同时保留内部时间序列的所有 Label。\n不要对可能上下波动的时间序列使用 Rate。此类时间序列称为 Gauge。Rate 只能应用于 Counter，Counter 总是上升的，但有时可能会重置为零（例如，服务重启时）。\n不要用irate代替rate，因为它不能捕捉尖峰，而且查询速度也比rate快不了多少。"},"title":"PromQL 新手入门"},"/docs/quickstart/":{"data":{"":"","发布到生产#发布到生产":"如果要在生产环境真正使用 VictoriaMetrics，我们有以下一些建议。\n监控 每个VictoriaMetrics组件都会暴露自己的指标，其中包含有关性能和健康状态的各种详细信息。组件的文档中都有一板块专门介绍监控，其中解释了组件的监控指标的含义，以及如何去监控。比如这里。\nVictoriaMetrics 团队为核心组件准备了一系列的 Grafana Dashboard。每个 Dashboard 中都包含很多有用的信息和提示。建议使用安装这些 Dashboard 并保持更新。\n针对单机版和集群版的VM，还有一系列的告警规则来帮助我们定义和通知系统问题。\n有一个经验是：使用额外的一套独立的监控系统，去监控生产环境的VictoriaMetrics。而不是让它自己监控自己。\n更多详细内容请参考这篇文章。\n容量规划 请阅读集群版和单机版文档中的容量规划部分。\n容量规划需要依赖于监控，所以你应该首先配置下监控。搞清楚资源使用情况以及VictoriaMetrics的性能的前提是，需要知道活跃时序系列，高流失率，基数，慢写入这些基础技术概念，他们都会在 Grafana Dashboard 中呈现。\n数据安全 建议阅读下面几篇内容：\n多副本和数据可靠性 Why replication doesn’t save from disaster? 数据备份 配置限制 为了避免资源使用过度或性能下降，必须设置限制：\n资源使用限制 基数限制 安全建议 单机版安全建议 集群版安全建议 ","告警#告警":"我们不可能一直盯着监控图表来跟踪所有变化，这就是我们需要告警的原因。vmalert 可以基于 PromQL 或 MetricsQL 查询语句创建一系列条件，当条件触发时候会发送自动发送通知。","如何安装#如何安装":"VictoriaMetrics 有 2 种发布形式：\n单机版本 - ALL-IN-ONE 的二进制形式，非常易于使用和维护。可完美地垂直扩展，并且轻松处理百万级的QPS写入。 集群版本 - 一套组件，可用于构建水平可扩展集群。 单机版的 VictoriaMetrics 有以下几种提供方式：\nManaged VictoriaMetrics at AWS Docker 镜像 Snap packages Helm Charts 二进制 源代码。 参见如何构建源代码 VictoriaMetrics on Linode VictoriaMetrics on DigitalOcean 只需要下载 VictoriaMetrics 然后跟随这些步骤把 VictoriaMetrics 运行起来，然后再阅读 Prometheus 和 Grafana 配置文档。\n使用 Docker 启动单机版VM 使用下面的命令下载最新版本的 VictoriaMetrics Docker 镜像，然后使用 8482 端口运行，并将数据存储在当前目录中的 victoria-metrics-data 目录下。\ndocker pull victoriametrics/victoria-metrics:latest docker run -it --rm -v `pwd`/victoria-metrics-data:/victoria-metrics-data -p 8428:8428 victoriametrics/victoria-metrics:latest 用浏览器打开 http://localhost:8428 然后阅读这些文档。\n使用 Docker 启动集群版VM 下面的命令 clone 最新版本的 VictoriaMetrics 仓库，然后使用命令make docker-cluster-up启动 Docker 容器。更多的自定义启动项可以通过编辑docker-compose-cluster.yml实现。\ngit clone https://github.com/VictoriaMetrics/VictoriaMetrics \u0026\u0026 cd VictoriaMetrics make docker-cluster-up 更多详情请看这个文档和集群安装文档","数据写入#数据写入":"数据采集有 2 种主要模式：Push 和 Pull。当今监控领域都会使用，VictoriaMetrics 也全都支持。\n更多数据写入详情，请参考这里。","数据查询#数据查询":"VictoriaMetrics 提供了 HTTP 接口来处理查询请求。这些接口会被各种联合使用，比如 Grafana。这些 API 通用会被 VMUI （用来查看并绘制请求数据的用户界面）使用。\nMetricsQL - 是用来在 VictoriaMetrics 上查询数据的一种查询语言。 MetricsQL 是一个类 PromQL 的查询语言，但它拥有很多强大的处理函数和特性来处理时序数据。\n更多数据查询详情，请参考这里。","数据迁移#数据迁移":"将数据从其他的 TSDB 迁移到 VictoriaMetrics 就像使用支持的数据格式导入数据一样简单。\n使用vmctl迁移数据会很简单（一个 VictoriaMetrics 命令行工具）。它支持将一下几种数据库的数据迁移到 VictoriaMetrics。\nPrometheus using snapshot API; Thanos; InfluxDB; OpenTSDB; Migrate data between VictoriaMetrics single and cluster versions. "},"title":"快速开始"},"/docs/write/":{"data":{"":"","pull#Pull 模型":"VictoriaMetrics 支持当今监控应用的 2 种主流写入模式：Push 和 Pull。\nPush 模型 客户端定期以推送模式将收集到的指标数据发送给服务端：\n客户端（应用程序）决定何时何地发送其指标。VictoriaMetrics支持以下数据摄取协议（也称为推送协议）：\nPrometheus remote write API. Prometheus text exposition format. DataDog protocol. InfluxDB line protocol over HTTP, TCP and UDP. Graphite plaintext protocol with tags. OpenTSDB put message. HTTP OpenTSDB /api/put requests. JSON line format. Arbitrary CSV data. 所有协议都与VictoriaMetrics数据模型完全兼容，可以在生产环境中使用。我们建议使用github.com/VictoriaMetrics/metrics包将应用程序指标推送到VictoriaMetrics。还可以使用已经存在的与上述协议兼容的客户端，例如Telegraf用的 InfluxDB line protocol。\n创建自定义客户端或为指标编写应用程序非常简单，只需发送一个POST请求即可：\ncurl -d '{\"metric\":{\"__name__\":\"foo\",\"job\":\"node_exporter\"},\"values\":[0,1,2],\"timestamps\":[1549891472010,1549891487724,1549891503438]}' -X POST 'http://localhost:8428/api/v1/import' 允许将指标推送/写入单机版VictoriaMetrics、集群组件vminsert 和 vmagent。\nPush 模型的优点：\n在VictoriaMetrics方面，配置更简单 - 无需为监控应用程序配置VictoriaMetrics的位置。不需要复杂的服务发现方案。 安全设置更简单 - 无需设置从VictoriaMetrics到每个监控应用程序的访问权限。 详细了解Percona为什么从 Pull 模式转向 Push 模式，请参阅 Foiled by the Firewall: A Tale of Transition From Prometheus to VictoriaMetrics。\nPush 模型的缺点：\n增加了对被监控应用程序的配置复杂性。每个应用程序都需要独立配置与度量系统交付指标数据的地址。还需要配置指标推送间隔以及在指标传递失败时采取的策略。 将指标数据推送给多个监控系统可能会比较麻烦。 很难判断是应用程序崩溃还是由于其他原因停止发送指标数据。 如果应用程序以太短间隔推送指标数据，可能会使监控系统负载过重。 Pull 模型 Pull 模型是由Prometheus推广的一种方法，其中监控系统决定何时以及从哪里拉取指标：\n在 Pull 模型中，监控系统需要知道所有需要监控的应用程序的地址。指标是定期从已知的应用程序（也称为抓取目标）通过HTTP协议进行抓取（拉取）。\nVictoriaMetrics支持发现与Prometheus兼容的目标，并以与Prometheus相同的方式从这些目标中抓取指标-请参阅这些文档。\n单机版VictoriaMetrics和vmagent都支持指标抓取。\nPull 模型的优点：\n更易于调试-VictoriaMetrics了解所有被监视的应用程序（即抓取目标）。 up == 0查询立即显示不可用的抓取目标。有关抓取目标的实际信息可以在http://victoriametrics:8428/targets和http://vmagent:8429/targets上找到。 监控系统可以控制指标采集频率，因此更容易控制其负载。 应用程序不知道监控系统，并且无需实现指标传递逻辑。 Pull 模型的缺点：\n较难设置安全性-监控系统需要访问它所监视的应用程序。 Pull 模型重度依赖于服务发现方案。 ","push#Push 模型":"","常见的数据收集方法#常见的数据收集方法":"VictoriaMetrics支持数据收集的 Push 和 Pull 模式。许多场景只使用其中一种模式，或同时使用两种模式。\n对于数据收集来说，最常见的方法是同时使用这两种模式：\n在这种方法中，使用了额外的组件 - vmagent。vmagent是一个轻量级代理程序，其主要目的是收集、过滤、重新标记和发送指标给VictoriaMetrics。它支持上述提到的所有Push和Pull协议。\n关于VictoriaMetrics和vmagent的基本监控设置已在示例docker-compose清单中进行了描述。在这个示例中，vmagent会抓取一系列目标，并将收集到的数据转发给VictoriaMetrics。然后，VictoriaMetrics被作为Grafana上的一个Prometheus类型数据源，以查询收集到的数据。\nVictoriaMetrics组件允许构建更高级的拓扑结构。例如，vmagents可以从不同数据中心推送指标到中央的VictoriaMetrics：\n在这个例子中，VictoriaMetrics可以是单机版的VictoriaMetrics或者是集群版本VictoriaMetrics。vmagent还允许将相同的数据复制到多个目标。"},"title":"数据写入"}}